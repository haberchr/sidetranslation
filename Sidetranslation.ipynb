{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dWhJbz0ChHcD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Preamble"
      ],
      "metadata": {
        "id": "I2bHikHDXe64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fairseq wandb sacrebleu sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K-u3lJLXqGQ",
        "outputId": "0e4beb48-b992-4a65-c965-32af310fa3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.6)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.6.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.1)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.9/279.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.23.5)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291817 sha256=899036a241760b07b603b55686cad89cf9037129df5226440ed5958b09704791\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=086e6e48912dd00f8169a3ba46d300bd5e430691e369c288d7daa2a115d82bec\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: sentencepiece, bitarray, antlr4-python3-runtime, smmap, setproctitle, sentry-sdk, portalocker, omegaconf, docker-pycreds, colorama, sacrebleu, hydra-core, gitdb, GitPython, wandb, fairseq\n",
            "Successfully installed GitPython-3.1.40 antlr4-python3-runtime-4.8 bitarray-2.8.4 colorama-0.4.6 docker-pycreds-0.4.0 fairseq-0.12.2 gitdb-4.0.11 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.3 sentencepiece-0.1.99 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get baseline metrics"
      ],
      "metadata": {
        "id": "JY8Qp7JcWEY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget --trust-server-names https://tinyurl.com/nllb200moe54bmetrics -O nllb_54B.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYCoryhRWKbp",
        "outputId": "65c19dd6-4eb5-440e-fe67-f1c4ac2828c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-04 23:32:45--  https://tinyurl.com/nllb200moe54bmetrics\n",
            "Resolving tinyurl.com (tinyurl.com)... 104.20.139.65, 172.67.1.225, 104.20.138.65, ...\n",
            "Connecting to tinyurl.com (tinyurl.com)|104.20.139.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dl.fbaipublicfiles.com/large_objects/nllb/models/nllb_200_moe_54b/metrics.csv [following]\n",
            "--2023-12-04 23:32:45--  https://dl.fbaipublicfiles.com/large_objects/nllb/models/nllb_200_moe_54b/metrics.csv\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.162.163.51, 3.162.163.19, 3.162.163.34, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.162.163.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1297810 (1.2M) [text/csv]\n",
            "Saving to: ‘nllb_54B.csv’\n",
            "\n",
            "nllb_54B.csv        100%[===================>]   1.24M  5.05MB/s    in 0.2s    \n",
            "\n",
            "2023-12-04 23:32:46 (5.05 MB/s) - ‘nllb_54B.csv’ saved [1297810/1297810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "directions = {\"ita_Latn-lij_Latn\", \"ita_Latn-fur_Latn\"}\n",
        "metrics_nllb_54B = pd.read_csv(\"nllb_54B.csv\")\n",
        "metrics_nllb_54B.loc[metrics_nllb_54B[\"direction\"].isin(directions)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "tD3GbdvoWSyD",
        "outputId": "7e2ae71d-7ef4-4188-f985-ac510a12b510"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               direction  chrf++  spBLEU(spm-200)  spBLEU(spm-100)\n",
              "15534  ita_Latn-fur_Latn    50.2             31.1             32.9\n",
              "15578  ita_Latn-lij_Latn    45.5             27.5             27.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9157db4-dae9-44b6-9335-f0eaa453a845\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>direction</th>\n",
              "      <th>chrf++</th>\n",
              "      <th>spBLEU(spm-200)</th>\n",
              "      <th>spBLEU(spm-100)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15534</th>\n",
              "      <td>ita_Latn-fur_Latn</td>\n",
              "      <td>50.2</td>\n",
              "      <td>31.1</td>\n",
              "      <td>32.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15578</th>\n",
              "      <td>ita_Latn-lij_Latn</td>\n",
              "      <td>45.5</td>\n",
              "      <td>27.5</td>\n",
              "      <td>27.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9157db4-dae9-44b6-9335-f0eaa453a845')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9157db4-dae9-44b6-9335-f0eaa453a845 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9157db4-dae9-44b6-9335-f0eaa453a845');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d485225a-8838-460c-8592-867e33e2fb7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d485225a-8838-460c-8592-867e33e2fb7a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d485225a-8838-460c-8592-867e33e2fb7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n"
      ],
      "metadata": {
        "id": "dWhJbz0ChHcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O data.zip https://www.dropbox.com/scl/fi/m866661ie28umen9ve0tc/sidetranslation.zip?rlkey=vufpkuch0k4vdqorao9bvk3d7&dl=0\n",
        "! unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCOePRlBhJLR",
        "outputId": "55b04c30-07a1-4d33-cc9a-ae2cf8210c23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-04 23:32:52--  https://www.dropbox.com/scl/fi/m866661ie28umen9ve0tc/sidetranslation.zip?rlkey=vufpkuch0k4vdqorao9bvk3d7\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com/cd/0/inline/CIxm_5f54n52OnL9yxqz3faP7684AFlUlVtMuOOHCa31jZ4JyUewYYZIE5z6_r3erOE4cB096E5ukw14futbR4S7xOG2HjilccVMOiSmcJQRXCDPHNX4Q7gbMYZmczvOSww/file# [following]\n",
            "--2023-12-04 23:32:54--  https://ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com/cd/0/inline/CIxm_5f54n52OnL9yxqz3faP7684AFlUlVtMuOOHCa31jZ4JyUewYYZIE5z6_r3erOE4cB096E5ukw14futbR4S7xOG2HjilccVMOiSmcJQRXCDPHNX4Q7gbMYZmczvOSww/file\n",
            "Resolving ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com (ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com)... 162.125.83.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com (ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com)|162.125.83.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CIz2T3SdZD6vvB1mMAeYJEhqNU0UJQ2sngUAWZ8_3KW_tzc--Dgk1aS_HoYKhFyWtGuLihSP0ogmevbKW34Azz6pbctTXgDZ724qs92KM27G3IMGNFzsmqWWRTViWTpTrDGYQLMG4qzcqzKMkkiuIyUmsMjTpV_zwTepNrzdEPCdcw75L9T0O7kDT758TX2ctu-NUwGsl8y1OUCktUGzx2W1tj2X8I4JTiDNBRUV3OEQ78wxteaSgtps4TigZrJ5VEYEOG6FtVb_L4ppgDoOTBPMCvmPyBa0rhm8ovmPbGPMfmjduM3G_tMvHlYDetg8A5-_e49l87ZH39ZTcrg4OKy-BcF3Ab8M83k4Ev8XY_jWMQ/file [following]\n",
            "--2023-12-04 23:32:55--  https://ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com/cd/0/inline2/CIz2T3SdZD6vvB1mMAeYJEhqNU0UJQ2sngUAWZ8_3KW_tzc--Dgk1aS_HoYKhFyWtGuLihSP0ogmevbKW34Azz6pbctTXgDZ724qs92KM27G3IMGNFzsmqWWRTViWTpTrDGYQLMG4qzcqzKMkkiuIyUmsMjTpV_zwTepNrzdEPCdcw75L9T0O7kDT758TX2ctu-NUwGsl8y1OUCktUGzx2W1tj2X8I4JTiDNBRUV3OEQ78wxteaSgtps4TigZrJ5VEYEOG6FtVb_L4ppgDoOTBPMCvmPyBa0rhm8ovmPbGPMfmjduM3G_tMvHlYDetg8A5-_e49l87ZH39ZTcrg4OKy-BcF3Ab8M83k4Ev8XY_jWMQ/file\n",
            "Reusing existing connection to ucaf53472a1635e3b9537f9efaf3.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1507664 (1.4M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   1.44M   937KB/s    in 1.6s    \n",
            "\n",
            "2023-12-04 23:32:58 (937 KB/s) - ‘data.zip’ saved [1507664/1507664]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: sidetranslation/\n",
            "  inflating: sidetranslation/00_download.sh  \n",
            "   creating: sidetranslation/data_bin/\n",
            "  inflating: sidetranslation/data_bin/train.ita-lij.lij.idx  \n",
            "  inflating: sidetranslation/data_bin/train.ita-lij.ita.bin  \n",
            "  inflating: sidetranslation/data_bin/train.ita-lij.lij.bin  \n",
            "  inflating: sidetranslation/data_bin/train.ita-lij.ita.idx  \n",
            "  inflating: sidetranslation/data_bin/dict.lij.txt  \n",
            "  inflating: sidetranslation/data_bin/test.ita-lij.lij.bin  \n",
            "  inflating: sidetranslation/data_bin/test.ita-lij.ita.idx  \n",
            "  inflating: sidetranslation/data_bin/test.ita-lij.lij.idx  \n",
            "  inflating: sidetranslation/data_bin/dict.ita.txt  \n",
            "  inflating: sidetranslation/data_bin/test.ita-lij.ita.bin  \n",
            "  inflating: sidetranslation/data_bin/valid.ita-lij.ita.bin  \n",
            "  inflating: sidetranslation/data_bin/valid.ita-lij.lij.idx  \n",
            "  inflating: sidetranslation/data_bin/valid.ita-lij.ita.idx  \n",
            "  inflating: sidetranslation/data_bin/preprocess.log  \n",
            "  inflating: sidetranslation/data_bin/valid.ita-lij.lij.bin  \n",
            "   creating: sidetranslation/spm/\n",
            "  inflating: sidetranslation/spm/multi.unigram.2k.vocab  \n",
            "  inflating: sidetranslation/spm/multi.unigram.3k.model  \n",
            "  inflating: sidetranslation/spm/multi.unigram.3k.vocab  \n",
            "  inflating: sidetranslation/spm/multi.unigram.2k.model  \n",
            "  inflating: sidetranslation/02_apply_spm.sh  \n",
            "  inflating: sidetranslation/devtest.ita  \n",
            "  inflating: sidetranslation/devtest.lij  \n",
            "  inflating: sidetranslation/01_prepare_balanced_spm_corpus.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "6McTL_Uooai1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! LRS=6; EDIM=512; DRP=0.5; ADRP=0.3; RDRP=0.3; LR=1e-3; UF=8; MAXTOK=$((8192*2*8/UF)); fairseq-train \"sidetranslation/data_bin\" \\\n",
        "  --arch transformer --share-all-embeddings --fp16 \\\n",
        "  --encoder-layers ${LRS} --encoder-ffn-embed-dim $((${EDIM}*4)) --encoder-embed-dim ${EDIM} \\\n",
        "  --decoder-layers ${LRS} --decoder-ffn-embed-dim $((${EDIM}*4)) --decoder-embed-dim ${EDIM} \\\n",
        "  --encoder-attention-heads 8 --decoder-attention-heads 8 \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --attention-dropout ${ADRP} --relu-dropout ${RDRP} --dropout ${DRP} \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "  --lr ${LR} -s ita -t lij \\\n",
        "  --label-smoothing 0.1 \\\n",
        "  --lr-scheduler inverse_sqrt --weight-decay 0 \\\n",
        "  --criterion label_smoothed_cross_entropy --max-update 50000 \\\n",
        "  --warmup-updates 400 --warmup-init-lr '1e-07' \\\n",
        "  --max-tokens ${MAXTOK} --update-freq ${UF} \\\n",
        "  --save-interval 10 --validate-interval 10 --keep-last-epochs 2 --max-tokens-valid ${MAXTOK} \\\n",
        "  --best-checkpoint-metric bleu --maximize-best-checkpoint-metric --eval-bleu --eval-bleu-remove-bpe sentencepiece --eval-bleu-detok space --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' --eval-bleu-print-samples \\\n",
        "  --save-dir checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C05KkDVjobSZ",
        "outputId": "b5d76f61-d12b-4fa0-fed3-727e3723c5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2023-12-04 20:47:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:47:33 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)\n",
            "2023-12-04 20:47:33 | INFO | train | epoch 499 | loss 2.305 | nll_loss 0.754 | ppl 1.69 | wps 140977 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 1991 | lr 0.000448223 | gnorm 0.178 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2002\n",
            "2023-12-04 20:47:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 500:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:33 | INFO | fairseq.trainer | begin training epoch 500\n",
            "2023-12-04 20:47:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 500:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 20:47:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:47:37 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, inte Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan utili inte quarche çircostanse.\n",
            "2023-12-04 20:47:37 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 20:47:38 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:47:38 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.51s/it]\u001b[A2023-12-04 20:47:40 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:47:40 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.56s/it]\u001b[A2023-12-04 20:47:42 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dsong, compreiso l’imagine de Zhabdrung Nwang Namgyal.\n",
            "2023-12-04 20:47:42 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  57% 4/7 [00:06<00:04,  1.66s/it]\u001b[A2023-12-04 20:47:44 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vostro hotel o vostro òspite (in caxo sorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; ascì pe desviluppo ò inte un Internet cafète (Inte un pòsto Wi-Fi pubrico.\n",
            "2023-12-04 20:47:44 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.83s/it]\u001b[A2023-12-04 20:47:45 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 de km (29173 d'addeuvia quaddræ) inte l'Asia sud-òvest de Ponente, 2376 (2 km 174 d'ancheu).\n",
            "2023-12-04 20:47:45 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 20:47:47 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî unichi, into meise d'ottobre, inserçioin personalio, un network de 24,4 a l'é stæta ciammâ bòrdo do mondo e a-o Duceoldur, ch'o l'é stæto ciammou Dumbur de personalio.\n",
            "2023-12-04 20:47:47 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 500 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.80s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:47:47 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 6.386 | nll_loss 5.121 | ppl 34.81 | bleu 12.47 | wps 4159 | wpb 7753.9 | bsz 142.4 | num_updates 1995 | best_bleu 12.6\n",
            "2023-12-04 20:47:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 1995 updates\n",
            "2023-12-04 20:47:47 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint500.pt\n",
            "2023-12-04 20:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint500.pt\n",
            "2023-12-04 20:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint500.pt (epoch 500 @ 1995 updates, score 12.47) (writing took 2.12726110299991 seconds)\n",
            "2023-12-04 20:47:50 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)\n",
            "2023-12-04 20:47:50 | INFO | train | epoch 500 | loss 2.307 | nll_loss 0.757 | ppl 1.69 | wps 20516.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 1995 | lr 0.000447774 | gnorm 0.172 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2018\n",
            "2023-12-04 20:47:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 501:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:50 | INFO | fairseq.trainer | begin training epoch 501\n",
            "2023-12-04 20:47:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:47:52 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)\n",
            "2023-12-04 20:47:52 | INFO | train | epoch 501 | loss 2.304 | nll_loss 0.753 | ppl 1.68 | wps 141934 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 1999 | lr 0.000447325 | gnorm 0.177 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2021\n",
            "2023-12-04 20:47:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 502:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:52 | INFO | fairseq.trainer | begin training epoch 502\n",
            "2023-12-04 20:47:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:47:54 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)\n",
            "2023-12-04 20:47:54 | INFO | train | epoch 502 | loss 2.301 | nll_loss 0.75 | ppl 1.68 | wps 142864 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2003 | lr 0.000446879 | gnorm 0.171 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2023\n",
            "2023-12-04 20:47:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 503:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:54 | INFO | fairseq.trainer | begin training epoch 503\n",
            "2023-12-04 20:47:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:47:57 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)\n",
            "2023-12-04 20:47:57 | INFO | train | epoch 503 | loss 2.301 | nll_loss 0.75 | ppl 1.68 | wps 145193 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2007 | lr 0.000446433 | gnorm 0.17 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2025\n",
            "2023-12-04 20:47:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 504:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:57 | INFO | fairseq.trainer | begin training epoch 504\n",
            "2023-12-04 20:47:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:47:59 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)\n",
            "2023-12-04 20:47:59 | INFO | train | epoch 504 | loss 2.294 | nll_loss 0.743 | ppl 1.67 | wps 139236 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2011 | lr 0.000445989 | gnorm 0.162 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2028\n",
            "2023-12-04 20:47:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 505:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:47:59 | INFO | fairseq.trainer | begin training epoch 505\n",
            "2023-12-04 20:47:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:02 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)\n",
            "2023-12-04 20:48:02 | INFO | train | epoch 505 | loss 2.296 | nll_loss 0.744 | ppl 1.68 | wps 140528 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2015 | lr 0.000445546 | gnorm 0.167 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2030\n",
            "2023-12-04 20:48:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 506:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:02 | INFO | fairseq.trainer | begin training epoch 506\n",
            "2023-12-04 20:48:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:04 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)\n",
            "2023-12-04 20:48:04 | INFO | train | epoch 506 | loss 2.292 | nll_loss 0.74 | ppl 1.67 | wps 143837 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2019 | lr 0.000445104 | gnorm 0.168 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2033\n",
            "2023-12-04 20:48:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 507:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:04 | INFO | fairseq.trainer | begin training epoch 507\n",
            "2023-12-04 20:48:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:06 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)\n",
            "2023-12-04 20:48:06 | INFO | train | epoch 507 | loss 2.292 | nll_loss 0.742 | ppl 1.67 | wps 143591 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2023 | lr 0.000444664 | gnorm 0.165 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2035\n",
            "2023-12-04 20:48:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 508:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:07 | INFO | fairseq.trainer | begin training epoch 508\n",
            "2023-12-04 20:48:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:09 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)\n",
            "2023-12-04 20:48:09 | INFO | train | epoch 508 | loss 2.293 | nll_loss 0.741 | ppl 1.67 | wps 141100 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2027 | lr 0.000444225 | gnorm 0.166 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2038\n",
            "2023-12-04 20:48:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 509:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:09 | INFO | fairseq.trainer | begin training epoch 509\n",
            "2023-12-04 20:48:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:11 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)\n",
            "2023-12-04 20:48:11 | INFO | train | epoch 509 | loss 2.29 | nll_loss 0.738 | ppl 1.67 | wps 142263 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2031 | lr 0.000443787 | gnorm 0.161 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2040\n",
            "2023-12-04 20:48:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 510:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:11 | INFO | fairseq.trainer | begin training epoch 510\n",
            "2023-12-04 20:48:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 510:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 20:48:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:48:15 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:48:15 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 20:48:17 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e settemañe struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:48:17 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 20:48:18 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erta propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:48:18 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 20:48:20 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte requilie do Drugkyal Dzong, compreiso l’imagine de Zhabrung Ngawang Namgyal.\n",
            "2023-12-04 20:48:20 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.67s/it]\u001b[A2023-12-04 20:48:22 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo soviorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ in sce l’Internet ò intenet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:48:22 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.82s/it]\u001b[A2023-12-04 20:48:24 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggiæa d'ancheu): de sti 75.68 km (29173 quaddræ) in sce l'Asia sud-òvest de Ponente, 2376 (29173), ch'a l'é Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:48:24 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 20:48:26 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ di attirati de 5.00.00 vixitatoî de unichi, into meise d'öto d'ottobre, inserçioin personali, un neorkwork de 24, ch'o l'é stæto ciammou un mondo a-o Dumbur, Woldur.\n",
            "2023-12-04 20:48:26 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 510 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:48:26 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 6.385 | nll_loss 5.125 | ppl 34.88 | bleu 12.45 | wps 4257.4 | wpb 7753.9 | bsz 142.4 | num_updates 2035 | best_bleu 12.6\n",
            "2023-12-04 20:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 2035 updates\n",
            "2023-12-04 20:48:26 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint510.pt\n",
            "2023-12-04 20:48:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint510.pt\n",
            "2023-12-04 20:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint510.pt (epoch 510 @ 2035 updates, score 12.45) (writing took 2.1121166889997767 seconds)\n",
            "2023-12-04 20:48:28 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)\n",
            "2023-12-04 20:48:28 | INFO | train | epoch 510 | loss 2.287 | nll_loss 0.735 | ppl 1.66 | wps 20850 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2035 | lr 0.000443351 | gnorm 0.159 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2057\n",
            "2023-12-04 20:48:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 511:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:28 | INFO | fairseq.trainer | begin training epoch 511\n",
            "2023-12-04 20:48:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:30 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)\n",
            "2023-12-04 20:48:30 | INFO | train | epoch 511 | loss 2.286 | nll_loss 0.734 | ppl 1.66 | wps 138522 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 2039 | lr 0.000442916 | gnorm 0.153 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2059\n",
            "2023-12-04 20:48:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 512:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:30 | INFO | fairseq.trainer | begin training epoch 512\n",
            "2023-12-04 20:48:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:33 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)\n",
            "2023-12-04 20:48:33 | INFO | train | epoch 512 | loss 2.285 | nll_loss 0.733 | ppl 1.66 | wps 140842 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2043 | lr 0.000442482 | gnorm 0.159 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2061\n",
            "2023-12-04 20:48:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 513:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:33 | INFO | fairseq.trainer | begin training epoch 513\n",
            "2023-12-04 20:48:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:35 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)\n",
            "2023-12-04 20:48:35 | INFO | train | epoch 513 | loss 2.285 | nll_loss 0.733 | ppl 1.66 | wps 142270 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2047 | lr 0.00044205 | gnorm 0.16 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2064\n",
            "2023-12-04 20:48:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 514:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:35 | INFO | fairseq.trainer | begin training epoch 514\n",
            "2023-12-04 20:48:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:38 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)\n",
            "2023-12-04 20:48:38 | INFO | train | epoch 514 | loss 2.284 | nll_loss 0.733 | ppl 1.66 | wps 143545 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2051 | lr 0.000441618 | gnorm 0.157 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2066\n",
            "2023-12-04 20:48:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 515:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:38 | INFO | fairseq.trainer | begin training epoch 515\n",
            "2023-12-04 20:48:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:40 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)\n",
            "2023-12-04 20:48:40 | INFO | train | epoch 515 | loss 2.284 | nll_loss 0.73 | ppl 1.66 | wps 142742 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2055 | lr 0.000441188 | gnorm 0.161 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2069\n",
            "2023-12-04 20:48:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 516:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:40 | INFO | fairseq.trainer | begin training epoch 516\n",
            "2023-12-04 20:48:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:42 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)\n",
            "2023-12-04 20:48:42 | INFO | train | epoch 516 | loss 2.283 | nll_loss 0.732 | ppl 1.66 | wps 141553 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2059 | lr 0.00044076 | gnorm 0.158 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2071\n",
            "2023-12-04 20:48:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 517:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:42 | INFO | fairseq.trainer | begin training epoch 517\n",
            "2023-12-04 20:48:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:45 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)\n",
            "2023-12-04 20:48:45 | INFO | train | epoch 517 | loss 2.282 | nll_loss 0.729 | ppl 1.66 | wps 140445 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2063 | lr 0.000440332 | gnorm 0.159 | loss_scale 4 | train_wall 2 | gb_free 33.2 | wall 2074\n",
            "2023-12-04 20:48:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 518:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:45 | INFO | fairseq.trainer | begin training epoch 518\n",
            "2023-12-04 20:48:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:47 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)\n",
            "2023-12-04 20:48:47 | INFO | train | epoch 518 | loss 2.28 | nll_loss 0.727 | ppl 1.65 | wps 144874 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2067 | lr 0.000439906 | gnorm 0.161 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2076\n",
            "2023-12-04 20:48:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 519:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:47 | INFO | fairseq.trainer | begin training epoch 519\n",
            "2023-12-04 20:48:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:48:50 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)\n",
            "2023-12-04 20:48:50 | INFO | train | epoch 519 | loss 2.28 | nll_loss 0.729 | ppl 1.66 | wps 142048 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2071 | lr 0.000439481 | gnorm 0.157 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2078\n",
            "2023-12-04 20:48:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 520:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:48:50 | INFO | fairseq.trainer | begin training epoch 520\n",
            "2023-12-04 20:48:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 520:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:48:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:48:53 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:48:53 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.42s/it]\u001b[A2023-12-04 20:48:55 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:48:55 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.51s/it]\u001b[A2023-12-04 20:48:57 | INFO | fairseq.tasks.translation | example hypothesis: Tanto ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ da çerti ponti an fornio à di microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 20:48:57 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.55s/it]\u001b[A2023-12-04 20:48:58 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dsong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:48:58 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  57% 4/7 [00:06<00:04,  1.67s/it]\u001b[A2023-12-04 20:49:01 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel ò o vostro ospite (in caxo sorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o l’é trovou in sce lonquente ò inte l’Internet ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:49:01 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.82s/it]\u001b[A2023-12-04 20:49:02 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 de km (2917373 quaddræ) in sce l’Asia sud-òvest de Ponente, 2376 (29173 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:49:02 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 20:49:04 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scitoweb o peu attiâ di 5.00.000 vixitatoî de vixitatoî unichi into meise d'ötovie, inserçioin personali, un network de noçieh, 24 ch'o l'é stæto lasciou do mondo a-o Duldur.\n",
            "2023-12-04 20:49:04 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 520 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:49:04 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 6.401 | nll_loss 5.143 | ppl 35.34 | bleu 12.33 | wps 4247 | wpb 7753.9 | bsz 142.4 | num_updates 2075 | best_bleu 12.6\n",
            "2023-12-04 20:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 2075 updates\n",
            "2023-12-04 20:49:04 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint520.pt\n",
            "2023-12-04 20:49:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint520.pt\n",
            "2023-12-04 20:49:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint520.pt (epoch 520 @ 2075 updates, score 12.33) (writing took 2.114592299999913 seconds)\n",
            "2023-12-04 20:49:06 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)\n",
            "2023-12-04 20:49:06 | INFO | train | epoch 520 | loss 2.28 | nll_loss 0.727 | ppl 1.66 | wps 20832.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2075 | lr 0.000439057 | gnorm 0.166 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2095\n",
            "2023-12-04 20:49:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 521:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:06 | INFO | fairseq.trainer | begin training epoch 521\n",
            "2023-12-04 20:49:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:09 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)\n",
            "2023-12-04 20:49:09 | INFO | train | epoch 521 | loss 2.276 | nll_loss 0.725 | ppl 1.65 | wps 139749 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2079 | lr 0.000438634 | gnorm 0.167 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2097\n",
            "2023-12-04 20:49:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 522:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:09 | INFO | fairseq.trainer | begin training epoch 522\n",
            "2023-12-04 20:49:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:11 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)\n",
            "2023-12-04 20:49:11 | INFO | train | epoch 522 | loss 2.273 | nll_loss 0.72 | ppl 1.65 | wps 142932 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2083 | lr 0.000438213 | gnorm 0.16 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2100\n",
            "2023-12-04 20:49:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 523:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:11 | INFO | fairseq.trainer | begin training epoch 523\n",
            "2023-12-04 20:49:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:13 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)\n",
            "2023-12-04 20:49:13 | INFO | train | epoch 523 | loss 2.275 | nll_loss 0.724 | ppl 1.65 | wps 140727 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2087 | lr 0.000437793 | gnorm 0.16 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2102\n",
            "2023-12-04 20:49:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 524:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:13 | INFO | fairseq.trainer | begin training epoch 524\n",
            "2023-12-04 20:49:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:16 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)\n",
            "2023-12-04 20:49:16 | INFO | train | epoch 524 | loss 2.272 | nll_loss 0.718 | ppl 1.64 | wps 141622 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2091 | lr 0.000437374 | gnorm 0.17 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2105\n",
            "2023-12-04 20:49:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 525:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:16 | INFO | fairseq.trainer | begin training epoch 525\n",
            "2023-12-04 20:49:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:18 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)\n",
            "2023-12-04 20:49:18 | INFO | train | epoch 525 | loss 2.272 | nll_loss 0.719 | ppl 1.65 | wps 143485 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2095 | lr 0.000436956 | gnorm 0.163 | loss_scale 4 | train_wall 2 | gb_free 33.7 | wall 2107\n",
            "2023-12-04 20:49:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 526:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:18 | INFO | fairseq.trainer | begin training epoch 526\n",
            "2023-12-04 20:49:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:21 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)\n",
            "2023-12-04 20:49:21 | INFO | train | epoch 526 | loss 2.271 | nll_loss 0.717 | ppl 1.64 | wps 141437 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2099 | lr 0.00043654 | gnorm 0.162 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2109\n",
            "2023-12-04 20:49:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 527:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:21 | INFO | fairseq.trainer | begin training epoch 527\n",
            "2023-12-04 20:49:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:23 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)\n",
            "2023-12-04 20:49:23 | INFO | train | epoch 527 | loss 2.269 | nll_loss 0.716 | ppl 1.64 | wps 142826 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2103 | lr 0.000436124 | gnorm 0.166 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2112\n",
            "2023-12-04 20:49:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 528:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:23 | INFO | fairseq.trainer | begin training epoch 528\n",
            "2023-12-04 20:49:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:25 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)\n",
            "2023-12-04 20:49:25 | INFO | train | epoch 528 | loss 2.27 | nll_loss 0.717 | ppl 1.64 | wps 145572 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2107 | lr 0.00043571 | gnorm 0.169 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2114\n",
            "2023-12-04 20:49:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 529:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:25 | INFO | fairseq.trainer | begin training epoch 529\n",
            "2023-12-04 20:49:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:28 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)\n",
            "2023-12-04 20:49:28 | INFO | train | epoch 529 | loss 2.273 | nll_loss 0.72 | ppl 1.65 | wps 144232 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2111 | lr 0.000435297 | gnorm 0.171 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2117\n",
            "2023-12-04 20:49:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 530:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:28 | INFO | fairseq.trainer | begin training epoch 530\n",
            "2023-12-04 20:49:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 530:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 20:49:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:49:32 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:49:32 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 20:49:33 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioinæ da-e seçioin settemañe de struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:49:33 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.56s/it]\u001b[A2023-12-04 20:49:35 | INFO | fairseq.tasks.translation | example hypothesis: Tanto ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che Alban an produto di additi microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 20:49:35 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.63s/it]\u001b[A2023-12-04 20:49:37 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dsong, compreiso l'imagine de Zhabrung Nwang Namgyal.\n",
            "2023-12-04 20:49:37 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.74s/it]\u001b[A2023-12-04 20:49:39 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel ò o vostro ospite (in caxo soviorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; pe de ciù o trove ancon inte l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:49:39 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.90s/it]\u001b[A2023-12-04 20:49:41 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 de km (29173 quaddræ) in sce l’Asia sud-òvest, ch’a l’é 75. (29173), ch’a s’attreuva inte l’Asia sud-òvest, e 2376).\n",
            "2023-12-04 20:49:41 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 20:49:42 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb o peu attiâ di atti de 5.00.000 vixitatoî de unichi, into meise d'öto d'ottobre, inserçioin personali, un network de noçiest, ch'o l'é stæto lasciou à Duceante, Wor.\n",
            "2023-12-04 20:49:42 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 530 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:49:42 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 6.407 | nll_loss 5.157 | ppl 35.67 | bleu 12.4 | wps 4166.7 | wpb 7753.9 | bsz 142.4 | num_updates 2115 | best_bleu 12.6\n",
            "2023-12-04 20:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 2115 updates\n",
            "2023-12-04 20:49:42 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint530.pt\n",
            "2023-12-04 20:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint530.pt\n",
            "2023-12-04 20:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint530.pt (epoch 530 @ 2115 updates, score 12.4) (writing took 6.05314448199988 seconds)\n",
            "2023-12-04 20:49:48 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)\n",
            "2023-12-04 20:49:48 | INFO | train | epoch 530 | loss 2.274 | nll_loss 0.722 | ppl 1.65 | wps 16638.4 | ups 0.19 | wpb 85903.8 | bsz 1548.2 | num_updates 2115 | lr 0.000434885 | gnorm 0.196 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2137\n",
            "2023-12-04 20:49:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 531:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:49 | INFO | fairseq.trainer | begin training epoch 531\n",
            "2023-12-04 20:49:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:51 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)\n",
            "2023-12-04 20:49:51 | INFO | train | epoch 531 | loss 2.277 | nll_loss 0.727 | ppl 1.66 | wps 141451 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2119 | lr 0.000434475 | gnorm 0.207 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2140\n",
            "2023-12-04 20:49:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 532:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:51 | INFO | fairseq.trainer | begin training epoch 532\n",
            "2023-12-04 20:49:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:53 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)\n",
            "2023-12-04 20:49:53 | INFO | train | epoch 532 | loss 2.269 | nll_loss 0.716 | ppl 1.64 | wps 142862 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2123 | lr 0.000434065 | gnorm 0.191 | loss_scale 4 | train_wall 2 | gb_free 33.2 | wall 2142\n",
            "2023-12-04 20:49:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 533:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:53 | INFO | fairseq.trainer | begin training epoch 533\n",
            "2023-12-04 20:49:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:56 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)\n",
            "2023-12-04 20:49:56 | INFO | train | epoch 533 | loss 2.268 | nll_loss 0.718 | ppl 1.65 | wps 141686 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2127 | lr 0.000433657 | gnorm 0.187 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2144\n",
            "2023-12-04 20:49:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 534:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:56 | INFO | fairseq.trainer | begin training epoch 534\n",
            "2023-12-04 20:49:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:49:58 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)\n",
            "2023-12-04 20:49:58 | INFO | train | epoch 534 | loss 2.262 | nll_loss 0.706 | ppl 1.63 | wps 142860 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2131 | lr 0.00043325 | gnorm 0.172 | loss_scale 4 | train_wall 2 | gb_free 33.8 | wall 2147\n",
            "2023-12-04 20:49:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 535:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:49:58 | INFO | fairseq.trainer | begin training epoch 535\n",
            "2023-12-04 20:49:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:01 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)\n",
            "2023-12-04 20:50:01 | INFO | train | epoch 535 | loss 2.26 | nll_loss 0.707 | ppl 1.63 | wps 144582 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2135 | lr 0.000432844 | gnorm 0.164 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2149\n",
            "2023-12-04 20:50:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 536:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:01 | INFO | fairseq.trainer | begin training epoch 536\n",
            "2023-12-04 20:50:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:03 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)\n",
            "2023-12-04 20:50:03 | INFO | train | epoch 536 | loss 2.26 | nll_loss 0.706 | ppl 1.63 | wps 143375 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2139 | lr 0.000432439 | gnorm 0.16 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2152\n",
            "2023-12-04 20:50:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 537:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:03 | INFO | fairseq.trainer | begin training epoch 537\n",
            "2023-12-04 20:50:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:05 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)\n",
            "2023-12-04 20:50:05 | INFO | train | epoch 537 | loss 2.257 | nll_loss 0.703 | ppl 1.63 | wps 140665 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2143 | lr 0.000432035 | gnorm 0.163 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2154\n",
            "2023-12-04 20:50:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 538:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:05 | INFO | fairseq.trainer | begin training epoch 538\n",
            "2023-12-04 20:50:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:08 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)\n",
            "2023-12-04 20:50:08 | INFO | train | epoch 538 | loss 2.254 | nll_loss 0.701 | ppl 1.63 | wps 144592 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2147 | lr 0.000431632 | gnorm 0.162 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2156\n",
            "2023-12-04 20:50:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 539:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:08 | INFO | fairseq.trainer | begin training epoch 539\n",
            "2023-12-04 20:50:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:10 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)\n",
            "2023-12-04 20:50:10 | INFO | train | epoch 539 | loss 2.254 | nll_loss 0.701 | ppl 1.63 | wps 143082 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2151 | lr 0.000431231 | gnorm 0.173 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2159\n",
            "2023-12-04 20:50:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 540:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:10 | INFO | fairseq.trainer | begin training epoch 540\n",
            "2023-12-04 20:50:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 540:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:50:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:50:14 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no en deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:50:14 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  14% 1/7 [00:01<00:10,  1.76s/it]\u001b[A2023-12-04 20:50:16 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:50:16 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.64s/it]\u001b[A2023-12-04 20:50:18 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de gibinti ò an produto di additi microonde ò atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:50:18 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  43% 3/7 [00:05<00:06,  1.68s/it]\u001b[A2023-12-04 20:50:19 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dsong, compreiso l'imagine de Zhabrung Nwang Namgyal.\n",
            "2023-12-04 20:50:19 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.74s/it]\u001b[A2023-12-04 20:50:22 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo soviorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso d’Internet; o l’é ancon in azzonta à un inte lonquente ò inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:50:22 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.89s/it]\u001b[A2023-12-04 20:50:23 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): in sce sti 75.68 de km (29173 d’atoa stæti quaddræ) in sce l’Asia sud-òvest, ch’o l’à 2376 (2 km (1974 d’e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:50:23 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 20:50:25 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb o peu attiâ di atti de 5.00.000 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un neorkwork de noçieh, ch'o l'é stæto lasciou do mondo est, ciammou Duceante.\n",
            "2023-12-04 20:50:25 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 540 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:50:25 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 6.416 | nll_loss 5.164 | ppl 35.84 | bleu 12.66 | wps 4226.6 | wpb 7753.9 | bsz 142.4 | num_updates 2155 | best_bleu 12.66\n",
            "2023-12-04 20:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 2155 updates\n",
            "2023-12-04 20:50:25 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint540.pt\n",
            "2023-12-04 20:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint540.pt\n",
            "2023-12-04 20:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint540.pt (epoch 540 @ 2155 updates, score 12.66) (writing took 8.1643812049997 seconds)\n",
            "2023-12-04 20:50:33 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)\n",
            "2023-12-04 20:50:33 | INFO | train | epoch 540 | loss 2.254 | nll_loss 0.699 | ppl 1.62 | wps 15003.1 | ups 0.17 | wpb 85903.8 | bsz 1548.2 | num_updates 2155 | lr 0.00043083 | gnorm 0.17 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2182\n",
            "2023-12-04 20:50:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 541:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:33 | INFO | fairseq.trainer | begin training epoch 541\n",
            "2023-12-04 20:50:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:35 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)\n",
            "2023-12-04 20:50:35 | INFO | train | epoch 541 | loss 2.253 | nll_loss 0.699 | ppl 1.62 | wps 141722 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2159 | lr 0.000430431 | gnorm 0.161 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2184\n",
            "2023-12-04 20:50:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 542:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:35 | INFO | fairseq.trainer | begin training epoch 542\n",
            "2023-12-04 20:50:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:38 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)\n",
            "2023-12-04 20:50:38 | INFO | train | epoch 542 | loss 2.252 | nll_loss 0.699 | ppl 1.62 | wps 141397 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2163 | lr 0.000430033 | gnorm 0.163 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2187\n",
            "2023-12-04 20:50:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 543:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:38 | INFO | fairseq.trainer | begin training epoch 543\n",
            "2023-12-04 20:50:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:40 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)\n",
            "2023-12-04 20:50:40 | INFO | train | epoch 543 | loss 2.251 | nll_loss 0.698 | ppl 1.62 | wps 141885 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2167 | lr 0.000429636 | gnorm 0.156 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2189\n",
            "2023-12-04 20:50:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 544:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:40 | INFO | fairseq.trainer | begin training epoch 544\n",
            "2023-12-04 20:50:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:43 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)\n",
            "2023-12-04 20:50:43 | INFO | train | epoch 544 | loss 2.249 | nll_loss 0.695 | ppl 1.62 | wps 142500 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2171 | lr 0.00042924 | gnorm 0.159 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2191\n",
            "2023-12-04 20:50:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 545:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:43 | INFO | fairseq.trainer | begin training epoch 545\n",
            "2023-12-04 20:50:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:45 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)\n",
            "2023-12-04 20:50:45 | INFO | train | epoch 545 | loss 2.246 | nll_loss 0.691 | ppl 1.61 | wps 143285 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2175 | lr 0.000428845 | gnorm 0.153 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2194\n",
            "2023-12-04 20:50:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 546:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:45 | INFO | fairseq.trainer | begin training epoch 546\n",
            "2023-12-04 20:50:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:48 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)\n",
            "2023-12-04 20:50:48 | INFO | train | epoch 546 | loss 2.246 | nll_loss 0.692 | ppl 1.62 | wps 143147 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2179 | lr 0.000428451 | gnorm 0.158 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2196\n",
            "2023-12-04 20:50:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 547:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:48 | INFO | fairseq.trainer | begin training epoch 547\n",
            "2023-12-04 20:50:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:50 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)\n",
            "2023-12-04 20:50:50 | INFO | train | epoch 547 | loss 2.243 | nll_loss 0.686 | ppl 1.61 | wps 141877 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2183 | lr 0.000428059 | gnorm 0.154 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2199\n",
            "2023-12-04 20:50:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 548:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:50 | INFO | fairseq.trainer | begin training epoch 548\n",
            "2023-12-04 20:50:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:52 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)\n",
            "2023-12-04 20:50:52 | INFO | train | epoch 548 | loss 2.242 | nll_loss 0.688 | ppl 1.61 | wps 142921 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2187 | lr 0.000427667 | gnorm 0.153 | loss_scale 4 | train_wall 2 | gb_free 33.3 | wall 2201\n",
            "2023-12-04 20:50:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 549:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:52 | INFO | fairseq.trainer | begin training epoch 549\n",
            "2023-12-04 20:50:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:50:55 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)\n",
            "2023-12-04 20:50:55 | INFO | train | epoch 549 | loss 2.241 | nll_loss 0.686 | ppl 1.61 | wps 143125 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2191 | lr 0.000427276 | gnorm 0.158 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2203\n",
            "2023-12-04 20:50:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 550:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:50:55 | INFO | fairseq.trainer | begin training epoch 550\n",
            "2023-12-04 20:50:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 550:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 20:50:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:50:59 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:50:59 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 20:51:00 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioinæ da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:51:00 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 20:51:02 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:51:02 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 20:51:04 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:51:04 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.73s/it]\u001b[A2023-12-04 20:51:06 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo soviorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o l’é trovou inte lonquente ò inte l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:51:06 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.92s/it]\u001b[A2023-12-04 20:51:08 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): de sti 75.68 km (2917373 quaddræ) in sce l'Asia sud-occidentale, e 2376 (29173 d'ancheu (e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:51:08 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 20:51:09 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scitoweb o peu attiâ di attirati de 5.0000 de vixitatoî unichi into meise d'ötovie, inserçioin personali, un network de noçieh 24, ch'o l'é stæto lasciou à Duceanter, Woombur, un Ombur inser.\n",
            "2023-12-04 20:51:09 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 550 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.79s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:51:09 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 6.41 | nll_loss 5.165 | ppl 35.87 | bleu 12.73 | wps 4110.8 | wpb 7753.9 | bsz 142.4 | num_updates 2195 | best_bleu 12.73\n",
            "2023-12-04 20:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 2195 updates\n",
            "2023-12-04 20:51:09 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint550.pt\n",
            "2023-12-04 20:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint550.pt\n",
            "2023-12-04 20:51:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint550.pt (epoch 550 @ 2195 updates, score 12.73) (writing took 4.038869488999808 seconds)\n",
            "2023-12-04 20:51:14 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)\n",
            "2023-12-04 20:51:14 | INFO | train | epoch 550 | loss 2.242 | nll_loss 0.687 | ppl 1.61 | wps 18289.1 | ups 0.21 | wpb 85903.8 | bsz 1548.2 | num_updates 2195 | lr 0.000426887 | gnorm 0.156 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2222\n",
            "2023-12-04 20:51:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 551:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:14 | INFO | fairseq.trainer | begin training epoch 551\n",
            "2023-12-04 20:51:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:16 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)\n",
            "2023-12-04 20:51:16 | INFO | train | epoch 551 | loss 2.24 | nll_loss 0.685 | ppl 1.61 | wps 138757 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2199 | lr 0.000426498 | gnorm 0.152 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2225\n",
            "2023-12-04 20:51:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 552:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:16 | INFO | fairseq.trainer | begin training epoch 552\n",
            "2023-12-04 20:51:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:18 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)\n",
            "2023-12-04 20:51:18 | INFO | train | epoch 552 | loss 2.236 | nll_loss 0.682 | ppl 1.6 | wps 140348 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2203 | lr 0.000426111 | gnorm 0.156 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2227\n",
            "2023-12-04 20:51:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 553:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:18 | INFO | fairseq.trainer | begin training epoch 553\n",
            "2023-12-04 20:51:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:21 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)\n",
            "2023-12-04 20:51:21 | INFO | train | epoch 553 | loss 2.238 | nll_loss 0.682 | ppl 1.6 | wps 144882 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2207 | lr 0.000425725 | gnorm 0.158 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2230\n",
            "2023-12-04 20:51:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 554:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:21 | INFO | fairseq.trainer | begin training epoch 554\n",
            "2023-12-04 20:51:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:23 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)\n",
            "2023-12-04 20:51:23 | INFO | train | epoch 554 | loss 2.238 | nll_loss 0.684 | ppl 1.61 | wps 141902 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2211 | lr 0.000425339 | gnorm 0.159 | loss_scale 4 | train_wall 2 | gb_free 33.4 | wall 2232\n",
            "2023-12-04 20:51:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 555:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:23 | INFO | fairseq.trainer | begin training epoch 555\n",
            "2023-12-04 20:51:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:26 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)\n",
            "2023-12-04 20:51:26 | INFO | train | epoch 555 | loss 2.236 | nll_loss 0.68 | ppl 1.6 | wps 143816 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2215 | lr 0.000424955 | gnorm 0.162 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2234\n",
            "2023-12-04 20:51:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 556:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:26 | INFO | fairseq.trainer | begin training epoch 556\n",
            "2023-12-04 20:51:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:28 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)\n",
            "2023-12-04 20:51:28 | INFO | train | epoch 556 | loss 2.235 | nll_loss 0.682 | ppl 1.6 | wps 140614 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2219 | lr 0.000424572 | gnorm 0.162 | loss_scale 4 | train_wall 2 | gb_free 33.1 | wall 2237\n",
            "2023-12-04 20:51:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 557:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:28 | INFO | fairseq.trainer | begin training epoch 557\n",
            "2023-12-04 20:51:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:31 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)\n",
            "2023-12-04 20:51:31 | INFO | train | epoch 557 | loss 2.237 | nll_loss 0.682 | ppl 1.6 | wps 141881 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2223 | lr 0.00042419 | gnorm 0.168 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2239\n",
            "2023-12-04 20:51:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 558:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:31 | INFO | fairseq.trainer | begin training epoch 558\n",
            "2023-12-04 20:51:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:33 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)\n",
            "2023-12-04 20:51:33 | INFO | train | epoch 558 | loss 2.235 | nll_loss 0.681 | ppl 1.6 | wps 143465 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2227 | lr 0.000423809 | gnorm 0.166 | loss_scale 4 | train_wall 2 | gb_free 33.5 | wall 2242\n",
            "2023-12-04 20:51:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 559:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:33 | INFO | fairseq.trainer | begin training epoch 559\n",
            "2023-12-04 20:51:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:35 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)\n",
            "2023-12-04 20:51:35 | INFO | train | epoch 559 | loss 2.233 | nll_loss 0.678 | ppl 1.6 | wps 144062 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2231 | lr 0.000423429 | gnorm 0.167 | loss_scale 4 | train_wall 2 | gb_free 33.6 | wall 2244\n",
            "2023-12-04 20:51:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 560:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:35 | INFO | fairseq.trainer | begin training epoch 560\n",
            "2023-12-04 20:51:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 560:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:51:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:51:39 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:51:39 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 20:51:41 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:51:41 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 20:51:42 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibboin ò an produto di additi microonde ò atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 20:51:42 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 20:51:44 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:51:44 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.72s/it]\u001b[A2023-12-04 20:51:46 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vostro hotel o vostro òspite (in caxo soviorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù in sce lonquente ò inte l’Internet ò un pòsto con Wi-Fi pubrico.\n",
            "2023-12-04 20:51:46 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.88s/it]\u001b[A2023-12-04 20:51:48 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30.948 miggia quaddræ): in sce sti 75.68 de km (2917373 quaddræ) in sce l'Asia sud-òvest, e 2376 (29173 d'Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:51:48 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 20:51:50 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb o poeiva attiâ di atti de 5.00.000 vixitatoî unichi into meise d'öto d'ottobre, inserçioin personali, un neorkwork de noçieh, 24 etlante à Ducealdur, ciammou Dumbur de Ombur.\n",
            "2023-12-04 20:51:50 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 560 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:51:50 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 6.427 | nll_loss 5.183 | ppl 36.33 | bleu 12.61 | wps 4225.5 | wpb 7753.9 | bsz 142.4 | num_updates 2235 | best_bleu 12.73\n",
            "2023-12-04 20:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 2235 updates\n",
            "2023-12-04 20:51:50 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint560.pt\n",
            "2023-12-04 20:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint560.pt\n",
            "2023-12-04 20:51:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint560.pt (epoch 560 @ 2235 updates, score 12.61) (writing took 2.118871743999989 seconds)\n",
            "2023-12-04 20:51:52 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)\n",
            "2023-12-04 20:51:52 | INFO | train | epoch 560 | loss 2.234 | nll_loss 0.68 | ppl 1.6 | wps 20724.6 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2235 | lr 0.00042305 | gnorm 0.17 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2261\n",
            "2023-12-04 20:51:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 561:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:52 | INFO | fairseq.trainer | begin training epoch 561\n",
            "2023-12-04 20:51:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:54 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)\n",
            "2023-12-04 20:51:54 | INFO | train | epoch 561 | loss 2.231 | nll_loss 0.677 | ppl 1.6 | wps 141648 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2239 | lr 0.000422671 | gnorm 0.159 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2263\n",
            "2023-12-04 20:51:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 562:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:54 | INFO | fairseq.trainer | begin training epoch 562\n",
            "2023-12-04 20:51:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:57 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)\n",
            "2023-12-04 20:51:57 | INFO | train | epoch 562 | loss 2.231 | nll_loss 0.674 | ppl 1.6 | wps 140425 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2243 | lr 0.000422294 | gnorm 0.171 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2265\n",
            "2023-12-04 20:51:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 563:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:57 | INFO | fairseq.trainer | begin training epoch 563\n",
            "2023-12-04 20:51:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:51:59 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)\n",
            "2023-12-04 20:51:59 | INFO | train | epoch 563 | loss 2.228 | nll_loss 0.675 | ppl 1.6 | wps 142149 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2247 | lr 0.000421918 | gnorm 0.174 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2268\n",
            "2023-12-04 20:51:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 564:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:51:59 | INFO | fairseq.trainer | begin training epoch 564\n",
            "2023-12-04 20:51:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:02 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)\n",
            "2023-12-04 20:52:02 | INFO | train | epoch 564 | loss 2.23 | nll_loss 0.674 | ppl 1.6 | wps 144010 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2251 | lr 0.000421543 | gnorm 0.174 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2270\n",
            "2023-12-04 20:52:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 565:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:02 | INFO | fairseq.trainer | begin training epoch 565\n",
            "2023-12-04 20:52:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:04 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)\n",
            "2023-12-04 20:52:04 | INFO | train | epoch 565 | loss 2.228 | nll_loss 0.676 | ppl 1.6 | wps 143180 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2255 | lr 0.000421169 | gnorm 0.173 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2273\n",
            "2023-12-04 20:52:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 566:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:04 | INFO | fairseq.trainer | begin training epoch 566\n",
            "2023-12-04 20:52:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:06 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)\n",
            "2023-12-04 20:52:06 | INFO | train | epoch 566 | loss 2.226 | nll_loss 0.67 | ppl 1.59 | wps 142216 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2259 | lr 0.000420796 | gnorm 0.17 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2275\n",
            "2023-12-04 20:52:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 567:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:06 | INFO | fairseq.trainer | begin training epoch 567\n",
            "2023-12-04 20:52:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:09 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)\n",
            "2023-12-04 20:52:09 | INFO | train | epoch 567 | loss 2.226 | nll_loss 0.671 | ppl 1.59 | wps 139182 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2263 | lr 0.000420424 | gnorm 0.164 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2278\n",
            "2023-12-04 20:52:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 568:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:09 | INFO | fairseq.trainer | begin training epoch 568\n",
            "2023-12-04 20:52:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:11 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)\n",
            "2023-12-04 20:52:11 | INFO | train | epoch 568 | loss 2.224 | nll_loss 0.669 | ppl 1.59 | wps 141391 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2267 | lr 0.000420053 | gnorm 0.166 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2280\n",
            "2023-12-04 20:52:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 569:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:11 | INFO | fairseq.trainer | begin training epoch 569\n",
            "2023-12-04 20:52:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:14 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)\n",
            "2023-12-04 20:52:14 | INFO | train | epoch 569 | loss 2.223 | nll_loss 0.669 | ppl 1.59 | wps 142260 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2271 | lr 0.000419683 | gnorm 0.161 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2282\n",
            "2023-12-04 20:52:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 570:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:14 | INFO | fairseq.trainer | begin training epoch 570\n",
            "2023-12-04 20:52:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 570:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 20:52:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:52:17 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan releui ascì che i tasci in çircostanse.\n",
            "2023-12-04 20:52:17 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 20:52:19 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:52:19 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 20:52:21 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de çibboin ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:52:21 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 20:52:23 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Nwang Namgyal.\n",
            "2023-12-04 20:52:23 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 20:52:25 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ in sce l’Internet ò inte l’Internet ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:52:25 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 20:52:26 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): in sce sti 75.68 km (2917373 quaddræ) in sce l’Asia sud-òvest de Ponente, 2376 (29173 d’ancheu (e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:52:26 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 20:52:28 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in graddo attia de 5.00.000 vixitatoî unichi, into meise de öse d'ottobre, inserçioin personali, un network de nozieh, 24 etlante, ciammou Duceante, Wombur de Ombur.\n",
            "2023-12-04 20:52:28 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 570 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.77s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:52:28 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 6.404 | nll_loss 5.162 | ppl 35.8 | bleu 12.72 | wps 4177 | wpb 7753.9 | bsz 142.4 | num_updates 2275 | best_bleu 12.73\n",
            "2023-12-04 20:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 2275 updates\n",
            "2023-12-04 20:52:28 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint570.pt\n",
            "2023-12-04 20:52:29 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint570.pt\n",
            "2023-12-04 20:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint570.pt (epoch 570 @ 2275 updates, score 12.72) (writing took 2.117540270000063 seconds)\n",
            "2023-12-04 20:52:30 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)\n",
            "2023-12-04 20:52:30 | INFO | train | epoch 570 | loss 2.223 | nll_loss 0.668 | ppl 1.59 | wps 20620.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2275 | lr 0.000419314 | gnorm 0.162 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2299\n",
            "2023-12-04 20:52:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 571:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:30 | INFO | fairseq.trainer | begin training epoch 571\n",
            "2023-12-04 20:52:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:33 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)\n",
            "2023-12-04 20:52:33 | INFO | train | epoch 571 | loss 2.217 | nll_loss 0.662 | ppl 1.58 | wps 138743 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2279 | lr 0.000418946 | gnorm 0.156 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2302\n",
            "2023-12-04 20:52:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 572:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:33 | INFO | fairseq.trainer | begin training epoch 572\n",
            "2023-12-04 20:52:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:35 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)\n",
            "2023-12-04 20:52:35 | INFO | train | epoch 572 | loss 2.218 | nll_loss 0.663 | ppl 1.58 | wps 139244 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2283 | lr 0.000418579 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2304\n",
            "2023-12-04 20:52:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 573:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:35 | INFO | fairseq.trainer | begin training epoch 573\n",
            "2023-12-04 20:52:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:38 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)\n",
            "2023-12-04 20:52:38 | INFO | train | epoch 573 | loss 2.216 | nll_loss 0.66 | ppl 1.58 | wps 142071 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2287 | lr 0.000418212 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2306\n",
            "2023-12-04 20:52:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 574:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:38 | INFO | fairseq.trainer | begin training epoch 574\n",
            "2023-12-04 20:52:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:40 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)\n",
            "2023-12-04 20:52:40 | INFO | train | epoch 574 | loss 2.217 | nll_loss 0.663 | ppl 1.58 | wps 142005 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2291 | lr 0.000417847 | gnorm 0.157 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2309\n",
            "2023-12-04 20:52:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 575:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:40 | INFO | fairseq.trainer | begin training epoch 575\n",
            "2023-12-04 20:52:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:43 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)\n",
            "2023-12-04 20:52:43 | INFO | train | epoch 575 | loss 2.216 | nll_loss 0.661 | ppl 1.58 | wps 141967 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2295 | lr 0.000417483 | gnorm 0.157 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2311\n",
            "2023-12-04 20:52:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 576:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:43 | INFO | fairseq.trainer | begin training epoch 576\n",
            "2023-12-04 20:52:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:45 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)\n",
            "2023-12-04 20:52:45 | INFO | train | epoch 576 | loss 2.212 | nll_loss 0.656 | ppl 1.58 | wps 142218 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2299 | lr 0.00041712 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2314\n",
            "2023-12-04 20:52:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 577:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:45 | INFO | fairseq.trainer | begin training epoch 577\n",
            "2023-12-04 20:52:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:47 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)\n",
            "2023-12-04 20:52:47 | INFO | train | epoch 577 | loss 2.212 | nll_loss 0.657 | ppl 1.58 | wps 141296 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2303 | lr 0.000416757 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2316\n",
            "2023-12-04 20:52:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 578:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:47 | INFO | fairseq.trainer | begin training epoch 578\n",
            "2023-12-04 20:52:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:50 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)\n",
            "2023-12-04 20:52:50 | INFO | train | epoch 578 | loss 2.211 | nll_loss 0.654 | ppl 1.57 | wps 141559 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2307 | lr 0.000416396 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2319\n",
            "2023-12-04 20:52:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 579:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:50 | INFO | fairseq.trainer | begin training epoch 579\n",
            "2023-12-04 20:52:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:52:52 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)\n",
            "2023-12-04 20:52:52 | INFO | train | epoch 579 | loss 2.209 | nll_loss 0.656 | ppl 1.58 | wps 143013 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2311 | lr 0.000416035 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2321\n",
            "2023-12-04 20:52:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 580:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:52:52 | INFO | fairseq.trainer | begin training epoch 580\n",
            "2023-12-04 20:52:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 580:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 20:52:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:52:56 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:52:56 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 20:52:58 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin semanæ struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:52:58 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.69s/it]\u001b[A2023-12-04 20:53:00 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibboin ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:53:00 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.68s/it]\u001b[A2023-12-04 20:53:01 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Nwang Namgyal.\n",
            "2023-12-04 20:53:01 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.76s/it]\u001b[A2023-12-04 20:53:04 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ inte l’Internet ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:53:04 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.91s/it]\u001b[A2023-12-04 20:53:05 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 km (29173 mescciæ into quaddræ) in sce l’Asia sud-òvest de Ponente, 23764 (29173 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:53:05 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 20:53:07 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scitoweb in sciô graddo de attia 5.000.000 vixitatoî de unichi, into meise d'ottobre, inserçioin personali, un network de nozieh 24 estlante, ch'o l'é stæto lasciou into mondo de Ombur, ciammou Duce.\n",
            "2023-12-04 20:53:07 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 580 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:53:07 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 6.415 | nll_loss 5.176 | ppl 36.15 | bleu 12.61 | wps 4125.7 | wpb 7753.9 | bsz 142.4 | num_updates 2315 | best_bleu 12.73\n",
            "2023-12-04 20:53:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 2315 updates\n",
            "2023-12-04 20:53:07 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint580.pt\n",
            "2023-12-04 20:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint580.pt\n",
            "2023-12-04 20:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint580.pt (epoch 580 @ 2315 updates, score 12.61) (writing took 2.1149979689998872 seconds)\n",
            "2023-12-04 20:53:09 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)\n",
            "2023-12-04 20:53:09 | INFO | train | epoch 580 | loss 2.208 | nll_loss 0.652 | ppl 1.57 | wps 20430.7 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2315 | lr 0.000415676 | gnorm 0.153 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2338\n",
            "2023-12-04 20:53:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 581:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:09 | INFO | fairseq.trainer | begin training epoch 581\n",
            "2023-12-04 20:53:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:11 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)\n",
            "2023-12-04 20:53:11 | INFO | train | epoch 581 | loss 2.206 | nll_loss 0.65 | ppl 1.57 | wps 139644 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2319 | lr 0.000415317 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2340\n",
            "2023-12-04 20:53:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 582:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:12 | INFO | fairseq.trainer | begin training epoch 582\n",
            "2023-12-04 20:53:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:14 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)\n",
            "2023-12-04 20:53:14 | INFO | train | epoch 582 | loss 2.208 | nll_loss 0.654 | ppl 1.57 | wps 140799 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2323 | lr 0.000414959 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2343\n",
            "2023-12-04 20:53:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 583:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:14 | INFO | fairseq.trainer | begin training epoch 583\n",
            "2023-12-04 20:53:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:16 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)\n",
            "2023-12-04 20:53:16 | INFO | train | epoch 583 | loss 2.207 | nll_loss 0.651 | ppl 1.57 | wps 142926 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2327 | lr 0.000414602 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2345\n",
            "2023-12-04 20:53:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 584:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:16 | INFO | fairseq.trainer | begin training epoch 584\n",
            "2023-12-04 20:53:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:19 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)\n",
            "2023-12-04 20:53:19 | INFO | train | epoch 584 | loss 2.205 | nll_loss 0.65 | ppl 1.57 | wps 140880 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2331 | lr 0.000414247 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2347\n",
            "2023-12-04 20:53:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 585:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:19 | INFO | fairseq.trainer | begin training epoch 585\n",
            "2023-12-04 20:53:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:21 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)\n",
            "2023-12-04 20:53:21 | INFO | train | epoch 585 | loss 2.203 | nll_loss 0.646 | ppl 1.56 | wps 141555 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2335 | lr 0.000413892 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2350\n",
            "2023-12-04 20:53:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 586:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:21 | INFO | fairseq.trainer | begin training epoch 586\n",
            "2023-12-04 20:53:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:24 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)\n",
            "2023-12-04 20:53:24 | INFO | train | epoch 586 | loss 2.203 | nll_loss 0.648 | ppl 1.57 | wps 141866 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2339 | lr 0.000413537 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2352\n",
            "2023-12-04 20:53:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 587:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:24 | INFO | fairseq.trainer | begin training epoch 587\n",
            "2023-12-04 20:53:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:26 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)\n",
            "2023-12-04 20:53:26 | INFO | train | epoch 587 | loss 2.203 | nll_loss 0.647 | ppl 1.57 | wps 140978 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2343 | lr 0.000413184 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2355\n",
            "2023-12-04 20:53:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 588:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:26 | INFO | fairseq.trainer | begin training epoch 588\n",
            "2023-12-04 20:53:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:29 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)\n",
            "2023-12-04 20:53:29 | INFO | train | epoch 588 | loss 2.203 | nll_loss 0.648 | ppl 1.57 | wps 140772 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2347 | lr 0.000412832 | gnorm 0.16 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2357\n",
            "2023-12-04 20:53:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 589:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:29 | INFO | fairseq.trainer | begin training epoch 589\n",
            "2023-12-04 20:53:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:31 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)\n",
            "2023-12-04 20:53:31 | INFO | train | epoch 589 | loss 2.203 | nll_loss 0.647 | ppl 1.57 | wps 143371 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2351 | lr 0.000412481 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2360\n",
            "2023-12-04 20:53:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 590:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:31 | INFO | fairseq.trainer | begin training epoch 590\n",
            "2023-12-04 20:53:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 590:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 20:53:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:53:35 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:53:35 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.50s/it]\u001b[A2023-12-04 20:53:36 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:53:36 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.56s/it]\u001b[A2023-12-04 20:53:38 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ da çerti ponti an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:53:38 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.64s/it]\u001b[A2023-12-04 20:53:40 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:53:40 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 20:53:42 | INFO | fairseq.tasks.translation | example hypothesis: O l’é bon che o vòstro hotel o vostro òspite (in caxo sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ in sce l’Internet ò inte l’Internet ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:53:42 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 20:53:44 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): in sce sti 75.68 de km (2917373 quaddræ) in sce l’Asia sud-òvest de Ponente, 23764 (29173), ch’a l’à miggiæ in Euröpa) inte l’Asia sud-òvest, e 23764.\n",
            "2023-12-04 20:53:44 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 20:53:45 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ de 5.00.000 vixitatoî unichi, into meise de l'ottobre, inserçioin personali, un network de nozieh, 24 ch'o l'é stæto lasciou do mondo a-o Ducea Woldur, ch'à ciammou ombur.\n",
            "2023-12-04 20:53:45 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 590 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:53:45 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 6.423 | nll_loss 5.189 | ppl 36.47 | bleu 12.6 | wps 4157.2 | wpb 7753.9 | bsz 142.4 | num_updates 2355 | best_bleu 12.73\n",
            "2023-12-04 20:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 2355 updates\n",
            "2023-12-04 20:53:45 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint590.pt\n",
            "2023-12-04 20:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint590.pt\n",
            "2023-12-04 20:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint590.pt (epoch 590 @ 2355 updates, score 12.6) (writing took 2.1299048830001084 seconds)\n",
            "2023-12-04 20:53:48 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)\n",
            "2023-12-04 20:53:48 | INFO | train | epoch 590 | loss 2.199 | nll_loss 0.643 | ppl 1.56 | wps 20465.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2355 | lr 0.00041213 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2376\n",
            "2023-12-04 20:53:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 591:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:48 | INFO | fairseq.trainer | begin training epoch 591\n",
            "2023-12-04 20:53:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:50 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)\n",
            "2023-12-04 20:53:50 | INFO | train | epoch 591 | loss 2.201 | nll_loss 0.645 | ppl 1.56 | wps 137264 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 2359 | lr 0.000411781 | gnorm 0.16 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2379\n",
            "2023-12-04 20:53:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 592:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:50 | INFO | fairseq.trainer | begin training epoch 592\n",
            "2023-12-04 20:53:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:53 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)\n",
            "2023-12-04 20:53:53 | INFO | train | epoch 592 | loss 2.201 | nll_loss 0.647 | ppl 1.57 | wps 140819 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2363 | lr 0.000411432 | gnorm 0.159 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2381\n",
            "2023-12-04 20:53:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 593:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:53 | INFO | fairseq.trainer | begin training epoch 593\n",
            "2023-12-04 20:53:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:55 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)\n",
            "2023-12-04 20:53:55 | INFO | train | epoch 593 | loss 2.199 | nll_loss 0.643 | ppl 1.56 | wps 145145 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2367 | lr 0.000411084 | gnorm 0.163 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2384\n",
            "2023-12-04 20:53:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 594:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:55 | INFO | fairseq.trainer | begin training epoch 594\n",
            "2023-12-04 20:53:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:53:57 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)\n",
            "2023-12-04 20:53:57 | INFO | train | epoch 594 | loss 2.199 | nll_loss 0.642 | ppl 1.56 | wps 141481 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2371 | lr 0.000410737 | gnorm 0.16 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2386\n",
            "2023-12-04 20:53:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 595:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:53:57 | INFO | fairseq.trainer | begin training epoch 595\n",
            "2023-12-04 20:53:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:00 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)\n",
            "2023-12-04 20:54:00 | INFO | train | epoch 595 | loss 2.197 | nll_loss 0.642 | ppl 1.56 | wps 141718 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2375 | lr 0.000410391 | gnorm 0.165 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2389\n",
            "2023-12-04 20:54:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 596:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:00 | INFO | fairseq.trainer | begin training epoch 596\n",
            "2023-12-04 20:54:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:02 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)\n",
            "2023-12-04 20:54:02 | INFO | train | epoch 596 | loss 2.195 | nll_loss 0.64 | ppl 1.56 | wps 141843 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2379 | lr 0.000410046 | gnorm 0.156 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2391\n",
            "2023-12-04 20:54:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 597:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:02 | INFO | fairseq.trainer | begin training epoch 597\n",
            "2023-12-04 20:54:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:05 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)\n",
            "2023-12-04 20:54:05 | INFO | train | epoch 597 | loss 2.193 | nll_loss 0.637 | ppl 1.56 | wps 141962 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2383 | lr 0.000409702 | gnorm 0.153 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2393\n",
            "2023-12-04 20:54:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 598:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:05 | INFO | fairseq.trainer | begin training epoch 598\n",
            "2023-12-04 20:54:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:07 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)\n",
            "2023-12-04 20:54:07 | INFO | train | epoch 598 | loss 2.195 | nll_loss 0.639 | ppl 1.56 | wps 143622 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2387 | lr 0.000409358 | gnorm 0.153 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2396\n",
            "2023-12-04 20:54:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 599:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:07 | INFO | fairseq.trainer | begin training epoch 599\n",
            "2023-12-04 20:54:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:10 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)\n",
            "2023-12-04 20:54:10 | INFO | train | epoch 599 | loss 2.192 | nll_loss 0.635 | ppl 1.55 | wps 141581 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2391 | lr 0.000409016 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2398\n",
            "2023-12-04 20:54:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 600:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:10 | INFO | fairseq.trainer | begin training epoch 600\n",
            "2023-12-04 20:54:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 600:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 20:54:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:54:13 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:54:13 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 20:54:15 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:54:15 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.53s/it]\u001b[A2023-12-04 20:54:17 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibinti. Al òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:54:17 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.62s/it]\u001b[A2023-12-04 20:54:19 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dsong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:54:19 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 20:54:21 | INFO | fairseq.tasks.translation | example hypothesis: O l’é bon che o vòstro hotel o vostro òspite (in caxo sovitessa sorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ in sce l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:54:21 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.87s/it]\u001b[A2023-12-04 20:54:22 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 de km (29173 quaddræ) in sce l’Asia sud-òvest, ch’a l’é 2376 (29173 d’Euröpa quaddræ) inte l’Asia sud-òvest, e 23764 (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:54:22 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 20:54:24 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî unichi, into meise de öse d'ottobre, inserçioin personali, un neorkwork de noçieh, 24 etlante, ch'o l'é stæto lasciou do tutto o nomme de Ombur.\n",
            "2023-12-04 20:54:24 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 600 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.78s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:54:24 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 6.422 | nll_loss 5.19 | ppl 36.52 | bleu 12.63 | wps 4138.1 | wpb 7753.9 | bsz 142.4 | num_updates 2395 | best_bleu 12.73\n",
            "2023-12-04 20:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 2395 updates\n",
            "2023-12-04 20:54:24 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint600.pt\n",
            "2023-12-04 20:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint600.pt\n",
            "2023-12-04 20:54:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint600.pt (epoch 600 @ 2395 updates, score 12.63) (writing took 2.1358356890000323 seconds)\n",
            "2023-12-04 20:54:26 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)\n",
            "2023-12-04 20:54:26 | INFO | train | epoch 600 | loss 2.19 | nll_loss 0.635 | ppl 1.55 | wps 20416.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2395 | lr 0.000408674 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2415\n",
            "2023-12-04 20:54:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 601:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:26 | INFO | fairseq.trainer | begin training epoch 601\n",
            "2023-12-04 20:54:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:29 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)\n",
            "2023-12-04 20:54:29 | INFO | train | epoch 601 | loss 2.19 | nll_loss 0.633 | ppl 1.55 | wps 137080 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 2399 | lr 0.000408333 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2418\n",
            "2023-12-04 20:54:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 602:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:29 | INFO | fairseq.trainer | begin training epoch 602\n",
            "2023-12-04 20:54:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:31 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)\n",
            "2023-12-04 20:54:31 | INFO | train | epoch 602 | loss 2.189 | nll_loss 0.634 | ppl 1.55 | wps 144160 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2403 | lr 0.000407993 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2420\n",
            "2023-12-04 20:54:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 603:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:31 | INFO | fairseq.trainer | begin training epoch 603\n",
            "2023-12-04 20:54:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:34 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)\n",
            "2023-12-04 20:54:34 | INFO | train | epoch 603 | loss 2.186 | nll_loss 0.63 | ppl 1.55 | wps 141643 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2407 | lr 0.000407654 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2422\n",
            "2023-12-04 20:54:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 604:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:34 | INFO | fairseq.trainer | begin training epoch 604\n",
            "2023-12-04 20:54:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:36 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)\n",
            "2023-12-04 20:54:36 | INFO | train | epoch 604 | loss 2.189 | nll_loss 0.633 | ppl 1.55 | wps 142124 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2411 | lr 0.000407316 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2425\n",
            "2023-12-04 20:54:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 605:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:36 | INFO | fairseq.trainer | begin training epoch 605\n",
            "2023-12-04 20:54:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:39 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)\n",
            "2023-12-04 20:54:39 | INFO | train | epoch 605 | loss 2.186 | nll_loss 0.632 | ppl 1.55 | wps 141359 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2415 | lr 0.000406978 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2427\n",
            "2023-12-04 20:54:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 606:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:39 | INFO | fairseq.trainer | begin training epoch 606\n",
            "2023-12-04 20:54:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:41 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)\n",
            "2023-12-04 20:54:41 | INFO | train | epoch 606 | loss 2.185 | nll_loss 0.628 | ppl 1.55 | wps 140998 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2419 | lr 0.000406642 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2430\n",
            "2023-12-04 20:54:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 607:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:41 | INFO | fairseq.trainer | begin training epoch 607\n",
            "2023-12-04 20:54:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:43 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)\n",
            "2023-12-04 20:54:43 | INFO | train | epoch 607 | loss 2.185 | nll_loss 0.629 | ppl 1.55 | wps 144423 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2423 | lr 0.000406306 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2432\n",
            "2023-12-04 20:54:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 608:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:43 | INFO | fairseq.trainer | begin training epoch 608\n",
            "2023-12-04 20:54:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:46 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)\n",
            "2023-12-04 20:54:46 | INFO | train | epoch 608 | loss 2.186 | nll_loss 0.631 | ppl 1.55 | wps 144733 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2427 | lr 0.000405971 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2434\n",
            "2023-12-04 20:54:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 609:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:46 | INFO | fairseq.trainer | begin training epoch 609\n",
            "2023-12-04 20:54:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:54:48 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)\n",
            "2023-12-04 20:54:48 | INFO | train | epoch 609 | loss 2.182 | nll_loss 0.625 | ppl 1.54 | wps 142216 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2431 | lr 0.000405637 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2437\n",
            "2023-12-04 20:54:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 610:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:54:48 | INFO | fairseq.trainer | begin training epoch 610\n",
            "2023-12-04 20:54:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 610:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:54:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:54:52 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:54:52 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.50s/it]\u001b[A2023-12-04 20:54:54 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settemanæ de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:54:54 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.54s/it]\u001b[A2023-12-04 20:54:55 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibinti. Al òffiti an fornio à microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:54:55 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 20:54:57 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:54:57 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 20:54:59 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro ospite (in caxo sovitessa sorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o troveva inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:54:59 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 20:55:01 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): de sti 75.68 km (29173 mescciæ) sensæ inte l’Asia sud-òvest, ch’o l’à 23764 (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:55:01 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 20:55:03 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web inte di atti de 5.00.00 vixitatoî unichi into mesegno d'ottobre, inserçioin personali, un neorkwork de 24 ch'o l'é stæto lasciou do mondo etlante, ciammou Ombur de Ducea or.\n",
            "2023-12-04 20:55:03 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 610 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:55:03 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 6.426 | nll_loss 5.197 | ppl 36.67 | bleu 12.61 | wps 4229.1 | wpb 7753.9 | bsz 142.4 | num_updates 2435 | best_bleu 12.73\n",
            "2023-12-04 20:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 2435 updates\n",
            "2023-12-04 20:55:03 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint610.pt\n",
            "2023-12-04 20:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint610.pt\n",
            "2023-12-04 20:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint610.pt (epoch 610 @ 2435 updates, score 12.61) (writing took 2.13959211700012 seconds)\n",
            "2023-12-04 20:55:05 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)\n",
            "2023-12-04 20:55:05 | INFO | train | epoch 610 | loss 2.184 | nll_loss 0.629 | ppl 1.55 | wps 20663.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2435 | lr 0.000405304 | gnorm 0.153 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2453\n",
            "2023-12-04 20:55:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 611:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:05 | INFO | fairseq.trainer | begin training epoch 611\n",
            "2023-12-04 20:55:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:07 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)\n",
            "2023-12-04 20:55:07 | INFO | train | epoch 611 | loss 2.185 | nll_loss 0.628 | ppl 1.55 | wps 139596 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2439 | lr 0.000404971 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2456\n",
            "2023-12-04 20:55:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 612:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:07 | INFO | fairseq.trainer | begin training epoch 612\n",
            "2023-12-04 20:55:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:10 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)\n",
            "2023-12-04 20:55:10 | INFO | train | epoch 612 | loss 2.182 | nll_loss 0.627 | ppl 1.54 | wps 141715 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2443 | lr 0.000404639 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2458\n",
            "2023-12-04 20:55:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 613:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:10 | INFO | fairseq.trainer | begin training epoch 613\n",
            "2023-12-04 20:55:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:12 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)\n",
            "2023-12-04 20:55:12 | INFO | train | epoch 613 | loss 2.18 | nll_loss 0.624 | ppl 1.54 | wps 141603 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2447 | lr 0.000404309 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2461\n",
            "2023-12-04 20:55:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 614:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:12 | INFO | fairseq.trainer | begin training epoch 614\n",
            "2023-12-04 20:55:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:14 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)\n",
            "2023-12-04 20:55:14 | INFO | train | epoch 614 | loss 2.179 | nll_loss 0.622 | ppl 1.54 | wps 143662 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2451 | lr 0.000403979 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2463\n",
            "2023-12-04 20:55:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 615:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:15 | INFO | fairseq.trainer | begin training epoch 615\n",
            "2023-12-04 20:55:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:17 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)\n",
            "2023-12-04 20:55:17 | INFO | train | epoch 615 | loss 2.179 | nll_loss 0.625 | ppl 1.54 | wps 140740 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2455 | lr 0.000403649 | gnorm 0.168 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2466\n",
            "2023-12-04 20:55:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 616:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:17 | INFO | fairseq.trainer | begin training epoch 616\n",
            "2023-12-04 20:55:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:19 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)\n",
            "2023-12-04 20:55:19 | INFO | train | epoch 616 | loss 2.19 | nll_loss 0.636 | ppl 1.55 | wps 141870 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2459 | lr 0.000403321 | gnorm 0.204 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2468\n",
            "2023-12-04 20:55:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 617:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:19 | INFO | fairseq.trainer | begin training epoch 617\n",
            "2023-12-04 20:55:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:22 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)\n",
            "2023-12-04 20:55:22 | INFO | train | epoch 617 | loss 2.193 | nll_loss 0.64 | ppl 1.56 | wps 142650 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2463 | lr 0.000402993 | gnorm 0.199 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2470\n",
            "2023-12-04 20:55:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 618:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:22 | INFO | fairseq.trainer | begin training epoch 618\n",
            "2023-12-04 20:55:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:24 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)\n",
            "2023-12-04 20:55:24 | INFO | train | epoch 618 | loss 2.19 | nll_loss 0.636 | ppl 1.55 | wps 142005 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2467 | lr 0.000402666 | gnorm 0.184 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2473\n",
            "2023-12-04 20:55:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 619:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:24 | INFO | fairseq.trainer | begin training epoch 619\n",
            "2023-12-04 20:55:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:27 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)\n",
            "2023-12-04 20:55:27 | INFO | train | epoch 619 | loss 2.181 | nll_loss 0.625 | ppl 1.54 | wps 143663 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2471 | lr 0.00040234 | gnorm 0.178 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2475\n",
            "2023-12-04 20:55:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 620:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:27 | INFO | fairseq.trainer | begin training epoch 620\n",
            "2023-12-04 20:55:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 620:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 20:55:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:55:30 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:55:30 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 20:55:32 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin semanæ de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:55:32 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.53s/it]\u001b[A2023-12-04 20:55:34 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de gibinti. Alfæn an produto di microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 20:55:34 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 20:55:35 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dsong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:55:35 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.79s/it]\u001b[A2023-12-04 20:55:38 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vòstro hotel o vostro òspite (in caxo sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; ascì pe de ciù o trovâ inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:55:38 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.90s/it]\u001b[A2023-12-04 20:55:39 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 km (29173 mescciæ) seræ inte l’Asia sud-òvest, ch’o l’à 23764 (29173 d’etæ quaddræ) in Euröpa.\n",
            "2023-12-04 20:55:39 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.77s/it]\u001b[A2023-12-04 20:55:41 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de l'ottobre, inserçioin personali, un neorkwork de nozieh, 24 ch'o l'é stæto lasciou into mondo de Duceante.\n",
            "2023-12-04 20:55:41 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 620 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:55:41 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 6.419 | nll_loss 5.183 | ppl 36.33 | bleu 12.59 | wps 4189.9 | wpb 7753.9 | bsz 142.4 | num_updates 2475 | best_bleu 12.73\n",
            "2023-12-04 20:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 2475 updates\n",
            "2023-12-04 20:55:41 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint620.pt\n",
            "2023-12-04 20:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint620.pt\n",
            "2023-12-04 20:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint620.pt (epoch 620 @ 2475 updates, score 12.59) (writing took 2.1296432430003733 seconds)\n",
            "2023-12-04 20:55:43 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)\n",
            "2023-12-04 20:55:43 | INFO | train | epoch 620 | loss 2.184 | nll_loss 0.632 | ppl 1.55 | wps 20601.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2475 | lr 0.000402015 | gnorm 0.171 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2492\n",
            "2023-12-04 20:55:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 621:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:43 | INFO | fairseq.trainer | begin training epoch 621\n",
            "2023-12-04 20:55:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:46 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)\n",
            "2023-12-04 20:55:46 | INFO | train | epoch 621 | loss 2.179 | nll_loss 0.621 | ppl 1.54 | wps 139148 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2479 | lr 0.000401691 | gnorm 0.165 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2494\n",
            "2023-12-04 20:55:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 622:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:46 | INFO | fairseq.trainer | begin training epoch 622\n",
            "2023-12-04 20:55:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:48 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)\n",
            "2023-12-04 20:55:48 | INFO | train | epoch 622 | loss 2.175 | nll_loss 0.62 | ppl 1.54 | wps 142322 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2483 | lr 0.000401367 | gnorm 0.159 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2497\n",
            "2023-12-04 20:55:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 623:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:48 | INFO | fairseq.trainer | begin training epoch 623\n",
            "2023-12-04 20:55:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:51 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)\n",
            "2023-12-04 20:55:51 | INFO | train | epoch 623 | loss 2.176 | nll_loss 0.621 | ppl 1.54 | wps 142353 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2487 | lr 0.000401044 | gnorm 0.159 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2499\n",
            "2023-12-04 20:55:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 624:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:51 | INFO | fairseq.trainer | begin training epoch 624\n",
            "2023-12-04 20:55:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:53 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)\n",
            "2023-12-04 20:55:53 | INFO | train | epoch 624 | loss 2.171 | nll_loss 0.615 | ppl 1.53 | wps 140486 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2491 | lr 0.000400722 | gnorm 0.165 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2502\n",
            "2023-12-04 20:55:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 625:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:53 | INFO | fairseq.trainer | begin training epoch 625\n",
            "2023-12-04 20:55:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:55 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)\n",
            "2023-12-04 20:55:55 | INFO | train | epoch 625 | loss 2.17 | nll_loss 0.614 | ppl 1.53 | wps 141557 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2495 | lr 0.000400401 | gnorm 0.157 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2504\n",
            "2023-12-04 20:55:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 626:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:55 | INFO | fairseq.trainer | begin training epoch 626\n",
            "2023-12-04 20:55:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:55:58 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)\n",
            "2023-12-04 20:55:58 | INFO | train | epoch 626 | loss 2.172 | nll_loss 0.616 | ppl 1.53 | wps 143998 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2499 | lr 0.00040008 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2506\n",
            "2023-12-04 20:55:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 627:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:55:58 | INFO | fairseq.trainer | begin training epoch 627\n",
            "2023-12-04 20:55:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:00 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)\n",
            "2023-12-04 20:56:00 | INFO | train | epoch 627 | loss 2.167 | nll_loss 0.611 | ppl 1.53 | wps 141917 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2503 | lr 0.00039976 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2509\n",
            "2023-12-04 20:56:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 628:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:00 | INFO | fairseq.trainer | begin training epoch 628\n",
            "2023-12-04 20:56:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:03 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)\n",
            "2023-12-04 20:56:03 | INFO | train | epoch 628 | loss 2.164 | nll_loss 0.608 | ppl 1.52 | wps 144041 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2507 | lr 0.000399441 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2511\n",
            "2023-12-04 20:56:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 629:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:03 | INFO | fairseq.trainer | begin training epoch 629\n",
            "2023-12-04 20:56:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:05 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)\n",
            "2023-12-04 20:56:05 | INFO | train | epoch 629 | loss 2.165 | nll_loss 0.609 | ppl 1.53 | wps 143199 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2511 | lr 0.000399123 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2514\n",
            "2023-12-04 20:56:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 630:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:05 | INFO | fairseq.trainer | begin training epoch 630\n",
            "2023-12-04 20:56:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 630:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:56:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:56:09 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:56:09 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 20:56:10 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settemanæ de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:56:10 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.49s/it]\u001b[A2023-12-04 20:56:12 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ da çerti ponti, an produto di additi microonde ò di atri mezi pe rescäda o mangiâ.\n",
            "2023-12-04 20:56:12 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 20:56:14 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:56:14 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.67s/it]\u001b[A2023-12-04 20:56:16 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vostro hotel o vostro òspite (isòtta sovitessa sorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; ascì in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:56:16 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.83s/it]\u001b[A2023-12-04 20:56:18 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 de km (29173 quaddræ) in sce l'Asia sud-òvest, 5.68 km (29173), ch'a l'é collocâ Euröpa quaddræ) inte l'Asia sud-òvest, e 23764 (174 d'Euröpa).\n",
            "2023-12-04 20:56:18 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 20:56:19 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scitoweb pe attiâ de 5.00.000 vixitatoî unichi meise de l'ottobre, inserçioin personali, un network de nozieh 24 ch'o l'é stæto lasciou da-o mondo est, ciammou Ducea Ombur de Duoldur.\n",
            "2023-12-04 20:56:19 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 630 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.75s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:56:19 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 6.42 | nll_loss 5.197 | ppl 36.68 | bleu 12.68 | wps 4221.5 | wpb 7753.9 | bsz 142.4 | num_updates 2515 | best_bleu 12.73\n",
            "2023-12-04 20:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 2515 updates\n",
            "2023-12-04 20:56:19 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint630.pt\n",
            "2023-12-04 20:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint630.pt\n",
            "2023-12-04 20:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint630.pt (epoch 630 @ 2515 updates, score 12.68) (writing took 2.112159346000226 seconds)\n",
            "2023-12-04 20:56:22 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)\n",
            "2023-12-04 20:56:22 | INFO | train | epoch 630 | loss 2.162 | nll_loss 0.606 | ppl 1.52 | wps 20768.7 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2515 | lr 0.000398805 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2530\n",
            "2023-12-04 20:56:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 631:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:22 | INFO | fairseq.trainer | begin training epoch 631\n",
            "2023-12-04 20:56:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:24 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)\n",
            "2023-12-04 20:56:24 | INFO | train | epoch 631 | loss 2.164 | nll_loss 0.608 | ppl 1.52 | wps 137049 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 2519 | lr 0.000398489 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2533\n",
            "2023-12-04 20:56:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 632:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:24 | INFO | fairseq.trainer | begin training epoch 632\n",
            "2023-12-04 20:56:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:26 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)\n",
            "2023-12-04 20:56:26 | INFO | train | epoch 632 | loss 2.163 | nll_loss 0.607 | ppl 1.52 | wps 144452 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2523 | lr 0.000398173 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2535\n",
            "2023-12-04 20:56:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 633:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:26 | INFO | fairseq.trainer | begin training epoch 633\n",
            "2023-12-04 20:56:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:29 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)\n",
            "2023-12-04 20:56:29 | INFO | train | epoch 633 | loss 2.163 | nll_loss 0.608 | ppl 1.52 | wps 140068 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2527 | lr 0.000397857 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2538\n",
            "2023-12-04 20:56:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 634:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:29 | INFO | fairseq.trainer | begin training epoch 634\n",
            "2023-12-04 20:56:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:31 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)\n",
            "2023-12-04 20:56:31 | INFO | train | epoch 634 | loss 2.162 | nll_loss 0.605 | ppl 1.52 | wps 142396 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2531 | lr 0.000397543 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2540\n",
            "2023-12-04 20:56:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 635:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:31 | INFO | fairseq.trainer | begin training epoch 635\n",
            "2023-12-04 20:56:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:34 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)\n",
            "2023-12-04 20:56:34 | INFO | train | epoch 635 | loss 2.163 | nll_loss 0.608 | ppl 1.52 | wps 140277 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2535 | lr 0.000397229 | gnorm 0.167 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2542\n",
            "2023-12-04 20:56:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 636:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:34 | INFO | fairseq.trainer | begin training epoch 636\n",
            "2023-12-04 20:56:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:36 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)\n",
            "2023-12-04 20:56:36 | INFO | train | epoch 636 | loss 2.159 | nll_loss 0.602 | ppl 1.52 | wps 142341 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2539 | lr 0.000396916 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2545\n",
            "2023-12-04 20:56:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 637:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:36 | INFO | fairseq.trainer | begin training epoch 637\n",
            "2023-12-04 20:56:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:39 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)\n",
            "2023-12-04 20:56:39 | INFO | train | epoch 637 | loss 2.162 | nll_loss 0.608 | ppl 1.52 | wps 143426 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2543 | lr 0.000396604 | gnorm 0.161 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2547\n",
            "2023-12-04 20:56:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 638:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:39 | INFO | fairseq.trainer | begin training epoch 638\n",
            "2023-12-04 20:56:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:41 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)\n",
            "2023-12-04 20:56:41 | INFO | train | epoch 638 | loss 2.162 | nll_loss 0.607 | ppl 1.52 | wps 144551 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2547 | lr 0.000396292 | gnorm 0.166 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2550\n",
            "2023-12-04 20:56:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 639:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:41 | INFO | fairseq.trainer | begin training epoch 639\n",
            "2023-12-04 20:56:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:56:43 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)\n",
            "2023-12-04 20:56:43 | INFO | train | epoch 639 | loss 2.157 | nll_loss 0.602 | ppl 1.52 | wps 140135 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2551 | lr 0.000395981 | gnorm 0.158 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2552\n",
            "2023-12-04 20:56:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 640:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:56:43 | INFO | fairseq.trainer | begin training epoch 640\n",
            "2023-12-04 20:56:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 640:  75% 3/4 [00:01<00:00,  1.60it/s]2023-12-04 20:56:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:56:47 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, de Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:56:47 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A2023-12-04 20:56:49 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 20:56:49 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 20:56:51 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 20:56:51 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 20:56:52 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:56:52 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 20:56:55 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (in caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte lonquente inte un pòsto caft-Fi pubrico.\n",
            "2023-12-04 20:56:55 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.89s/it]\u001b[A2023-12-04 20:56:56 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 km (29173 quaddræ) in sce l’Asia sud-òvest, ch’o l’à 23764 (29173 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:56:56 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.81s/it]\u001b[A2023-12-04 20:56:58 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.000 vixitatoî unichi into meise de l'ottobre, inserçioin personali, un neorkwork de nozieh, 24 ch'o l'é stæto lasciou do mondo est, ciammou Duceante.\n",
            "2023-12-04 20:56:58 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 640 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:56:58 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 6.416 | nll_loss 5.192 | ppl 36.56 | bleu 12.63 | wps 4183.1 | wpb 7753.9 | bsz 142.4 | num_updates 2555 | best_bleu 12.73\n",
            "2023-12-04 20:56:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 2555 updates\n",
            "2023-12-04 20:56:58 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint640.pt\n",
            "2023-12-04 20:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint640.pt\n",
            "2023-12-04 20:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint640.pt (epoch 640 @ 2555 updates, score 12.63) (writing took 2.1065098529998068 seconds)\n",
            "2023-12-04 20:57:00 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)\n",
            "2023-12-04 20:57:00 | INFO | train | epoch 640 | loss 2.158 | nll_loss 0.602 | ppl 1.52 | wps 20541.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2555 | lr 0.000395671 | gnorm 0.151 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2569\n",
            "2023-12-04 20:57:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 641:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:00 | INFO | fairseq.trainer | begin training epoch 641\n",
            "2023-12-04 20:57:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:03 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)\n",
            "2023-12-04 20:57:03 | INFO | train | epoch 641 | loss 2.157 | nll_loss 0.602 | ppl 1.52 | wps 136697 | ups 1.59 | wpb 85903.8 | bsz 1548.2 | num_updates 2559 | lr 0.000395362 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2571\n",
            "2023-12-04 20:57:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 642:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:03 | INFO | fairseq.trainer | begin training epoch 642\n",
            "2023-12-04 20:57:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:05 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)\n",
            "2023-12-04 20:57:05 | INFO | train | epoch 642 | loss 2.156 | nll_loss 0.6 | ppl 1.52 | wps 141634 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2563 | lr 0.000395053 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2574\n",
            "2023-12-04 20:57:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 643:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:05 | INFO | fairseq.trainer | begin training epoch 643\n",
            "2023-12-04 20:57:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:07 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)\n",
            "2023-12-04 20:57:07 | INFO | train | epoch 643 | loss 2.153 | nll_loss 0.596 | ppl 1.51 | wps 141806 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2567 | lr 0.000394745 | gnorm 0.151 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2576\n",
            "2023-12-04 20:57:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 644:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:08 | INFO | fairseq.trainer | begin training epoch 644\n",
            "2023-12-04 20:57:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:10 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)\n",
            "2023-12-04 20:57:10 | INFO | train | epoch 644 | loss 2.154 | nll_loss 0.599 | ppl 1.52 | wps 142867 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2571 | lr 0.000394438 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2579\n",
            "2023-12-04 20:57:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 645:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:10 | INFO | fairseq.trainer | begin training epoch 645\n",
            "2023-12-04 20:57:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:12 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)\n",
            "2023-12-04 20:57:12 | INFO | train | epoch 645 | loss 2.152 | nll_loss 0.596 | ppl 1.51 | wps 143511 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2575 | lr 0.000394132 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2581\n",
            "2023-12-04 20:57:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 646:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:12 | INFO | fairseq.trainer | begin training epoch 646\n",
            "2023-12-04 20:57:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:15 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)\n",
            "2023-12-04 20:57:15 | INFO | train | epoch 646 | loss 2.152 | nll_loss 0.596 | ppl 1.51 | wps 141185 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2579 | lr 0.000393826 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2583\n",
            "2023-12-04 20:57:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 647:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:15 | INFO | fairseq.trainer | begin training epoch 647\n",
            "2023-12-04 20:57:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:17 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)\n",
            "2023-12-04 20:57:17 | INFO | train | epoch 647 | loss 2.153 | nll_loss 0.598 | ppl 1.51 | wps 141796 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2583 | lr 0.000393521 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2586\n",
            "2023-12-04 20:57:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 648:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:17 | INFO | fairseq.trainer | begin training epoch 648\n",
            "2023-12-04 20:57:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:20 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)\n",
            "2023-12-04 20:57:20 | INFO | train | epoch 648 | loss 2.149 | nll_loss 0.592 | ppl 1.51 | wps 140578 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2587 | lr 0.000393217 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2588\n",
            "2023-12-04 20:57:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 649:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:20 | INFO | fairseq.trainer | begin training epoch 649\n",
            "2023-12-04 20:57:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:22 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)\n",
            "2023-12-04 20:57:22 | INFO | train | epoch 649 | loss 2.148 | nll_loss 0.592 | ppl 1.51 | wps 139662 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2591 | lr 0.000392913 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2591\n",
            "2023-12-04 20:57:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 650:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:22 | INFO | fairseq.trainer | begin training epoch 650\n",
            "2023-12-04 20:57:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 650:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 20:57:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:57:26 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:57:26 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 20:57:27 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:57:27 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 20:57:29 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:57:29 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 20:57:31 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:57:31 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.68s/it]\u001b[A2023-12-04 20:57:33 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unna guæra guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; ascì pe de ciù in sce lonquente ò inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 20:57:33 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 20:57:35 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 de km (29173 quaddræ) in sce l’Asia sud-òvest, 568 km (29173), ch’a l’é quaddrâ in Euröpa) inte l’Asia sud-òvest, e 23764 (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 20:57:35 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.77s/it]\u001b[A2023-12-04 20:57:36 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî de unna meixi ascia into meise d'öo de travaggio, inserçioin personali, un neork de nòrktieh, 24 etlante à Duceante, ciammou Duoldur de Ombur.\n",
            "2023-12-04 20:57:36 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 650 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:57:36 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 6.431 | nll_loss 5.209 | ppl 36.98 | bleu 12.77 | wps 4184.3 | wpb 7753.9 | bsz 142.4 | num_updates 2595 | best_bleu 12.77\n",
            "2023-12-04 20:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 2595 updates\n",
            "2023-12-04 20:57:36 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint650.pt\n",
            "2023-12-04 20:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint650.pt\n",
            "2023-12-04 20:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint650.pt (epoch 650 @ 2595 updates, score 12.77) (writing took 3.8252054439999483 seconds)\n",
            "2023-12-04 20:57:40 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)\n",
            "2023-12-04 20:57:40 | INFO | train | epoch 650 | loss 2.15 | nll_loss 0.594 | ppl 1.51 | wps 18734.3 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 2595 | lr 0.00039261 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2609\n",
            "2023-12-04 20:57:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 651:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:40 | INFO | fairseq.trainer | begin training epoch 651\n",
            "2023-12-04 20:57:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:43 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)\n",
            "2023-12-04 20:57:43 | INFO | train | epoch 651 | loss 2.148 | nll_loss 0.592 | ppl 1.51 | wps 140716 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2599 | lr 0.000392308 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2612\n",
            "2023-12-04 20:57:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 652:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:43 | INFO | fairseq.trainer | begin training epoch 652\n",
            "2023-12-04 20:57:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:45 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)\n",
            "2023-12-04 20:57:45 | INFO | train | epoch 652 | loss 2.145 | nll_loss 0.591 | ppl 1.51 | wps 141088 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2603 | lr 0.000392006 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2614\n",
            "2023-12-04 20:57:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 653:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:45 | INFO | fairseq.trainer | begin training epoch 653\n",
            "2023-12-04 20:57:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:48 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)\n",
            "2023-12-04 20:57:48 | INFO | train | epoch 653 | loss 2.143 | nll_loss 0.585 | ppl 1.5 | wps 143147 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2607 | lr 0.000391705 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2616\n",
            "2023-12-04 20:57:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 654:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:48 | INFO | fairseq.trainer | begin training epoch 654\n",
            "2023-12-04 20:57:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:50 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)\n",
            "2023-12-04 20:57:50 | INFO | train | epoch 654 | loss 2.146 | nll_loss 0.591 | ppl 1.51 | wps 141412 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2611 | lr 0.000391405 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2619\n",
            "2023-12-04 20:57:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 655:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:50 | INFO | fairseq.trainer | begin training epoch 655\n",
            "2023-12-04 20:57:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:53 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)\n",
            "2023-12-04 20:57:53 | INFO | train | epoch 655 | loss 2.146 | nll_loss 0.59 | ppl 1.51 | wps 140913 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2615 | lr 0.000391106 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2621\n",
            "2023-12-04 20:57:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 656:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:53 | INFO | fairseq.trainer | begin training epoch 656\n",
            "2023-12-04 20:57:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:55 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)\n",
            "2023-12-04 20:57:55 | INFO | train | epoch 656 | loss 2.145 | nll_loss 0.589 | ppl 1.5 | wps 140232 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2619 | lr 0.000390807 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2624\n",
            "2023-12-04 20:57:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 657:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:55 | INFO | fairseq.trainer | begin training epoch 657\n",
            "2023-12-04 20:57:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:57:57 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)\n",
            "2023-12-04 20:57:57 | INFO | train | epoch 657 | loss 2.143 | nll_loss 0.588 | ppl 1.5 | wps 144332 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2623 | lr 0.000390509 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2626\n",
            "2023-12-04 20:57:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 658:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:57:57 | INFO | fairseq.trainer | begin training epoch 658\n",
            "2023-12-04 20:57:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:00 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)\n",
            "2023-12-04 20:58:00 | INFO | train | epoch 658 | loss 2.142 | nll_loss 0.585 | ppl 1.5 | wps 142294 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2627 | lr 0.000390211 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2628\n",
            "2023-12-04 20:58:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 659:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:00 | INFO | fairseq.trainer | begin training epoch 659\n",
            "2023-12-04 20:58:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:02 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)\n",
            "2023-12-04 20:58:02 | INFO | train | epoch 659 | loss 2.143 | nll_loss 0.589 | ppl 1.5 | wps 141025 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2631 | lr 0.000389915 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2631\n",
            "2023-12-04 20:58:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 660:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:02 | INFO | fairseq.trainer | begin training epoch 660\n",
            "2023-12-04 20:58:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 660:  75% 3/4 [00:01<00:00,  1.69it/s]2023-12-04 20:58:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:58:06 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan releui inte quarche çircostanse.\n",
            "2023-12-04 20:58:06 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 20:58:08 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:58:08 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 20:58:09 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti ò an produto di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:58:09 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 20:58:11 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:58:11 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 20:58:13 | INFO | fairseq.tasks.translation | example hypothesis: O l’é probabile che o vostro hotel o vostro òspite (in o caso sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ inte l’Internet ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:58:13 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 20:58:15 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 km (29173 quaddræ) in sce l'Asia sud-òvest, 75.68 km (29173), ch'a l'é collocâ Euröpa quaddræ inte l'Asia sud-òvest, e 23764 km (174).\n",
            "2023-12-04 20:58:15 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 20:58:17 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb in sciô graddo de attirare 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh, 24 e o l'é stæto lasciou à Duceante, Woldur de Ombur.\n",
            "2023-12-04 20:58:17 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 660 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:58:17 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 6.436 | nll_loss 5.219 | ppl 37.24 | bleu 12.72 | wps 4196.4 | wpb 7753.9 | bsz 142.4 | num_updates 2635 | best_bleu 12.77\n",
            "2023-12-04 20:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 2635 updates\n",
            "2023-12-04 20:58:17 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint660.pt\n",
            "2023-12-04 20:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint660.pt\n",
            "2023-12-04 20:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint660.pt (epoch 660 @ 2635 updates, score 12.72) (writing took 2.1334286329997667 seconds)\n",
            "2023-12-04 20:58:19 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)\n",
            "2023-12-04 20:58:19 | INFO | train | epoch 660 | loss 2.139 | nll_loss 0.583 | ppl 1.5 | wps 20682.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2635 | lr 0.000389619 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2648\n",
            "2023-12-04 20:58:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 661:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:19 | INFO | fairseq.trainer | begin training epoch 661\n",
            "2023-12-04 20:58:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:21 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)\n",
            "2023-12-04 20:58:21 | INFO | train | epoch 661 | loss 2.14 | nll_loss 0.586 | ppl 1.5 | wps 137658 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 2639 | lr 0.000389323 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2650\n",
            "2023-12-04 20:58:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 662:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:21 | INFO | fairseq.trainer | begin training epoch 662\n",
            "2023-12-04 20:58:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:24 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)\n",
            "2023-12-04 20:58:24 | INFO | train | epoch 662 | loss 2.139 | nll_loss 0.583 | ppl 1.5 | wps 142250 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2643 | lr 0.000389028 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2652\n",
            "2023-12-04 20:58:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 663:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:24 | INFO | fairseq.trainer | begin training epoch 663\n",
            "2023-12-04 20:58:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:26 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)\n",
            "2023-12-04 20:58:26 | INFO | train | epoch 663 | loss 2.141 | nll_loss 0.586 | ppl 1.5 | wps 143604 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2647 | lr 0.000388734 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 2655\n",
            "2023-12-04 20:58:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 664:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:26 | INFO | fairseq.trainer | begin training epoch 664\n",
            "2023-12-04 20:58:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:29 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)\n",
            "2023-12-04 20:58:29 | INFO | train | epoch 664 | loss 2.14 | nll_loss 0.584 | ppl 1.5 | wps 143506 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2651 | lr 0.000388441 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2657\n",
            "2023-12-04 20:58:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 665:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:29 | INFO | fairseq.trainer | begin training epoch 665\n",
            "2023-12-04 20:58:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:31 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)\n",
            "2023-12-04 20:58:31 | INFO | train | epoch 665 | loss 2.137 | nll_loss 0.581 | ppl 1.5 | wps 143438 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2655 | lr 0.000388148 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2660\n",
            "2023-12-04 20:58:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 666:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:31 | INFO | fairseq.trainer | begin training epoch 666\n",
            "2023-12-04 20:58:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:33 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)\n",
            "2023-12-04 20:58:33 | INFO | train | epoch 666 | loss 2.138 | nll_loss 0.583 | ppl 1.5 | wps 143906 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2659 | lr 0.000387856 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2662\n",
            "2023-12-04 20:58:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 667:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:33 | INFO | fairseq.trainer | begin training epoch 667\n",
            "2023-12-04 20:58:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:36 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)\n",
            "2023-12-04 20:58:36 | INFO | train | epoch 667 | loss 2.136 | nll_loss 0.58 | ppl 1.49 | wps 140714 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2663 | lr 0.000387565 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2664\n",
            "2023-12-04 20:58:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 668:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:36 | INFO | fairseq.trainer | begin training epoch 668\n",
            "2023-12-04 20:58:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:38 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)\n",
            "2023-12-04 20:58:38 | INFO | train | epoch 668 | loss 2.138 | nll_loss 0.583 | ppl 1.5 | wps 142409 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2667 | lr 0.000387274 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2667\n",
            "2023-12-04 20:58:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 669:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:38 | INFO | fairseq.trainer | begin training epoch 669\n",
            "2023-12-04 20:58:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:58:41 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)\n",
            "2023-12-04 20:58:41 | INFO | train | epoch 669 | loss 2.133 | nll_loss 0.578 | ppl 1.49 | wps 144807 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2671 | lr 0.000386984 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2669\n",
            "2023-12-04 20:58:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 670:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:58:41 | INFO | fairseq.trainer | begin training epoch 670\n",
            "2023-12-04 20:58:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 670:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 20:58:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:58:45 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan resòlve di utili inte quarche çircostanse.\n",
            "2023-12-04 20:58:45 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  14% 1/7 [00:01<00:10,  1.81s/it]\u001b[A2023-12-04 20:58:46 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:58:46 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.65s/it]\u001b[A2023-12-04 20:58:48 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de gibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:58:48 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  43% 3/7 [00:05<00:06,  1.70s/it]\u001b[A2023-12-04 20:58:50 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:58:50 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.75s/it]\u001b[A2023-12-04 20:58:52 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vostro hotel o vostro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; ascì in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:58:52 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.94s/it]\u001b[A2023-12-04 20:58:54 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 km (29173 quaddræ) in sce l'Asia sud-òvest, ch'a l'à 23764 (29173 d'ancheu).\n",
            "2023-12-04 20:58:54 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.81s/it]\u001b[A2023-12-04 20:58:55 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb ch'o segge bon à attiâ de 5.00.00 vixitatoî unichi into meise d'ötovie, inserçioin personali, un network de nozieh, 24 ch'o l'é stæto lasciou à Duceante, ciammou Dumbur Ombur.\n",
            "2023-12-04 20:58:55 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 670 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.77s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:58:55 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 6.429 | nll_loss 5.212 | ppl 37.07 | bleu 12.96 | wps 4146.8 | wpb 7753.9 | bsz 142.4 | num_updates 2675 | best_bleu 12.96\n",
            "2023-12-04 20:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 2675 updates\n",
            "2023-12-04 20:58:55 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint670.pt\n",
            "2023-12-04 20:58:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint670.pt\n",
            "2023-12-04 20:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint670.pt (epoch 670 @ 2675 updates, score 12.96) (writing took 7.561258215999715 seconds)\n",
            "2023-12-04 20:59:03 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)\n",
            "2023-12-04 20:59:03 | INFO | train | epoch 670 | loss 2.136 | nll_loss 0.582 | ppl 1.5 | wps 15253.2 | ups 0.18 | wpb 85903.8 | bsz 1548.2 | num_updates 2675 | lr 0.000386695 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2692\n",
            "2023-12-04 20:59:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 671:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:03 | INFO | fairseq.trainer | begin training epoch 671\n",
            "2023-12-04 20:59:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:06 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)\n",
            "2023-12-04 20:59:06 | INFO | train | epoch 671 | loss 2.134 | nll_loss 0.577 | ppl 1.49 | wps 139261 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2679 | lr 0.000386406 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2694\n",
            "2023-12-04 20:59:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 672:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:06 | INFO | fairseq.trainer | begin training epoch 672\n",
            "2023-12-04 20:59:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:08 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)\n",
            "2023-12-04 20:59:08 | INFO | train | epoch 672 | loss 2.135 | nll_loss 0.581 | ppl 1.5 | wps 142220 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2683 | lr 0.000386118 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2697\n",
            "2023-12-04 20:59:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 673:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:08 | INFO | fairseq.trainer | begin training epoch 673\n",
            "2023-12-04 20:59:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:10 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)\n",
            "2023-12-04 20:59:10 | INFO | train | epoch 673 | loss 2.136 | nll_loss 0.581 | ppl 1.5 | wps 138986 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2687 | lr 0.00038583 | gnorm 0.163 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2699\n",
            "2023-12-04 20:59:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 674:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:10 | INFO | fairseq.trainer | begin training epoch 674\n",
            "2023-12-04 20:59:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:13 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)\n",
            "2023-12-04 20:59:13 | INFO | train | epoch 674 | loss 2.134 | nll_loss 0.579 | ppl 1.49 | wps 143354 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2691 | lr 0.000385543 | gnorm 0.156 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2702\n",
            "2023-12-04 20:59:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 675:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:13 | INFO | fairseq.trainer | begin training epoch 675\n",
            "2023-12-04 20:59:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:15 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)\n",
            "2023-12-04 20:59:15 | INFO | train | epoch 675 | loss 2.135 | nll_loss 0.58 | ppl 1.5 | wps 140191 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2695 | lr 0.000385257 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2704\n",
            "2023-12-04 20:59:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 676:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:15 | INFO | fairseq.trainer | begin training epoch 676\n",
            "2023-12-04 20:59:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:18 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)\n",
            "2023-12-04 20:59:18 | INFO | train | epoch 676 | loss 2.134 | nll_loss 0.581 | ppl 1.5 | wps 143697 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2699 | lr 0.000384971 | gnorm 0.165 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2706\n",
            "2023-12-04 20:59:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 677:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:18 | INFO | fairseq.trainer | begin training epoch 677\n",
            "2023-12-04 20:59:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:20 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)\n",
            "2023-12-04 20:59:20 | INFO | train | epoch 677 | loss 2.134 | nll_loss 0.577 | ppl 1.49 | wps 145369 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2703 | lr 0.000384687 | gnorm 0.161 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2709\n",
            "2023-12-04 20:59:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 678:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:20 | INFO | fairseq.trainer | begin training epoch 678\n",
            "2023-12-04 20:59:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:22 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)\n",
            "2023-12-04 20:59:22 | INFO | train | epoch 678 | loss 2.131 | nll_loss 0.578 | ppl 1.49 | wps 141455 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2707 | lr 0.000384402 | gnorm 0.156 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2711\n",
            "2023-12-04 20:59:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 679:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:22 | INFO | fairseq.trainer | begin training epoch 679\n",
            "2023-12-04 20:59:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:25 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)\n",
            "2023-12-04 20:59:25 | INFO | train | epoch 679 | loss 2.13 | nll_loss 0.574 | ppl 1.49 | wps 142985 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2711 | lr 0.000384119 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2714\n",
            "2023-12-04 20:59:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 680:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:25 | INFO | fairseq.trainer | begin training epoch 680\n",
            "2023-12-04 20:59:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 680:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 20:59:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 20:59:29 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 20:59:29 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  14% 1/7 [00:01<00:09,  1.51s/it]\u001b[A2023-12-04 20:59:30 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 20:59:30 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.55s/it]\u001b[A2023-12-04 20:59:32 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 20:59:32 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.62s/it]\u001b[A2023-12-04 20:59:34 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 20:59:34 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.72s/it]\u001b[A2023-12-04 20:59:36 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (in o caso sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; pe de ciù o trovâ in sce l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 20:59:36 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.89s/it]\u001b[A2023-12-04 20:59:38 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): in sce sti 75.68 km (29173 quaddræ) sensæ inte l'Asia sud-òvest de Ponente, 23764 km (174 d'ancheu) in Euröpa quaddræ inte l'Asia sud-òvest de ponente, e 23764 km (174 d'Euröpa).\n",
            "2023-12-04 20:59:38 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 20:59:39 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.000 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un neork de neork de 24 ch'o l'é stæto lasciou do mondo est, ciammou Duceante.\n",
            "2023-12-04 20:59:39 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 680 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 20:59:39 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 6.425 | nll_loss 5.21 | ppl 37.01 | bleu 13.03 | wps 4148.9 | wpb 7753.9 | bsz 142.4 | num_updates 2715 | best_bleu 13.03\n",
            "2023-12-04 20:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 2715 updates\n",
            "2023-12-04 20:59:39 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint680.pt\n",
            "2023-12-04 20:59:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint680.pt\n",
            "2023-12-04 20:59:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint680.pt (epoch 680 @ 2715 updates, score 13.03) (writing took 3.7411197000001266 seconds)\n",
            "2023-12-04 20:59:43 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)\n",
            "2023-12-04 20:59:43 | INFO | train | epoch 680 | loss 2.133 | nll_loss 0.579 | ppl 1.49 | wps 18689.4 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 2715 | lr 0.000383835 | gnorm 0.165 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2732\n",
            "2023-12-04 20:59:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 681:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:43 | INFO | fairseq.trainer | begin training epoch 681\n",
            "2023-12-04 20:59:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:46 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)\n",
            "2023-12-04 20:59:46 | INFO | train | epoch 681 | loss 2.132 | nll_loss 0.578 | ppl 1.49 | wps 139904 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2719 | lr 0.000383553 | gnorm 0.164 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2734\n",
            "2023-12-04 20:59:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 682:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:46 | INFO | fairseq.trainer | begin training epoch 682\n",
            "2023-12-04 20:59:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:48 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)\n",
            "2023-12-04 20:59:48 | INFO | train | epoch 682 | loss 2.129 | nll_loss 0.574 | ppl 1.49 | wps 140451 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2723 | lr 0.000383271 | gnorm 0.158 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2737\n",
            "2023-12-04 20:59:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 683:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:48 | INFO | fairseq.trainer | begin training epoch 683\n",
            "2023-12-04 20:59:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:51 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)\n",
            "2023-12-04 20:59:51 | INFO | train | epoch 683 | loss 2.128 | nll_loss 0.575 | ppl 1.49 | wps 140644 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2727 | lr 0.00038299 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2739\n",
            "2023-12-04 20:59:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 684:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:51 | INFO | fairseq.trainer | begin training epoch 684\n",
            "2023-12-04 20:59:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:53 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)\n",
            "2023-12-04 20:59:53 | INFO | train | epoch 684 | loss 2.132 | nll_loss 0.576 | ppl 1.49 | wps 140592 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2731 | lr 0.000382709 | gnorm 0.178 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2742\n",
            "2023-12-04 20:59:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 685:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:53 | INFO | fairseq.trainer | begin training epoch 685\n",
            "2023-12-04 20:59:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:55 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)\n",
            "2023-12-04 20:59:55 | INFO | train | epoch 685 | loss 2.129 | nll_loss 0.574 | ppl 1.49 | wps 141046 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2735 | lr 0.000382429 | gnorm 0.176 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2744\n",
            "2023-12-04 20:59:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 686:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:56 | INFO | fairseq.trainer | begin training epoch 686\n",
            "2023-12-04 20:59:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 20:59:58 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)\n",
            "2023-12-04 20:59:58 | INFO | train | epoch 686 | loss 2.127 | nll_loss 0.574 | ppl 1.49 | wps 141329 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2739 | lr 0.00038215 | gnorm 0.159 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2747\n",
            "2023-12-04 20:59:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 687:   0% 0/4 [00:00<?, ?it/s]2023-12-04 20:59:58 | INFO | fairseq.trainer | begin training epoch 687\n",
            "2023-12-04 20:59:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:00 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)\n",
            "2023-12-04 21:00:00 | INFO | train | epoch 687 | loss 2.125 | nll_loss 0.568 | ppl 1.48 | wps 142465 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2743 | lr 0.000381871 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2749\n",
            "2023-12-04 21:00:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 688:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:00 | INFO | fairseq.trainer | begin training epoch 688\n",
            "2023-12-04 21:00:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:03 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)\n",
            "2023-12-04 21:00:03 | INFO | train | epoch 688 | loss 2.122 | nll_loss 0.569 | ppl 1.48 | wps 141516 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2747 | lr 0.000381593 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2751\n",
            "2023-12-04 21:00:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 689:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:03 | INFO | fairseq.trainer | begin training epoch 689\n",
            "2023-12-04 21:00:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:05 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)\n",
            "2023-12-04 21:00:05 | INFO | train | epoch 689 | loss 2.124 | nll_loss 0.569 | ppl 1.48 | wps 142369 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2751 | lr 0.000381316 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2754\n",
            "2023-12-04 21:00:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 690:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:05 | INFO | fairseq.trainer | begin training epoch 690\n",
            "2023-12-04 21:00:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 690:  75% 3/4 [00:01<00:00,  1.62it/s]2023-12-04 21:00:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:00:09 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:00:09 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A2023-12-04 21:00:11 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:00:11 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.54s/it]\u001b[A2023-12-04 21:00:12 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:00:12 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:00:14 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951, o l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dsong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:00:14 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:00:16 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:00:16 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:00:18 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 km (29173 quaddræ) in sce l'Asia sud-òvest, ch'a l'é 2376 (29173 d'ancheu (e Euröpa quaddræ) inte l'Asia sud-òvest, e 23764 km (174 d'Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:00:18 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:00:20 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ de 5.00.00 vixitatoî de vixitatoî unichi into meise d'ötovie, inserçioin personali, un neork de neork de noçieh, 24 etlante à Duceante, ciammou Ducedywor, Wombur de Ombur.\n",
            "2023-12-04 21:00:20 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 690 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.78s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:00:20 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 6.42 | nll_loss 5.208 | ppl 36.95 | bleu 12.69 | wps 4145.7 | wpb 7753.9 | bsz 142.4 | num_updates 2755 | best_bleu 13.03\n",
            "2023-12-04 21:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 2755 updates\n",
            "2023-12-04 21:00:20 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint690.pt\n",
            "2023-12-04 21:00:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint690.pt\n",
            "2023-12-04 21:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint690.pt (epoch 690 @ 2755 updates, score 12.69) (writing took 2.1194932049997988 seconds)\n",
            "2023-12-04 21:00:22 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)\n",
            "2023-12-04 21:00:22 | INFO | train | epoch 690 | loss 2.122 | nll_loss 0.567 | ppl 1.48 | wps 20412.8 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2755 | lr 0.000381039 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2771\n",
            "2023-12-04 21:00:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 691:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:22 | INFO | fairseq.trainer | begin training epoch 691\n",
            "2023-12-04 21:00:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:25 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)\n",
            "2023-12-04 21:00:25 | INFO | train | epoch 691 | loss 2.123 | nll_loss 0.569 | ppl 1.48 | wps 136188 | ups 1.59 | wpb 85903.8 | bsz 1548.2 | num_updates 2759 | lr 0.000380762 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2773\n",
            "2023-12-04 21:00:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 692:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:25 | INFO | fairseq.trainer | begin training epoch 692\n",
            "2023-12-04 21:00:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:27 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)\n",
            "2023-12-04 21:00:27 | INFO | train | epoch 692 | loss 2.121 | nll_loss 0.567 | ppl 1.48 | wps 140442 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2763 | lr 0.000380487 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2776\n",
            "2023-12-04 21:00:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 693:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:27 | INFO | fairseq.trainer | begin training epoch 693\n",
            "2023-12-04 21:00:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:29 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)\n",
            "2023-12-04 21:00:29 | INFO | train | epoch 693 | loss 2.121 | nll_loss 0.567 | ppl 1.48 | wps 141333 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2767 | lr 0.000380212 | gnorm 0.154 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2778\n",
            "2023-12-04 21:00:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 694:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:29 | INFO | fairseq.trainer | begin training epoch 694\n",
            "2023-12-04 21:00:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:32 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)\n",
            "2023-12-04 21:00:32 | INFO | train | epoch 694 | loss 2.122 | nll_loss 0.567 | ppl 1.48 | wps 141453 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2771 | lr 0.000379937 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2781\n",
            "2023-12-04 21:00:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 695:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:32 | INFO | fairseq.trainer | begin training epoch 695\n",
            "2023-12-04 21:00:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:34 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)\n",
            "2023-12-04 21:00:34 | INFO | train | epoch 695 | loss 2.12 | nll_loss 0.564 | ppl 1.48 | wps 145481 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2775 | lr 0.000379663 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2783\n",
            "2023-12-04 21:00:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 696:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:34 | INFO | fairseq.trainer | begin training epoch 696\n",
            "2023-12-04 21:00:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:37 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)\n",
            "2023-12-04 21:00:37 | INFO | train | epoch 696 | loss 2.117 | nll_loss 0.563 | ppl 1.48 | wps 142563 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2779 | lr 0.00037939 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2785\n",
            "2023-12-04 21:00:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 697:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:37 | INFO | fairseq.trainer | begin training epoch 697\n",
            "2023-12-04 21:00:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:39 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)\n",
            "2023-12-04 21:00:39 | INFO | train | epoch 697 | loss 2.116 | nll_loss 0.561 | ppl 1.48 | wps 140836 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2783 | lr 0.000379117 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2788\n",
            "2023-12-04 21:00:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 698:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:39 | INFO | fairseq.trainer | begin training epoch 698\n",
            "2023-12-04 21:00:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:41 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)\n",
            "2023-12-04 21:00:41 | INFO | train | epoch 698 | loss 2.117 | nll_loss 0.564 | ppl 1.48 | wps 141528 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2787 | lr 0.000378845 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2790\n",
            "2023-12-04 21:00:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 699:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:42 | INFO | fairseq.trainer | begin training epoch 699\n",
            "2023-12-04 21:00:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:00:44 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)\n",
            "2023-12-04 21:00:44 | INFO | train | epoch 699 | loss 2.116 | nll_loss 0.561 | ppl 1.48 | wps 144825 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2791 | lr 0.000378573 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2793\n",
            "2023-12-04 21:00:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 700:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:00:44 | INFO | fairseq.trainer | begin training epoch 700\n",
            "2023-12-04 21:00:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 700:  75% 3/4 [00:01<00:00,  1.60it/s]2023-12-04 21:00:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:00:48 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:00:48 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  14% 1/7 [00:01<00:09,  1.52s/it]\u001b[A2023-12-04 21:00:49 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:00:49 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.58s/it]\u001b[A2023-12-04 21:00:51 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:00:51 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.62s/it]\u001b[A2023-12-04 21:00:53 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:00:53 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:00:55 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (in o caso sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; pe de ciù o trovâ in sce l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:00:55 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.90s/it]\u001b[A2023-12-04 21:00:57 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 km (29173 quaddræ) in sce l’Asia sud-òvest, ch’a l’é 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:00:57 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:00:58 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scitoweb pe attiâ de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh,4 ch'o l'é stæto lasciou à Duceante, Woldur de Ombur.\n",
            "2023-12-04 21:00:58 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 700 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:00:58 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 6.437 | nll_loss 5.228 | ppl 37.48 | bleu 12.94 | wps 4188.6 | wpb 7753.9 | bsz 142.4 | num_updates 2795 | best_bleu 13.03\n",
            "2023-12-04 21:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 2795 updates\n",
            "2023-12-04 21:00:58 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint700.pt\n",
            "2023-12-04 21:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint700.pt\n",
            "2023-12-04 21:01:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint700.pt (epoch 700 @ 2795 updates, score 12.94) (writing took 2.143443761999606 seconds)\n",
            "2023-12-04 21:01:01 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)\n",
            "2023-12-04 21:01:01 | INFO | train | epoch 700 | loss 2.116 | nll_loss 0.562 | ppl 1.48 | wps 20484.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2795 | lr 0.000378302 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2809\n",
            "2023-12-04 21:01:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 701:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:01 | INFO | fairseq.trainer | begin training epoch 701\n",
            "2023-12-04 21:01:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:03 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)\n",
            "2023-12-04 21:01:03 | INFO | train | epoch 701 | loss 2.113 | nll_loss 0.558 | ppl 1.47 | wps 140422 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2799 | lr 0.000378032 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2812\n",
            "2023-12-04 21:01:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 702:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:03 | INFO | fairseq.trainer | begin training epoch 702\n",
            "2023-12-04 21:01:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:05 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)\n",
            "2023-12-04 21:01:05 | INFO | train | epoch 702 | loss 2.112 | nll_loss 0.557 | ppl 1.47 | wps 141134 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2803 | lr 0.000377762 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2814\n",
            "2023-12-04 21:01:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 703:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:06 | INFO | fairseq.trainer | begin training epoch 703\n",
            "2023-12-04 21:01:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:08 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)\n",
            "2023-12-04 21:01:08 | INFO | train | epoch 703 | loss 2.111 | nll_loss 0.556 | ppl 1.47 | wps 144184 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2807 | lr 0.000377493 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2817\n",
            "2023-12-04 21:01:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 704:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:08 | INFO | fairseq.trainer | begin training epoch 704\n",
            "2023-12-04 21:01:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:10 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)\n",
            "2023-12-04 21:01:10 | INFO | train | epoch 704 | loss 2.112 | nll_loss 0.557 | ppl 1.47 | wps 143768 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2811 | lr 0.000377224 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2819\n",
            "2023-12-04 21:01:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 705:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:10 | INFO | fairseq.trainer | begin training epoch 705\n",
            "2023-12-04 21:01:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:13 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)\n",
            "2023-12-04 21:01:13 | INFO | train | epoch 705 | loss 2.111 | nll_loss 0.556 | ppl 1.47 | wps 139589 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2815 | lr 0.000376956 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2821\n",
            "2023-12-04 21:01:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 706:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:13 | INFO | fairseq.trainer | begin training epoch 706\n",
            "2023-12-04 21:01:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:15 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)\n",
            "2023-12-04 21:01:15 | INFO | train | epoch 706 | loss 2.111 | nll_loss 0.556 | ppl 1.47 | wps 143632 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2819 | lr 0.000376689 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2824\n",
            "2023-12-04 21:01:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 707:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:15 | INFO | fairseq.trainer | begin training epoch 707\n",
            "2023-12-04 21:01:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:18 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)\n",
            "2023-12-04 21:01:18 | INFO | train | epoch 707 | loss 2.108 | nll_loss 0.552 | ppl 1.47 | wps 143030 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2823 | lr 0.000376422 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2826\n",
            "2023-12-04 21:01:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 708:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:18 | INFO | fairseq.trainer | begin training epoch 708\n",
            "2023-12-04 21:01:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:20 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)\n",
            "2023-12-04 21:01:20 | INFO | train | epoch 708 | loss 2.107 | nll_loss 0.553 | ppl 1.47 | wps 139127 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2827 | lr 0.000376155 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2829\n",
            "2023-12-04 21:01:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 709:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:20 | INFO | fairseq.trainer | begin training epoch 709\n",
            "2023-12-04 21:01:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:22 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)\n",
            "2023-12-04 21:01:22 | INFO | train | epoch 709 | loss 2.108 | nll_loss 0.552 | ppl 1.47 | wps 143738 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2831 | lr 0.000375889 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 2831\n",
            "2023-12-04 21:01:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 710:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:22 | INFO | fairseq.trainer | begin training epoch 710\n",
            "2023-12-04 21:01:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 710:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:01:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:01:26 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:01:28 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:01:28 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.53s/it]\u001b[A2023-12-04 21:01:29 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ da çerti ponti, òffiti an fornio à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:01:29 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  43% 3/7 [00:05<00:07,  1.75s/it]\u001b[A2023-12-04 21:01:32 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:01:32 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.79s/it]\u001b[A2023-12-04 21:01:34 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (isòtta sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù in sce l’Internet ò inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 21:01:34 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.93s/it]\u001b[A2023-12-04 21:01:35 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 de km (29173 quaddræ) seræ inte l'Asia sud-òvest, ch'a l'à 23764 (174 d'etæ miggia Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:01:35 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 21:01:37 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.000 de vixitoî uniçittöia into meise de l'ottobre, inserçioin personali, un neork de neork de 240, ch'o l'é stæto lasciou da un mondiale à Duceante, Woldur de Ombur.\n",
            "2023-12-04 21:01:37 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 710 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.75s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:01:37 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 6.435 | nll_loss 5.229 | ppl 37.51 | bleu 12.82 | wps 4085.2 | wpb 7753.9 | bsz 142.4 | num_updates 2835 | best_bleu 13.03\n",
            "2023-12-04 21:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 2835 updates\n",
            "2023-12-04 21:01:37 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint710.pt\n",
            "2023-12-04 21:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint710.pt\n",
            "2023-12-04 21:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint710.pt (epoch 710 @ 2835 updates, score 12.82) (writing took 2.131483336999736 seconds)\n",
            "2023-12-04 21:01:39 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)\n",
            "2023-12-04 21:01:39 | INFO | train | epoch 710 | loss 2.109 | nll_loss 0.556 | ppl 1.47 | wps 20333.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2835 | lr 0.000375624 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2848\n",
            "2023-12-04 21:01:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 711:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:39 | INFO | fairseq.trainer | begin training epoch 711\n",
            "2023-12-04 21:01:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:42 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)\n",
            "2023-12-04 21:01:42 | INFO | train | epoch 711 | loss 2.109 | nll_loss 0.554 | ppl 1.47 | wps 138197 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 2839 | lr 0.000375359 | gnorm 0.143 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2850\n",
            "2023-12-04 21:01:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 712:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:42 | INFO | fairseq.trainer | begin training epoch 712\n",
            "2023-12-04 21:01:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:44 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)\n",
            "2023-12-04 21:01:44 | INFO | train | epoch 712 | loss 2.107 | nll_loss 0.553 | ppl 1.47 | wps 139396 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2843 | lr 0.000375095 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2853\n",
            "2023-12-04 21:01:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 713:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:44 | INFO | fairseq.trainer | begin training epoch 713\n",
            "2023-12-04 21:01:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:47 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)\n",
            "2023-12-04 21:01:47 | INFO | train | epoch 713 | loss 2.106 | nll_loss 0.552 | ppl 1.47 | wps 143068 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2847 | lr 0.000374832 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2855\n",
            "2023-12-04 21:01:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 714:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:47 | INFO | fairseq.trainer | begin training epoch 714\n",
            "2023-12-04 21:01:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:49 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)\n",
            "2023-12-04 21:01:49 | INFO | train | epoch 714 | loss 2.104 | nll_loss 0.549 | ppl 1.46 | wps 140857 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2851 | lr 0.000374569 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2858\n",
            "2023-12-04 21:01:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 715:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:49 | INFO | fairseq.trainer | begin training epoch 715\n",
            "2023-12-04 21:01:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:51 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)\n",
            "2023-12-04 21:01:51 | INFO | train | epoch 715 | loss 2.106 | nll_loss 0.553 | ppl 1.47 | wps 143888 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2855 | lr 0.000374306 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2860\n",
            "2023-12-04 21:01:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 716:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:52 | INFO | fairseq.trainer | begin training epoch 716\n",
            "2023-12-04 21:01:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:54 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)\n",
            "2023-12-04 21:01:54 | INFO | train | epoch 716 | loss 2.106 | nll_loss 0.55 | ppl 1.46 | wps 139759 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2859 | lr 0.000374044 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2863\n",
            "2023-12-04 21:01:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 717:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:54 | INFO | fairseq.trainer | begin training epoch 717\n",
            "2023-12-04 21:01:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:56 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)\n",
            "2023-12-04 21:01:56 | INFO | train | epoch 717 | loss 2.106 | nll_loss 0.554 | ppl 1.47 | wps 141832 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2863 | lr 0.000373783 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2865\n",
            "2023-12-04 21:01:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 718:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:56 | INFO | fairseq.trainer | begin training epoch 718\n",
            "2023-12-04 21:01:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:01:59 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)\n",
            "2023-12-04 21:01:59 | INFO | train | epoch 718 | loss 2.104 | nll_loss 0.548 | ppl 1.46 | wps 143746 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2867 | lr 0.000373522 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2867\n",
            "2023-12-04 21:01:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 719:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:01:59 | INFO | fairseq.trainer | begin training epoch 719\n",
            "2023-12-04 21:01:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:01 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)\n",
            "2023-12-04 21:02:01 | INFO | train | epoch 719 | loss 2.102 | nll_loss 0.548 | ppl 1.46 | wps 142781 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2871 | lr 0.000373262 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2870\n",
            "2023-12-04 21:02:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 720:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:01 | INFO | fairseq.trainer | begin training epoch 720\n",
            "2023-12-04 21:02:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 720:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:02:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:02:05 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:02:05 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:02:07 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:02:07 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:02:08 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:02:08 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.61s/it]\u001b[A2023-12-04 21:02:10 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:02:10 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:02:12 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (isòspite soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù in sce l’Internet ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:02:12 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:02:14 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 de km (29173 quaddræ) ch'a s'é collocâ inte l'Asia sud-òvest, e 23764 (174 d'Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:02:14 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 21:02:15 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scitoweb o peu attâ di atti de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh, 24 etlante à Duceante, ciammou Ducewoldur de Ombur.\n",
            "2023-12-04 21:02:15 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 720 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:02:15 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 6.436 | nll_loss 5.235 | ppl 37.67 | bleu 13.01 | wps 4224.6 | wpb 7753.9 | bsz 142.4 | num_updates 2875 | best_bleu 13.03\n",
            "2023-12-04 21:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 2875 updates\n",
            "2023-12-04 21:02:15 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint720.pt\n",
            "2023-12-04 21:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint720.pt\n",
            "2023-12-04 21:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint720.pt (epoch 720 @ 2875 updates, score 13.01) (writing took 2.1476169049997225 seconds)\n",
            "2023-12-04 21:02:18 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)\n",
            "2023-12-04 21:02:18 | INFO | train | epoch 720 | loss 2.101 | nll_loss 0.547 | ppl 1.46 | wps 20718.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2875 | lr 0.000373002 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2886\n",
            "2023-12-04 21:02:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 721:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:18 | INFO | fairseq.trainer | begin training epoch 721\n",
            "2023-12-04 21:02:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:20 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)\n",
            "2023-12-04 21:02:20 | INFO | train | epoch 721 | loss 2.099 | nll_loss 0.546 | ppl 1.46 | wps 139709 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2879 | lr 0.000372743 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2889\n",
            "2023-12-04 21:02:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 722:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:20 | INFO | fairseq.trainer | begin training epoch 722\n",
            "2023-12-04 21:02:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:23 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)\n",
            "2023-12-04 21:02:23 | INFO | train | epoch 722 | loss 2.1 | nll_loss 0.545 | ppl 1.46 | wps 140572 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 2883 | lr 0.000372484 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2891\n",
            "2023-12-04 21:02:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 723:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:23 | INFO | fairseq.trainer | begin training epoch 723\n",
            "2023-12-04 21:02:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:25 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)\n",
            "2023-12-04 21:02:25 | INFO | train | epoch 723 | loss 2.1 | nll_loss 0.546 | ppl 1.46 | wps 143914 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2887 | lr 0.000372226 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2894\n",
            "2023-12-04 21:02:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 724:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:25 | INFO | fairseq.trainer | begin training epoch 724\n",
            "2023-12-04 21:02:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:27 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)\n",
            "2023-12-04 21:02:27 | INFO | train | epoch 724 | loss 2.1 | nll_loss 0.546 | ppl 1.46 | wps 144068 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2891 | lr 0.000371968 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2896\n",
            "2023-12-04 21:02:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 725:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:27 | INFO | fairseq.trainer | begin training epoch 725\n",
            "2023-12-04 21:02:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:30 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)\n",
            "2023-12-04 21:02:30 | INFO | train | epoch 725 | loss 2.1 | nll_loss 0.544 | ppl 1.46 | wps 144672 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2895 | lr 0.000371711 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2898\n",
            "2023-12-04 21:02:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 726:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:30 | INFO | fairseq.trainer | begin training epoch 726\n",
            "2023-12-04 21:02:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:32 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)\n",
            "2023-12-04 21:02:32 | INFO | train | epoch 726 | loss 2.101 | nll_loss 0.549 | ppl 1.46 | wps 141862 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2899 | lr 0.000371455 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 2901\n",
            "2023-12-04 21:02:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 727:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:32 | INFO | fairseq.trainer | begin training epoch 727\n",
            "2023-12-04 21:02:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:35 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)\n",
            "2023-12-04 21:02:35 | INFO | train | epoch 727 | loss 2.097 | nll_loss 0.543 | ppl 1.46 | wps 143016 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2903 | lr 0.000371199 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2903\n",
            "2023-12-04 21:02:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 728:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:35 | INFO | fairseq.trainer | begin training epoch 728\n",
            "2023-12-04 21:02:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:37 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)\n",
            "2023-12-04 21:02:37 | INFO | train | epoch 728 | loss 2.097 | nll_loss 0.543 | ppl 1.46 | wps 143797 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2907 | lr 0.000370943 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2906\n",
            "2023-12-04 21:02:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 729:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:37 | INFO | fairseq.trainer | begin training epoch 729\n",
            "2023-12-04 21:02:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:02:39 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)\n",
            "2023-12-04 21:02:39 | INFO | train | epoch 729 | loss 2.095 | nll_loss 0.542 | ppl 1.46 | wps 140352 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2911 | lr 0.000370688 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2908\n",
            "2023-12-04 21:02:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 730:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:39 | INFO | fairseq.trainer | begin training epoch 730\n",
            "2023-12-04 21:02:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 730:  75% 3/4 [00:01<00:00,  1.62it/s]2023-12-04 21:02:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:02:43 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:02:43 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  14% 1/7 [00:01<00:09,  1.51s/it]\u001b[A2023-12-04 21:02:45 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:02:45 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.57s/it]\u001b[A2023-12-04 21:02:47 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che Aldun òffiti an fornio à di microonde ò di atri mezi pe rescäve o mangiâ.\n",
            "2023-12-04 21:02:47 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.62s/it]\u001b[A2023-12-04 21:02:48 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:02:48 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:02:51 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ inte l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:02:51 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:02:52 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) in sce l’Asia sud-òvest, ch’o l’à 23764 (29173 d’ancheu (e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:02:52 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:02:54 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh 24 etlante, ch'o l'é stæto lasciou à Duceabrou de Ombur, Wor.\n",
            "2023-12-04 21:02:54 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 730 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.71s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:02:54 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 6.434 | nll_loss 5.231 | ppl 37.57 | bleu 13.1 | wps 4251.3 | wpb 7753.9 | bsz 142.4 | num_updates 2915 | best_bleu 13.1\n",
            "2023-12-04 21:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 2915 updates\n",
            "2023-12-04 21:02:54 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint730.pt\n",
            "2023-12-04 21:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint730.pt\n",
            "2023-12-04 21:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint730.pt (epoch 730 @ 2915 updates, score 13.1) (writing took 3.987123905000317 seconds)\n",
            "2023-12-04 21:02:58 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)\n",
            "2023-12-04 21:02:58 | INFO | train | epoch 730 | loss 2.096 | nll_loss 0.543 | ppl 1.46 | wps 18642.8 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 2915 | lr 0.000370434 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2927\n",
            "2023-12-04 21:02:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 731:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:02:58 | INFO | fairseq.trainer | begin training epoch 731\n",
            "2023-12-04 21:02:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:00 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)\n",
            "2023-12-04 21:03:00 | INFO | train | epoch 731 | loss 2.095 | nll_loss 0.541 | ppl 1.46 | wps 137630 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 2919 | lr 0.00037018 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2929\n",
            "2023-12-04 21:03:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 732:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:00 | INFO | fairseq.trainer | begin training epoch 732\n",
            "2023-12-04 21:03:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:03 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)\n",
            "2023-12-04 21:03:03 | INFO | train | epoch 732 | loss 2.094 | nll_loss 0.539 | ppl 1.45 | wps 139926 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2923 | lr 0.000369927 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2932\n",
            "2023-12-04 21:03:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 733:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:03 | INFO | fairseq.trainer | begin training epoch 733\n",
            "2023-12-04 21:03:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:05 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)\n",
            "2023-12-04 21:03:05 | INFO | train | epoch 733 | loss 2.094 | nll_loss 0.542 | ppl 1.46 | wps 144869 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2927 | lr 0.000369674 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2934\n",
            "2023-12-04 21:03:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 734:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:05 | INFO | fairseq.trainer | begin training epoch 734\n",
            "2023-12-04 21:03:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:08 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)\n",
            "2023-12-04 21:03:08 | INFO | train | epoch 734 | loss 2.095 | nll_loss 0.541 | ppl 1.46 | wps 143811 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2931 | lr 0.000369421 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2936\n",
            "2023-12-04 21:03:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 735:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:08 | INFO | fairseq.trainer | begin training epoch 735\n",
            "2023-12-04 21:03:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:10 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)\n",
            "2023-12-04 21:03:10 | INFO | train | epoch 735 | loss 2.097 | nll_loss 0.544 | ppl 1.46 | wps 143707 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2935 | lr 0.00036917 | gnorm 0.151 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2939\n",
            "2023-12-04 21:03:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 736:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:10 | INFO | fairseq.trainer | begin training epoch 736\n",
            "2023-12-04 21:03:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:12 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)\n",
            "2023-12-04 21:03:12 | INFO | train | epoch 736 | loss 2.096 | nll_loss 0.542 | ppl 1.46 | wps 142268 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2939 | lr 0.000368918 | gnorm 0.152 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2941\n",
            "2023-12-04 21:03:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 737:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:12 | INFO | fairseq.trainer | begin training epoch 737\n",
            "2023-12-04 21:03:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:15 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)\n",
            "2023-12-04 21:03:15 | INFO | train | epoch 737 | loss 2.096 | nll_loss 0.544 | ppl 1.46 | wps 141329 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2943 | lr 0.000368668 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2944\n",
            "2023-12-04 21:03:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 738:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:15 | INFO | fairseq.trainer | begin training epoch 738\n",
            "2023-12-04 21:03:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:17 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)\n",
            "2023-12-04 21:03:17 | INFO | train | epoch 738 | loss 2.092 | nll_loss 0.541 | ppl 1.45 | wps 142589 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2947 | lr 0.000368417 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 2946\n",
            "2023-12-04 21:03:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 739:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:17 | INFO | fairseq.trainer | begin training epoch 739\n",
            "2023-12-04 21:03:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:20 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)\n",
            "2023-12-04 21:03:20 | INFO | train | epoch 739 | loss 2.092 | nll_loss 0.537 | ppl 1.45 | wps 146912 | ups 1.71 | wpb 85903.8 | bsz 1548.2 | num_updates 2951 | lr 0.000368167 | gnorm 0.144 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2948\n",
            "2023-12-04 21:03:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 740:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:20 | INFO | fairseq.trainer | begin training epoch 740\n",
            "2023-12-04 21:03:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 740:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:03:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:03:23 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, inte Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelative inte quarche çircostanse.\n",
            "2023-12-04 21:03:23 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  14% 1/7 [00:01<00:09,  1.50s/it]\u001b[A2023-12-04 21:03:25 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:03:25 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.53s/it]\u001b[A2023-12-04 21:03:27 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ercæ propoñan un reparto con unna ciù grande çernia de gibinti. Al òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:03:27 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:03:29 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:03:29 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:03:31 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù in sce l’Internet ò inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 21:03:31 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.87s/it]\u001b[A2023-12-04 21:03:32 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) che s’attreuvan in sce l’Asia sud-òvest, 23764 (29173 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:03:32 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 21:03:34 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web in graddo attia de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh, 24 etlante à Duceante, ciammou Ombur, Wor.\n",
            "2023-12-04 21:03:34 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 740 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.78s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:03:34 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 6.435 | nll_loss 5.234 | ppl 37.64 | bleu 12.95 | wps 4155.3 | wpb 7753.9 | bsz 142.4 | num_updates 2955 | best_bleu 13.1\n",
            "2023-12-04 21:03:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 2955 updates\n",
            "2023-12-04 21:03:34 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint740.pt\n",
            "2023-12-04 21:03:36 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint740.pt\n",
            "2023-12-04 21:03:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint740.pt (epoch 740 @ 2955 updates, score 12.95) (writing took 2.1274375130001317 seconds)\n",
            "2023-12-04 21:03:36 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)\n",
            "2023-12-04 21:03:36 | INFO | train | epoch 740 | loss 2.09 | nll_loss 0.538 | ppl 1.45 | wps 20458.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 2955 | lr 0.000367918 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2965\n",
            "2023-12-04 21:03:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 741:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:36 | INFO | fairseq.trainer | begin training epoch 741\n",
            "2023-12-04 21:03:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:39 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)\n",
            "2023-12-04 21:03:39 | INFO | train | epoch 741 | loss 2.09 | nll_loss 0.537 | ppl 1.45 | wps 140134 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 2959 | lr 0.000367669 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2968\n",
            "2023-12-04 21:03:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 742:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:39 | INFO | fairseq.trainer | begin training epoch 742\n",
            "2023-12-04 21:03:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:41 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)\n",
            "2023-12-04 21:03:41 | INFO | train | epoch 742 | loss 2.088 | nll_loss 0.536 | ppl 1.45 | wps 143439 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 2963 | lr 0.000367421 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2970\n",
            "2023-12-04 21:03:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 743:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:41 | INFO | fairseq.trainer | begin training epoch 743\n",
            "2023-12-04 21:03:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:44 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)\n",
            "2023-12-04 21:03:44 | INFO | train | epoch 743 | loss 2.089 | nll_loss 0.535 | ppl 1.45 | wps 145015 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 2967 | lr 0.000367173 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2972\n",
            "2023-12-04 21:03:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 744:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:44 | INFO | fairseq.trainer | begin training epoch 744\n",
            "2023-12-04 21:03:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:46 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)\n",
            "2023-12-04 21:03:46 | INFO | train | epoch 744 | loss 2.087 | nll_loss 0.534 | ppl 1.45 | wps 142615 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2971 | lr 0.000366926 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2975\n",
            "2023-12-04 21:03:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 745:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:46 | INFO | fairseq.trainer | begin training epoch 745\n",
            "2023-12-04 21:03:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:48 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)\n",
            "2023-12-04 21:03:48 | INFO | train | epoch 745 | loss 2.089 | nll_loss 0.535 | ppl 1.45 | wps 142749 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2975 | lr 0.000366679 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 2977\n",
            "2023-12-04 21:03:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 746:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:48 | INFO | fairseq.trainer | begin training epoch 746\n",
            "2023-12-04 21:03:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:51 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)\n",
            "2023-12-04 21:03:51 | INFO | train | epoch 746 | loss 2.088 | nll_loss 0.536 | ppl 1.45 | wps 142815 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 2979 | lr 0.000366433 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 2980\n",
            "2023-12-04 21:03:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 747:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:51 | INFO | fairseq.trainer | begin training epoch 747\n",
            "2023-12-04 21:03:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:53 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)\n",
            "2023-12-04 21:03:53 | INFO | train | epoch 747 | loss 2.085 | nll_loss 0.534 | ppl 1.45 | wps 144288 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 2983 | lr 0.000366187 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 2982\n",
            "2023-12-04 21:03:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 748:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:53 | INFO | fairseq.trainer | begin training epoch 748\n",
            "2023-12-04 21:03:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:56 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)\n",
            "2023-12-04 21:03:56 | INFO | train | epoch 748 | loss 2.087 | nll_loss 0.533 | ppl 1.45 | wps 145630 | ups 1.7 | wpb 85903.8 | bsz 1548.2 | num_updates 2987 | lr 0.000365942 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 2984\n",
            "2023-12-04 21:03:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 749:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:56 | INFO | fairseq.trainer | begin training epoch 749\n",
            "2023-12-04 21:03:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:03:58 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)\n",
            "2023-12-04 21:03:58 | INFO | train | epoch 749 | loss 2.087 | nll_loss 0.534 | ppl 1.45 | wps 141858 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 2991 | lr 0.000365697 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.8 | wall 2987\n",
            "2023-12-04 21:03:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 750:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:03:58 | INFO | fairseq.trainer | begin training epoch 750\n",
            "2023-12-04 21:03:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 750:  75% 3/4 [00:01<00:00,  1.61it/s]2023-12-04 21:04:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:04:02 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:04:02 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:04:03 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settemanæ de struttua fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:04:03 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.53s/it]\u001b[A2023-12-04 21:04:05 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ da çerti ponti an produto di additi microonde ò di atri mezi pe rescädatua o çibbo.\n",
            "2023-12-04 21:04:05 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:04:07 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:04:07 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:04:09 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ in sce l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:04:09 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:04:11 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l'à unna superfiçie de 783.562 km (30.948 miggia quaddræ): in sce sti 75.68 km (2917373 quaddræ) in sce l'Asia sud-òvest, ch'a l'é 2376 (29174 d'etæ traverso i quaddræ) in Euröpa.\n",
            "2023-12-04 21:04:11 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:04:12 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî unichi, into meserto d'ottobre, inserçioin personali, un network de nozieh, 24 etctlante, un mondiale, ciammou Duceoldur de Ombur de Or.\n",
            "2023-12-04 21:04:12 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 750 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:04:12 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 6.43 | nll_loss 5.229 | ppl 37.49 | bleu 13.02 | wps 4233 | wpb 7753.9 | bsz 142.4 | num_updates 2995 | best_bleu 13.1\n",
            "2023-12-04 21:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 2995 updates\n",
            "2023-12-04 21:04:12 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint750.pt\n",
            "2023-12-04 21:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint750.pt\n",
            "2023-12-04 21:04:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint750.pt (epoch 750 @ 2995 updates, score 13.02) (writing took 5.467947080000158 seconds)\n",
            "2023-12-04 21:04:18 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)\n",
            "2023-12-04 21:04:18 | INFO | train | epoch 750 | loss 2.086 | nll_loss 0.534 | ppl 1.45 | wps 17253.2 | ups 0.2 | wpb 85903.8 | bsz 1548.2 | num_updates 2995 | lr 0.000365453 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3007\n",
            "2023-12-04 21:04:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 751:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:18 | INFO | fairseq.trainer | begin training epoch 751\n",
            "2023-12-04 21:04:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:20 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)\n",
            "2023-12-04 21:04:20 | INFO | train | epoch 751 | loss 2.087 | nll_loss 0.534 | ppl 1.45 | wps 138847 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 2999 | lr 0.000365209 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3009\n",
            "2023-12-04 21:04:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 752:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:20 | INFO | fairseq.trainer | begin training epoch 752\n",
            "2023-12-04 21:04:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:23 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)\n",
            "2023-12-04 21:04:23 | INFO | train | epoch 752 | loss 2.086 | nll_loss 0.533 | ppl 1.45 | wps 143267 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3003 | lr 0.000364966 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3011\n",
            "2023-12-04 21:04:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 753:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:23 | INFO | fairseq.trainer | begin training epoch 753\n",
            "2023-12-04 21:04:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:25 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)\n",
            "2023-12-04 21:04:25 | INFO | train | epoch 753 | loss 2.086 | nll_loss 0.533 | ppl 1.45 | wps 141579 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3007 | lr 0.000364723 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3014\n",
            "2023-12-04 21:04:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 754:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:25 | INFO | fairseq.trainer | begin training epoch 754\n",
            "2023-12-04 21:04:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:28 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)\n",
            "2023-12-04 21:04:28 | INFO | train | epoch 754 | loss 2.085 | nll_loss 0.534 | ppl 1.45 | wps 141744 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3011 | lr 0.000364481 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3016\n",
            "2023-12-04 21:04:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 755:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:28 | INFO | fairseq.trainer | begin training epoch 755\n",
            "2023-12-04 21:04:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:30 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)\n",
            "2023-12-04 21:04:30 | INFO | train | epoch 755 | loss 2.087 | nll_loss 0.533 | ppl 1.45 | wps 143562 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3015 | lr 0.000364239 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3019\n",
            "2023-12-04 21:04:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 756:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:30 | INFO | fairseq.trainer | begin training epoch 756\n",
            "2023-12-04 21:04:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:32 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)\n",
            "2023-12-04 21:04:32 | INFO | train | epoch 756 | loss 2.085 | nll_loss 0.533 | ppl 1.45 | wps 141809 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3019 | lr 0.000363998 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3021\n",
            "2023-12-04 21:04:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 757:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:33 | INFO | fairseq.trainer | begin training epoch 757\n",
            "2023-12-04 21:04:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:35 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)\n",
            "2023-12-04 21:04:35 | INFO | train | epoch 757 | loss 2.083 | nll_loss 0.529 | ppl 1.44 | wps 126034 | ups 1.47 | wpb 85903.8 | bsz 1548.2 | num_updates 3023 | lr 0.000363757 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3024\n",
            "2023-12-04 21:04:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 758:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:35 | INFO | fairseq.trainer | begin training epoch 758\n",
            "2023-12-04 21:04:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:38 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)\n",
            "2023-12-04 21:04:38 | INFO | train | epoch 758 | loss 2.079 | nll_loss 0.526 | ppl 1.44 | wps 142794 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3027 | lr 0.000363516 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3026\n",
            "2023-12-04 21:04:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 759:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:38 | INFO | fairseq.trainer | begin training epoch 759\n",
            "2023-12-04 21:04:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:40 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)\n",
            "2023-12-04 21:04:40 | INFO | train | epoch 759 | loss 2.081 | nll_loss 0.529 | ppl 1.44 | wps 143721 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3031 | lr 0.000363276 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3029\n",
            "2023-12-04 21:04:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 760:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:40 | INFO | fairseq.trainer | begin training epoch 760\n",
            "2023-12-04 21:04:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 760:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 21:04:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:04:44 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:04:44 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:04:45 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin semanæ de struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:04:45 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.51s/it]\u001b[A2023-12-04 21:04:47 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:04:47 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:04:49 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte requie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:04:49 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.72s/it]\u001b[A2023-12-04 21:04:51 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ inte l’Internet ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:04:51 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.88s/it]\u001b[A2023-12-04 21:04:53 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti 75.68 km (29173 quaddræ) in sce l’Asia sud-òvest de Ponente, 23764 (29173 d’ancheu).\n",
            "2023-12-04 21:04:53 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:04:54 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî unichi into mesegno d'ötovie, inserçioin personali, un network de 5.0024 e o postlante, e un mondo ciammou Duceante, Woldur de Ombur.\n",
            "2023-12-04 21:04:54 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 760 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:04:54 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 6.426 | nll_loss 5.23 | ppl 37.54 | bleu 13 | wps 4212.8 | wpb 7753.9 | bsz 142.4 | num_updates 3035 | best_bleu 13.1\n",
            "2023-12-04 21:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 3035 updates\n",
            "2023-12-04 21:04:54 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint760.pt\n",
            "2023-12-04 21:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint760.pt\n",
            "2023-12-04 21:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint760.pt (epoch 760 @ 3035 updates, score 13.0) (writing took 2.117083453000305 seconds)\n",
            "2023-12-04 21:04:57 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)\n",
            "2023-12-04 21:04:57 | INFO | train | epoch 760 | loss 2.078 | nll_loss 0.524 | ppl 1.44 | wps 20659.8 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3035 | lr 0.000363037 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3045\n",
            "2023-12-04 21:04:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 761:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:57 | INFO | fairseq.trainer | begin training epoch 761\n",
            "2023-12-04 21:04:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:04:59 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)\n",
            "2023-12-04 21:04:59 | INFO | train | epoch 761 | loss 2.08 | nll_loss 0.528 | ppl 1.44 | wps 139757 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3039 | lr 0.000362798 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3048\n",
            "2023-12-04 21:04:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 762:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:04:59 | INFO | fairseq.trainer | begin training epoch 762\n",
            "2023-12-04 21:04:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:02 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)\n",
            "2023-12-04 21:05:02 | INFO | train | epoch 762 | loss 2.078 | nll_loss 0.524 | ppl 1.44 | wps 138647 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 3043 | lr 0.000362559 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3050\n",
            "2023-12-04 21:05:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 763:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:02 | INFO | fairseq.trainer | begin training epoch 763\n",
            "2023-12-04 21:05:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:04 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)\n",
            "2023-12-04 21:05:04 | INFO | train | epoch 763 | loss 2.079 | nll_loss 0.528 | ppl 1.44 | wps 143179 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3047 | lr 0.000362321 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3053\n",
            "2023-12-04 21:05:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 764:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:04 | INFO | fairseq.trainer | begin training epoch 764\n",
            "2023-12-04 21:05:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:06 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)\n",
            "2023-12-04 21:05:06 | INFO | train | epoch 764 | loss 2.078 | nll_loss 0.524 | ppl 1.44 | wps 143803 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3051 | lr 0.000362084 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3055\n",
            "2023-12-04 21:05:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 765:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:06 | INFO | fairseq.trainer | begin training epoch 765\n",
            "2023-12-04 21:05:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:09 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)\n",
            "2023-12-04 21:05:09 | INFO | train | epoch 765 | loss 2.077 | nll_loss 0.526 | ppl 1.44 | wps 141361 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3055 | lr 0.000361847 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3057\n",
            "2023-12-04 21:05:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 766:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:09 | INFO | fairseq.trainer | begin training epoch 766\n",
            "2023-12-04 21:05:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:11 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)\n",
            "2023-12-04 21:05:11 | INFO | train | epoch 766 | loss 2.076 | nll_loss 0.524 | ppl 1.44 | wps 144759 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 3059 | lr 0.00036161 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3060\n",
            "2023-12-04 21:05:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 767:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:11 | INFO | fairseq.trainer | begin training epoch 767\n",
            "2023-12-04 21:05:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:14 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)\n",
            "2023-12-04 21:05:14 | INFO | train | epoch 767 | loss 2.076 | nll_loss 0.521 | ppl 1.44 | wps 140260 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3063 | lr 0.000361374 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3062\n",
            "2023-12-04 21:05:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 768:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:14 | INFO | fairseq.trainer | begin training epoch 768\n",
            "2023-12-04 21:05:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:16 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)\n",
            "2023-12-04 21:05:16 | INFO | train | epoch 768 | loss 2.078 | nll_loss 0.528 | ppl 1.44 | wps 142107 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3067 | lr 0.000361138 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3065\n",
            "2023-12-04 21:05:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 769:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:16 | INFO | fairseq.trainer | begin training epoch 769\n",
            "2023-12-04 21:05:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:18 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)\n",
            "2023-12-04 21:05:18 | INFO | train | epoch 769 | loss 2.075 | nll_loss 0.522 | ppl 1.44 | wps 142579 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3071 | lr 0.000360903 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3067\n",
            "2023-12-04 21:05:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 770:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:18 | INFO | fairseq.trainer | begin training epoch 770\n",
            "2023-12-04 21:05:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 770:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:05:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:05:22 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:05:22 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:05:24 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:05:24 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.51s/it]\u001b[A2023-12-04 21:05:25 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de çibinti. Al òffiti an fornio à di microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:05:25 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 21:05:27 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:05:27 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:05:29 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon in sce lonque inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:05:29 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:05:31 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) che s’attreuva inte l’Asia sud-òvest de Ponente, 2376 (29174 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:05:31 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:05:33 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh 24 estlante, ch'o l'é stæto lasciou à Duceante, Woldur de Omburto.\n",
            "2023-12-04 21:05:33 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 770 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.75s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:05:33 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 6.437 | nll_loss 5.245 | ppl 37.92 | bleu 13.21 | wps 4193 | wpb 7753.9 | bsz 142.4 | num_updates 3075 | best_bleu 13.21\n",
            "2023-12-04 21:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 3075 updates\n",
            "2023-12-04 21:05:33 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint770.pt\n",
            "2023-12-04 21:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint770.pt\n",
            "2023-12-04 21:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint770.pt (epoch 770 @ 3075 updates, score 13.21) (writing took 3.761384521999844 seconds)\n",
            "2023-12-04 21:05:37 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)\n",
            "2023-12-04 21:05:37 | INFO | train | epoch 770 | loss 2.074 | nll_loss 0.522 | ppl 1.44 | wps 18790.5 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 3075 | lr 0.000360668 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3085\n",
            "2023-12-04 21:05:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 771:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:37 | INFO | fairseq.trainer | begin training epoch 771\n",
            "2023-12-04 21:05:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:39 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)\n",
            "2023-12-04 21:05:39 | INFO | train | epoch 771 | loss 2.075 | nll_loss 0.523 | ppl 1.44 | wps 139905 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3079 | lr 0.000360434 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3088\n",
            "2023-12-04 21:05:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 772:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:39 | INFO | fairseq.trainer | begin training epoch 772\n",
            "2023-12-04 21:05:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:42 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)\n",
            "2023-12-04 21:05:42 | INFO | train | epoch 772 | loss 2.074 | nll_loss 0.523 | ppl 1.44 | wps 140725 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3083 | lr 0.0003602 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3090\n",
            "2023-12-04 21:05:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 773:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:42 | INFO | fairseq.trainer | begin training epoch 773\n",
            "2023-12-04 21:05:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:44 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)\n",
            "2023-12-04 21:05:44 | INFO | train | epoch 773 | loss 2.077 | nll_loss 0.525 | ppl 1.44 | wps 145947 | ups 1.7 | wpb 85903.8 | bsz 1548.2 | num_updates 3087 | lr 0.000359966 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3093\n",
            "2023-12-04 21:05:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 774:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:44 | INFO | fairseq.trainer | begin training epoch 774\n",
            "2023-12-04 21:05:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:46 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)\n",
            "2023-12-04 21:05:46 | INFO | train | epoch 774 | loss 2.073 | nll_loss 0.52 | ppl 1.43 | wps 144454 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3091 | lr 0.000359733 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3095\n",
            "2023-12-04 21:05:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 775:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:46 | INFO | fairseq.trainer | begin training epoch 775\n",
            "2023-12-04 21:05:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:49 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)\n",
            "2023-12-04 21:05:49 | INFO | train | epoch 775 | loss 2.072 | nll_loss 0.522 | ppl 1.44 | wps 139710 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3095 | lr 0.000359501 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3097\n",
            "2023-12-04 21:05:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 776:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:49 | INFO | fairseq.trainer | begin training epoch 776\n",
            "2023-12-04 21:05:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:51 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)\n",
            "2023-12-04 21:05:51 | INFO | train | epoch 776 | loss 2.072 | nll_loss 0.519 | ppl 1.43 | wps 143655 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3099 | lr 0.000359269 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3100\n",
            "2023-12-04 21:05:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 777:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:51 | INFO | fairseq.trainer | begin training epoch 777\n",
            "2023-12-04 21:05:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:54 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)\n",
            "2023-12-04 21:05:54 | INFO | train | epoch 777 | loss 2.073 | nll_loss 0.522 | ppl 1.44 | wps 141327 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3103 | lr 0.000359037 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3102\n",
            "2023-12-04 21:05:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 778:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:54 | INFO | fairseq.trainer | begin training epoch 778\n",
            "2023-12-04 21:05:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:56 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)\n",
            "2023-12-04 21:05:56 | INFO | train | epoch 778 | loss 2.069 | nll_loss 0.518 | ppl 1.43 | wps 143491 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3107 | lr 0.000358806 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3105\n",
            "2023-12-04 21:05:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 779:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:56 | INFO | fairseq.trainer | begin training epoch 779\n",
            "2023-12-04 21:05:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:05:58 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)\n",
            "2023-12-04 21:05:58 | INFO | train | epoch 779 | loss 2.068 | nll_loss 0.516 | ppl 1.43 | wps 144300 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3111 | lr 0.000358575 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3107\n",
            "2023-12-04 21:05:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 780:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:05:58 | INFO | fairseq.trainer | begin training epoch 780\n",
            "2023-12-04 21:05:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 780:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:06:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:06:02 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:06:02 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:06:04 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settemanæ de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:06:04 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:06:05 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:06:05 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.54s/it]\u001b[A2023-12-04 21:06:07 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:06:07 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  57% 4/7 [00:06<00:04,  1.66s/it]\u001b[A2023-12-04 21:06:09 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; pe de ciù in sce l’Internet ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:06:09 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.81s/it]\u001b[A2023-12-04 21:06:11 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): de sti 75.68 km (29173 quaddræ) in sciâ scituæ inte l’Asia sud-òvest de Ponente, 2376 (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:06:11 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.72s/it]\u001b[A2023-12-04 21:06:12 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî de vixitatoî unichi into meserto d'ottobre, inserçioin personali, un network de noçieh, 24 etlante à Duceante, ciammou Dumbur de Ombur, Wor.\n",
            "2023-12-04 21:06:13 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 780 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.70s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:06:13 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 6.432 | nll_loss 5.239 | ppl 37.76 | bleu 13.02 | wps 4315.6 | wpb 7753.9 | bsz 142.4 | num_updates 3115 | best_bleu 13.21\n",
            "2023-12-04 21:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 3115 updates\n",
            "2023-12-04 21:06:13 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint780.pt\n",
            "2023-12-04 21:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint780.pt\n",
            "2023-12-04 21:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint780.pt (epoch 780 @ 3115 updates, score 13.02) (writing took 4.462114389000362 seconds)\n",
            "2023-12-04 21:06:17 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)\n",
            "2023-12-04 21:06:17 | INFO | train | epoch 780 | loss 2.07 | nll_loss 0.518 | ppl 1.43 | wps 18405.6 | ups 0.21 | wpb 85903.8 | bsz 1548.2 | num_updates 3115 | lr 0.000358345 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3126\n",
            "2023-12-04 21:06:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 781:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:17 | INFO | fairseq.trainer | begin training epoch 781\n",
            "2023-12-04 21:06:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:19 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)\n",
            "2023-12-04 21:06:19 | INFO | train | epoch 781 | loss 2.068 | nll_loss 0.517 | ppl 1.43 | wps 141027 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3119 | lr 0.000358115 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3128\n",
            "2023-12-04 21:06:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 782:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:20 | INFO | fairseq.trainer | begin training epoch 782\n",
            "2023-12-04 21:06:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:22 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)\n",
            "2023-12-04 21:06:22 | INFO | train | epoch 782 | loss 2.067 | nll_loss 0.513 | ppl 1.43 | wps 140728 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3123 | lr 0.000357885 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3131\n",
            "2023-12-04 21:06:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 783:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:22 | INFO | fairseq.trainer | begin training epoch 783\n",
            "2023-12-04 21:06:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:24 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)\n",
            "2023-12-04 21:06:24 | INFO | train | epoch 783 | loss 2.067 | nll_loss 0.517 | ppl 1.43 | wps 142180 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3127 | lr 0.000357656 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3133\n",
            "2023-12-04 21:06:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 784:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:24 | INFO | fairseq.trainer | begin training epoch 784\n",
            "2023-12-04 21:06:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:27 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)\n",
            "2023-12-04 21:06:27 | INFO | train | epoch 784 | loss 2.067 | nll_loss 0.515 | ppl 1.43 | wps 140089 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3131 | lr 0.000357428 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3136\n",
            "2023-12-04 21:06:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 785:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:27 | INFO | fairseq.trainer | begin training epoch 785\n",
            "2023-12-04 21:06:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:29 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)\n",
            "2023-12-04 21:06:29 | INFO | train | epoch 785 | loss 2.068 | nll_loss 0.518 | ppl 1.43 | wps 140506 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3135 | lr 0.0003572 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3138\n",
            "2023-12-04 21:06:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 786:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:29 | INFO | fairseq.trainer | begin training epoch 786\n",
            "2023-12-04 21:06:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:32 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)\n",
            "2023-12-04 21:06:32 | INFO | train | epoch 786 | loss 2.067 | nll_loss 0.515 | ppl 1.43 | wps 140998 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3139 | lr 0.000356972 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3140\n",
            "2023-12-04 21:06:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 787:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:32 | INFO | fairseq.trainer | begin training epoch 787\n",
            "2023-12-04 21:06:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:34 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)\n",
            "2023-12-04 21:06:34 | INFO | train | epoch 787 | loss 2.069 | nll_loss 0.518 | ppl 1.43 | wps 141659 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3143 | lr 0.000356745 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3143\n",
            "2023-12-04 21:06:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 788:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:34 | INFO | fairseq.trainer | begin training epoch 788\n",
            "2023-12-04 21:06:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:37 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)\n",
            "2023-12-04 21:06:37 | INFO | train | epoch 788 | loss 2.065 | nll_loss 0.514 | ppl 1.43 | wps 140565 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3147 | lr 0.000356518 | gnorm 0.149 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3145\n",
            "2023-12-04 21:06:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 789:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:37 | INFO | fairseq.trainer | begin training epoch 789\n",
            "2023-12-04 21:06:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:39 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)\n",
            "2023-12-04 21:06:39 | INFO | train | epoch 789 | loss 2.068 | nll_loss 0.515 | ppl 1.43 | wps 140656 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3151 | lr 0.000356292 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3148\n",
            "2023-12-04 21:06:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 790:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:39 | INFO | fairseq.trainer | begin training epoch 790\n",
            "2023-12-04 21:06:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 790:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:06:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:06:43 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:06:43 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:06:44 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:06:44 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 21:06:46 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibi Alcuni an produto di microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:06:46 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:06:48 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:06:50 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon in sce l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:06:50 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:06:52 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) in sce l’Asia sud-òvest de Ponente, 23764 (29173 d’ancheu (e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:06:52 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 21:06:53 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu eutto, The Onion o l'é vegnuo un veo da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.000 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de nozieh, 24 etlante, un mondo a piggiava do tutto o nomme de Omburto.\n",
            "2023-12-04 21:06:53 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 790 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.70s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:06:53 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 6.435 | nll_loss 5.242 | ppl 37.84 | bleu 13.15 | wps 4270.9 | wpb 7753.9 | bsz 142.4 | num_updates 3155 | best_bleu 13.21\n",
            "2023-12-04 21:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 3155 updates\n",
            "2023-12-04 21:06:53 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint790.pt\n",
            "2023-12-04 21:06:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint790.pt\n",
            "2023-12-04 21:06:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint790.pt (epoch 790 @ 3155 updates, score 13.15) (writing took 2.128935647000162 seconds)\n",
            "2023-12-04 21:06:55 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)\n",
            "2023-12-04 21:06:55 | INFO | train | epoch 790 | loss 2.066 | nll_loss 0.517 | ppl 1.43 | wps 20843.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3155 | lr 0.000356066 | gnorm 0.146 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3164\n",
            "2023-12-04 21:06:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 791:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:56 | INFO | fairseq.trainer | begin training epoch 791\n",
            "2023-12-04 21:06:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:06:58 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)\n",
            "2023-12-04 21:06:58 | INFO | train | epoch 791 | loss 2.065 | nll_loss 0.513 | ppl 1.43 | wps 139859 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3159 | lr 0.00035584 | gnorm 0.142 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3167\n",
            "2023-12-04 21:06:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 792:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:06:58 | INFO | fairseq.trainer | begin training epoch 792\n",
            "2023-12-04 21:06:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:00 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)\n",
            "2023-12-04 21:07:00 | INFO | train | epoch 792 | loss 2.065 | nll_loss 0.514 | ppl 1.43 | wps 143732 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3163 | lr 0.000355615 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3169\n",
            "2023-12-04 21:07:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 793:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:00 | INFO | fairseq.trainer | begin training epoch 793\n",
            "2023-12-04 21:07:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:03 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)\n",
            "2023-12-04 21:07:03 | INFO | train | epoch 793 | loss 2.066 | nll_loss 0.516 | ppl 1.43 | wps 142654 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3167 | lr 0.000355391 | gnorm 0.148 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3171\n",
            "2023-12-04 21:07:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 794:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:03 | INFO | fairseq.trainer | begin training epoch 794\n",
            "2023-12-04 21:07:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:05 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)\n",
            "2023-12-04 21:07:05 | INFO | train | epoch 794 | loss 2.066 | nll_loss 0.514 | ppl 1.43 | wps 142800 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3171 | lr 0.000355166 | gnorm 0.141 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3174\n",
            "2023-12-04 21:07:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 795:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:05 | INFO | fairseq.trainer | begin training epoch 795\n",
            "2023-12-04 21:07:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:08 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)\n",
            "2023-12-04 21:07:08 | INFO | train | epoch 795 | loss 2.062 | nll_loss 0.512 | ppl 1.43 | wps 142195 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3175 | lr 0.000354943 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3176\n",
            "2023-12-04 21:07:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 796:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:08 | INFO | fairseq.trainer | begin training epoch 796\n",
            "2023-12-04 21:07:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:10 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)\n",
            "2023-12-04 21:07:10 | INFO | train | epoch 796 | loss 2.061 | nll_loss 0.51 | ppl 1.42 | wps 144136 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3179 | lr 0.000354719 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3179\n",
            "2023-12-04 21:07:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 797:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:10 | INFO | fairseq.trainer | begin training epoch 797\n",
            "2023-12-04 21:07:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:12 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)\n",
            "2023-12-04 21:07:12 | INFO | train | epoch 797 | loss 2.062 | nll_loss 0.51 | ppl 1.42 | wps 139507 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3183 | lr 0.000354496 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3181\n",
            "2023-12-04 21:07:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 798:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:12 | INFO | fairseq.trainer | begin training epoch 798\n",
            "2023-12-04 21:07:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:15 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)\n",
            "2023-12-04 21:07:15 | INFO | train | epoch 798 | loss 2.061 | nll_loss 0.511 | ppl 1.43 | wps 143500 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3187 | lr 0.000354274 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3184\n",
            "2023-12-04 21:07:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 799:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:15 | INFO | fairseq.trainer | begin training epoch 799\n",
            "2023-12-04 21:07:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:17 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)\n",
            "2023-12-04 21:07:17 | INFO | train | epoch 799 | loss 2.06 | nll_loss 0.508 | ppl 1.42 | wps 139769 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3191 | lr 0.000354052 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3186\n",
            "2023-12-04 21:07:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 800:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:17 | INFO | fairseq.trainer | begin training epoch 800\n",
            "2023-12-04 21:07:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 800:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:07:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:07:21 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:07:21 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:07:23 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:07:23 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.69s/it]\u001b[A2023-12-04 21:07:25 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an produto di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:07:25 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.67s/it]\u001b[A2023-12-04 21:07:26 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:07:26 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.72s/it]\u001b[A2023-12-04 21:07:28 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; pe de ciù o trovâ inte l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:07:28 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:07:30 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest, e 23764 (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:07:30 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.74s/it]\u001b[A2023-12-04 21:07:32 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî unichi, into mese d'ottobre, inserçioin personali, un network de nozieh 24,4 ch'o l'é stæto lasciou un mondiale etlante, ciammou Dumbur de Ombur.\n",
            "2023-12-04 21:07:32 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 800 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:07:32 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 6.424 | nll_loss 5.237 | ppl 37.72 | bleu 13.08 | wps 4169.3 | wpb 7753.9 | bsz 142.4 | num_updates 3195 | best_bleu 13.21\n",
            "2023-12-04 21:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 3195 updates\n",
            "2023-12-04 21:07:32 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint800.pt\n",
            "2023-12-04 21:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint800.pt\n",
            "2023-12-04 21:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint800.pt (epoch 800 @ 3195 updates, score 13.08) (writing took 2.128887129999839 seconds)\n",
            "2023-12-04 21:07:34 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)\n",
            "2023-12-04 21:07:34 | INFO | train | epoch 800 | loss 2.059 | nll_loss 0.507 | ppl 1.42 | wps 20564.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3195 | lr 0.00035383 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3203\n",
            "2023-12-04 21:07:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 801:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:34 | INFO | fairseq.trainer | begin training epoch 801\n",
            "2023-12-04 21:07:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:36 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)\n",
            "2023-12-04 21:07:36 | INFO | train | epoch 801 | loss 2.058 | nll_loss 0.509 | ppl 1.42 | wps 140752 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3199 | lr 0.000353609 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3205\n",
            "2023-12-04 21:07:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 802:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:36 | INFO | fairseq.trainer | begin training epoch 802\n",
            "2023-12-04 21:07:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:39 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)\n",
            "2023-12-04 21:07:39 | INFO | train | epoch 802 | loss 2.058 | nll_loss 0.507 | ppl 1.42 | wps 140406 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3203 | lr 0.000353388 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3208\n",
            "2023-12-04 21:07:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 803:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:39 | INFO | fairseq.trainer | begin training epoch 803\n",
            "2023-12-04 21:07:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:41 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)\n",
            "2023-12-04 21:07:41 | INFO | train | epoch 803 | loss 2.058 | nll_loss 0.507 | ppl 1.42 | wps 142349 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3207 | lr 0.000353167 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3210\n",
            "2023-12-04 21:07:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 804:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:41 | INFO | fairseq.trainer | begin training epoch 804\n",
            "2023-12-04 21:07:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:44 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)\n",
            "2023-12-04 21:07:44 | INFO | train | epoch 804 | loss 2.059 | nll_loss 0.508 | ppl 1.42 | wps 129795 | ups 1.51 | wpb 85903.8 | bsz 1548.2 | num_updates 3211 | lr 0.000352947 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3213\n",
            "2023-12-04 21:07:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 805:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:44 | INFO | fairseq.trainer | begin training epoch 805\n",
            "2023-12-04 21:07:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:46 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)\n",
            "2023-12-04 21:07:46 | INFO | train | epoch 805 | loss 2.059 | nll_loss 0.507 | ppl 1.42 | wps 146254 | ups 1.7 | wpb 85903.8 | bsz 1548.2 | num_updates 3215 | lr 0.000352728 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3215\n",
            "2023-12-04 21:07:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 806:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:46 | INFO | fairseq.trainer | begin training epoch 806\n",
            "2023-12-04 21:07:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:49 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)\n",
            "2023-12-04 21:07:49 | INFO | train | epoch 806 | loss 2.057 | nll_loss 0.507 | ppl 1.42 | wps 142520 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3219 | lr 0.000352508 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3217\n",
            "2023-12-04 21:07:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 807:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:49 | INFO | fairseq.trainer | begin training epoch 807\n",
            "2023-12-04 21:07:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:51 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)\n",
            "2023-12-04 21:07:51 | INFO | train | epoch 807 | loss 2.055 | nll_loss 0.504 | ppl 1.42 | wps 141334 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3223 | lr 0.00035229 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3220\n",
            "2023-12-04 21:07:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 808:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:51 | INFO | fairseq.trainer | begin training epoch 808\n",
            "2023-12-04 21:07:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:54 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)\n",
            "2023-12-04 21:07:54 | INFO | train | epoch 808 | loss 2.054 | nll_loss 0.504 | ppl 1.42 | wps 142430 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3227 | lr 0.000352071 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3222\n",
            "2023-12-04 21:07:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 809:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:54 | INFO | fairseq.trainer | begin training epoch 809\n",
            "2023-12-04 21:07:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:07:56 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)\n",
            "2023-12-04 21:07:56 | INFO | train | epoch 809 | loss 2.056 | nll_loss 0.505 | ppl 1.42 | wps 141697 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3231 | lr 0.000351853 | gnorm 0.137 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3225\n",
            "2023-12-04 21:07:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 810:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:07:56 | INFO | fairseq.trainer | begin training epoch 810\n",
            "2023-12-04 21:07:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 810:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:07:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:08:00 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, inte Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:08:00 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:08:01 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:08:01 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.54s/it]\u001b[A2023-12-04 21:08:03 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che gh’an di offiti à fiña da microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:08:03 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:08:05 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:08:05 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:08:07 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:08:07 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:08:09 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest, e 23764 (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:08:09 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:08:10 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh 24, etlante à Duceante, ciammou Ombur à Duce.\n",
            "2023-12-04 21:08:10 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 810 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:08:10 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 6.427 | nll_loss 5.241 | ppl 37.82 | bleu 13.05 | wps 4229 | wpb 7753.9 | bsz 142.4 | num_updates 3235 | best_bleu 13.21\n",
            "2023-12-04 21:08:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 3235 updates\n",
            "2023-12-04 21:08:10 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint810.pt\n",
            "2023-12-04 21:08:12 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint810.pt\n",
            "2023-12-04 21:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint810.pt (epoch 810 @ 3235 updates, score 13.05) (writing took 2.126223688999744 seconds)\n",
            "2023-12-04 21:08:13 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)\n",
            "2023-12-04 21:08:13 | INFO | train | epoch 810 | loss 2.055 | nll_loss 0.504 | ppl 1.42 | wps 20721.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3235 | lr 0.000351636 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3241\n",
            "2023-12-04 21:08:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 811:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:13 | INFO | fairseq.trainer | begin training epoch 811\n",
            "2023-12-04 21:08:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:15 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)\n",
            "2023-12-04 21:08:15 | INFO | train | epoch 811 | loss 2.055 | nll_loss 0.504 | ppl 1.42 | wps 140948 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3239 | lr 0.000351418 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3244\n",
            "2023-12-04 21:08:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 812:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:15 | INFO | fairseq.trainer | begin training epoch 812\n",
            "2023-12-04 21:08:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:17 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)\n",
            "2023-12-04 21:08:17 | INFO | train | epoch 812 | loss 2.053 | nll_loss 0.504 | ppl 1.42 | wps 139748 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3243 | lr 0.000351202 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3246\n",
            "2023-12-04 21:08:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 813:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:17 | INFO | fairseq.trainer | begin training epoch 813\n",
            "2023-12-04 21:08:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:20 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)\n",
            "2023-12-04 21:08:20 | INFO | train | epoch 813 | loss 2.053 | nll_loss 0.502 | ppl 1.42 | wps 142677 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3247 | lr 0.000350985 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3249\n",
            "2023-12-04 21:08:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 814:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:20 | INFO | fairseq.trainer | begin training epoch 814\n",
            "2023-12-04 21:08:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:22 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)\n",
            "2023-12-04 21:08:22 | INFO | train | epoch 814 | loss 2.054 | nll_loss 0.504 | ppl 1.42 | wps 140435 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3251 | lr 0.000350769 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3251\n",
            "2023-12-04 21:08:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 815:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:22 | INFO | fairseq.trainer | begin training epoch 815\n",
            "2023-12-04 21:08:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:25 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)\n",
            "2023-12-04 21:08:25 | INFO | train | epoch 815 | loss 2.053 | nll_loss 0.502 | ppl 1.42 | wps 141159 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3255 | lr 0.000350554 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3253\n",
            "2023-12-04 21:08:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 816:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:25 | INFO | fairseq.trainer | begin training epoch 816\n",
            "2023-12-04 21:08:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:27 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)\n",
            "2023-12-04 21:08:27 | INFO | train | epoch 816 | loss 2.051 | nll_loss 0.501 | ppl 1.42 | wps 144538 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3259 | lr 0.000350338 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3256\n",
            "2023-12-04 21:08:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 817:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:27 | INFO | fairseq.trainer | begin training epoch 817\n",
            "2023-12-04 21:08:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:30 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)\n",
            "2023-12-04 21:08:30 | INFO | train | epoch 817 | loss 2.051 | nll_loss 0.499 | ppl 1.41 | wps 140820 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3263 | lr 0.000350124 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3258\n",
            "2023-12-04 21:08:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 818:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:30 | INFO | fairseq.trainer | begin training epoch 818\n",
            "2023-12-04 21:08:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:32 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)\n",
            "2023-12-04 21:08:32 | INFO | train | epoch 818 | loss 2.049 | nll_loss 0.499 | ppl 1.41 | wps 142658 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3267 | lr 0.000349909 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3261\n",
            "2023-12-04 21:08:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 819:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:32 | INFO | fairseq.trainer | begin training epoch 819\n",
            "2023-12-04 21:08:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:34 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)\n",
            "2023-12-04 21:08:34 | INFO | train | epoch 819 | loss 2.05 | nll_loss 0.5 | ppl 1.41 | wps 142548 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3271 | lr 0.000349695 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3263\n",
            "2023-12-04 21:08:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 820:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:34 | INFO | fairseq.trainer | begin training epoch 820\n",
            "2023-12-04 21:08:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 820:  75% 3/4 [00:01<00:00,  1.61it/s]2023-12-04 21:08:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:08:38 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:08:38 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.42s/it]\u001b[A2023-12-04 21:08:40 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settematiche struttua de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:08:40 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.49s/it]\u001b[A2023-12-04 21:08:41 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù supermercati propoñan un reparto con unna ciù grande çernia de çibinti ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:08:41 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.55s/it]\u001b[A2023-12-04 21:08:43 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à divampou un inçendio, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:08:43 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.67s/it]\u001b[A2023-12-04 21:08:45 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon in sce lonquente ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:08:45 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.83s/it]\u001b[A2023-12-04 21:08:47 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa in sce sti quaddræ): 75.68 km (2917373 quaddræ) in sce l’Asia sud-òvest, ch’o l’à 23764 km (174 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:08:47 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:08:49 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un erto web pe attiâ de 5.00.00 vixitatoî de vixitatoî unichi into meise d'ötovie, inserçioin personali, un network de nòçieh24, ch'o l'é stæto lasciou à Duceante, Wombur de Dudwor.\n",
            "2023-12-04 21:08:49 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 820 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:08:49 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 6.44 | nll_loss 5.253 | ppl 38.14 | bleu 13.13 | wps 4263.5 | wpb 7753.9 | bsz 142.4 | num_updates 3275 | best_bleu 13.21\n",
            "2023-12-04 21:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 3275 updates\n",
            "2023-12-04 21:08:49 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint820.pt\n",
            "2023-12-04 21:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint820.pt\n",
            "2023-12-04 21:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint820.pt (epoch 820 @ 3275 updates, score 13.13) (writing took 2.11051068200004 seconds)\n",
            "2023-12-04 21:08:51 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)\n",
            "2023-12-04 21:08:51 | INFO | train | epoch 820 | loss 2.049 | nll_loss 0.497 | ppl 1.41 | wps 20877.8 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3275 | lr 0.000349482 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3280\n",
            "2023-12-04 21:08:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 821:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:51 | INFO | fairseq.trainer | begin training epoch 821\n",
            "2023-12-04 21:08:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:53 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)\n",
            "2023-12-04 21:08:53 | INFO | train | epoch 821 | loss 2.05 | nll_loss 0.501 | ppl 1.41 | wps 142042 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3279 | lr 0.000349268 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3282\n",
            "2023-12-04 21:08:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 822:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:53 | INFO | fairseq.trainer | begin training epoch 822\n",
            "2023-12-04 21:08:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:56 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)\n",
            "2023-12-04 21:08:56 | INFO | train | epoch 822 | loss 2.049 | nll_loss 0.499 | ppl 1.41 | wps 143923 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3283 | lr 0.000349056 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3284\n",
            "2023-12-04 21:08:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 823:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:56 | INFO | fairseq.trainer | begin training epoch 823\n",
            "2023-12-04 21:08:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:08:58 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)\n",
            "2023-12-04 21:08:58 | INFO | train | epoch 823 | loss 2.051 | nll_loss 0.503 | ppl 1.42 | wps 143960 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3287 | lr 0.000348843 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3287\n",
            "2023-12-04 21:08:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 824:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:08:58 | INFO | fairseq.trainer | begin training epoch 824\n",
            "2023-12-04 21:08:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:00 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)\n",
            "2023-12-04 21:09:00 | INFO | train | epoch 824 | loss 2.051 | nll_loss 0.502 | ppl 1.42 | wps 143158 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3291 | lr 0.000348631 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3289\n",
            "2023-12-04 21:09:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 825:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:00 | INFO | fairseq.trainer | begin training epoch 825\n",
            "2023-12-04 21:09:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:03 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)\n",
            "2023-12-04 21:09:03 | INFO | train | epoch 825 | loss 2.049 | nll_loss 0.498 | ppl 1.41 | wps 143982 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3295 | lr 0.000348419 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3292\n",
            "2023-12-04 21:09:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 826:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:03 | INFO | fairseq.trainer | begin training epoch 826\n",
            "2023-12-04 21:09:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:05 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)\n",
            "2023-12-04 21:09:05 | INFO | train | epoch 826 | loss 2.048 | nll_loss 0.497 | ppl 1.41 | wps 143134 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3299 | lr 0.000348208 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3294\n",
            "2023-12-04 21:09:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 827:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:05 | INFO | fairseq.trainer | begin training epoch 827\n",
            "2023-12-04 21:09:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:08 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)\n",
            "2023-12-04 21:09:08 | INFO | train | epoch 827 | loss 2.049 | nll_loss 0.499 | ppl 1.41 | wps 144503 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3303 | lr 0.000347997 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3296\n",
            "2023-12-04 21:09:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 828:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:08 | INFO | fairseq.trainer | begin training epoch 828\n",
            "2023-12-04 21:09:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:10 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)\n",
            "2023-12-04 21:09:10 | INFO | train | epoch 828 | loss 2.049 | nll_loss 0.502 | ppl 1.42 | wps 143507 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3307 | lr 0.000347787 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3299\n",
            "2023-12-04 21:09:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 829:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:10 | INFO | fairseq.trainer | begin training epoch 829\n",
            "2023-12-04 21:09:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:12 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)\n",
            "2023-12-04 21:09:12 | INFO | train | epoch 829 | loss 2.045 | nll_loss 0.494 | ppl 1.41 | wps 140314 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3311 | lr 0.000347576 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3301\n",
            "2023-12-04 21:09:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 830:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:12 | INFO | fairseq.trainer | begin training epoch 830\n",
            "2023-12-04 21:09:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 830:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 21:09:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:09:16 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:09:16 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 21:09:18 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e settematiche struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:09:18 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:09:19 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che Aldun òffiti an fornio à di microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:09:19 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:09:21 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:09:21 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:09:24 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:09:24 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.91s/it]\u001b[A2023-12-04 21:09:25 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) in sciâ scituæ inte l’Asia sud-òvest de Ponente, 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:09:25 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:09:27 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh, 24 d'ascio do mondo etlante, stæto ciammou Ducente, Wombur de Ombur.\n",
            "2023-12-04 21:09:27 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 830 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:09:27 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 6.436 | nll_loss 5.252 | ppl 38.12 | bleu 12.88 | wps 4187.1 | wpb 7753.9 | bsz 142.4 | num_updates 3315 | best_bleu 13.21\n",
            "2023-12-04 21:09:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 3315 updates\n",
            "2023-12-04 21:09:27 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint830.pt\n",
            "2023-12-04 21:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint830.pt\n",
            "2023-12-04 21:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint830.pt (epoch 830 @ 3315 updates, score 12.88) (writing took 2.126647208000122 seconds)\n",
            "2023-12-04 21:09:29 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)\n",
            "2023-12-04 21:09:29 | INFO | train | epoch 830 | loss 2.046 | nll_loss 0.496 | ppl 1.41 | wps 20641.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3315 | lr 0.000347367 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3318\n",
            "2023-12-04 21:09:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 831:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:29 | INFO | fairseq.trainer | begin training epoch 831\n",
            "2023-12-04 21:09:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:32 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)\n",
            "2023-12-04 21:09:32 | INFO | train | epoch 831 | loss 2.046 | nll_loss 0.497 | ppl 1.41 | wps 139332 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3319 | lr 0.000347157 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3320\n",
            "2023-12-04 21:09:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 832:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:32 | INFO | fairseq.trainer | begin training epoch 832\n",
            "2023-12-04 21:09:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:34 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)\n",
            "2023-12-04 21:09:34 | INFO | train | epoch 832 | loss 2.045 | nll_loss 0.495 | ppl 1.41 | wps 141360 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3323 | lr 0.000346948 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3323\n",
            "2023-12-04 21:09:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 833:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:34 | INFO | fairseq.trainer | begin training epoch 833\n",
            "2023-12-04 21:09:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:36 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)\n",
            "2023-12-04 21:09:36 | INFO | train | epoch 833 | loss 2.044 | nll_loss 0.493 | ppl 1.41 | wps 143829 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3327 | lr 0.00034674 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3325\n",
            "2023-12-04 21:09:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 834:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:36 | INFO | fairseq.trainer | begin training epoch 834\n",
            "2023-12-04 21:09:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:39 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)\n",
            "2023-12-04 21:09:39 | INFO | train | epoch 834 | loss 2.042 | nll_loss 0.493 | ppl 1.41 | wps 144802 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 3331 | lr 0.000346531 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3327\n",
            "2023-12-04 21:09:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 835:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:39 | INFO | fairseq.trainer | begin training epoch 835\n",
            "2023-12-04 21:09:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:41 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)\n",
            "2023-12-04 21:09:41 | INFO | train | epoch 835 | loss 2.044 | nll_loss 0.495 | ppl 1.41 | wps 143443 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3335 | lr 0.000346324 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3330\n",
            "2023-12-04 21:09:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 836:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:41 | INFO | fairseq.trainer | begin training epoch 836\n",
            "2023-12-04 21:09:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:44 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)\n",
            "2023-12-04 21:09:44 | INFO | train | epoch 836 | loss 2.043 | nll_loss 0.492 | ppl 1.41 | wps 144444 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3339 | lr 0.000346116 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3332\n",
            "2023-12-04 21:09:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 837:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:44 | INFO | fairseq.trainer | begin training epoch 837\n",
            "2023-12-04 21:09:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:46 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)\n",
            "2023-12-04 21:09:46 | INFO | train | epoch 837 | loss 2.042 | nll_loss 0.494 | ppl 1.41 | wps 143035 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3343 | lr 0.000345909 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3335\n",
            "2023-12-04 21:09:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 838:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:46 | INFO | fairseq.trainer | begin training epoch 838\n",
            "2023-12-04 21:09:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:48 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)\n",
            "2023-12-04 21:09:48 | INFO | train | epoch 838 | loss 2.043 | nll_loss 0.493 | ppl 1.41 | wps 141247 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3347 | lr 0.000345702 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3337\n",
            "2023-12-04 21:09:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 839:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:48 | INFO | fairseq.trainer | begin training epoch 839\n",
            "2023-12-04 21:09:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:09:51 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)\n",
            "2023-12-04 21:09:51 | INFO | train | epoch 839 | loss 2.04 | nll_loss 0.489 | ppl 1.4 | wps 142942 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3351 | lr 0.000345496 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3339\n",
            "2023-12-04 21:09:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 840:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:09:51 | INFO | fairseq.trainer | begin training epoch 840\n",
            "2023-12-04 21:09:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 840:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:09:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:09:55 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:09:55 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.43s/it]\u001b[A2023-12-04 21:09:56 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematiche struttua de attivitæ fixica, a deprescion e a miagia.\n",
            "2023-12-04 21:09:56 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.56s/it]\u001b[A2023-12-04 21:09:58 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de gibinti ò an produto di additi microonde ò di atri mezi pe rescädatua do çibbo.\n",
            "2023-12-04 21:09:58 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:10:00 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:10:00 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.84s/it]\u001b[A2023-12-04 21:10:02 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; o l’agge trovou ancon inte l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:10:02 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  71% 5/7 [00:09<00:04,  2.00s/it]\u001b[A2023-12-04 21:10:04 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti 75.68 km (2917373 quaddræ) in sce l’Asia sud-òvest de Ponente, 23764 (29174 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:10:04 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.84s/it]\u001b[A2023-12-04 21:10:06 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî unichi, into meserto d'ottobre, inserçioin personali, un network de nòçieh,424 e o pontellou da-o mondo de Omburto, ciammou Duce.\n",
            "2023-12-04 21:10:06 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 840 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.78s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:10:06 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 6.433 | nll_loss 5.25 | ppl 38.07 | bleu 13.19 | wps 4024.5 | wpb 7753.9 | bsz 142.4 | num_updates 3355 | best_bleu 13.21\n",
            "2023-12-04 21:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 3355 updates\n",
            "2023-12-04 21:10:06 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint840.pt\n",
            "2023-12-04 21:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint840.pt\n",
            "2023-12-04 21:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint840.pt (epoch 840 @ 3355 updates, score 13.19) (writing took 2.131263413999932 seconds)\n",
            "2023-12-04 21:10:08 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)\n",
            "2023-12-04 21:10:08 | INFO | train | epoch 840 | loss 2.041 | nll_loss 0.493 | ppl 1.41 | wps 20143.1 | ups 0.23 | wpb 85903.8 | bsz 1548.2 | num_updates 3355 | lr 0.00034529 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3357\n",
            "2023-12-04 21:10:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 841:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:08 | INFO | fairseq.trainer | begin training epoch 841\n",
            "2023-12-04 21:10:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:10 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)\n",
            "2023-12-04 21:10:10 | INFO | train | epoch 841 | loss 2.04 | nll_loss 0.49 | ppl 1.4 | wps 138664 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 3359 | lr 0.000345084 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3359\n",
            "2023-12-04 21:10:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 842:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:10 | INFO | fairseq.trainer | begin training epoch 842\n",
            "2023-12-04 21:10:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:13 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)\n",
            "2023-12-04 21:10:13 | INFO | train | epoch 842 | loss 2.04 | nll_loss 0.49 | ppl 1.4 | wps 142552 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3363 | lr 0.000344879 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3361\n",
            "2023-12-04 21:10:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 843:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:13 | INFO | fairseq.trainer | begin training epoch 843\n",
            "2023-12-04 21:10:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:15 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)\n",
            "2023-12-04 21:10:15 | INFO | train | epoch 843 | loss 2.04 | nll_loss 0.493 | ppl 1.41 | wps 142786 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3367 | lr 0.000344674 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3364\n",
            "2023-12-04 21:10:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 844:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:15 | INFO | fairseq.trainer | begin training epoch 844\n",
            "2023-12-04 21:10:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:18 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)\n",
            "2023-12-04 21:10:18 | INFO | train | epoch 844 | loss 2.04 | nll_loss 0.49 | ppl 1.4 | wps 143601 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3371 | lr 0.000344469 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3366\n",
            "2023-12-04 21:10:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 845:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:18 | INFO | fairseq.trainer | begin training epoch 845\n",
            "2023-12-04 21:10:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:20 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)\n",
            "2023-12-04 21:10:20 | INFO | train | epoch 845 | loss 2.039 | nll_loss 0.489 | ppl 1.4 | wps 141942 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3375 | lr 0.000344265 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3369\n",
            "2023-12-04 21:10:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 846:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:20 | INFO | fairseq.trainer | begin training epoch 846\n",
            "2023-12-04 21:10:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:22 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)\n",
            "2023-12-04 21:10:22 | INFO | train | epoch 846 | loss 2.039 | nll_loss 0.491 | ppl 1.41 | wps 143914 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3379 | lr 0.000344061 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3371\n",
            "2023-12-04 21:10:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 847:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:22 | INFO | fairseq.trainer | begin training epoch 847\n",
            "2023-12-04 21:10:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:25 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)\n",
            "2023-12-04 21:10:25 | INFO | train | epoch 847 | loss 2.039 | nll_loss 0.491 | ppl 1.41 | wps 143746 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3383 | lr 0.000343858 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3373\n",
            "2023-12-04 21:10:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 848:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:25 | INFO | fairseq.trainer | begin training epoch 848\n",
            "2023-12-04 21:10:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:27 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)\n",
            "2023-12-04 21:10:27 | INFO | train | epoch 848 | loss 2.039 | nll_loss 0.489 | ppl 1.4 | wps 143937 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3387 | lr 0.000343655 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3376\n",
            "2023-12-04 21:10:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 849:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:27 | INFO | fairseq.trainer | begin training epoch 849\n",
            "2023-12-04 21:10:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:30 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)\n",
            "2023-12-04 21:10:30 | INFO | train | epoch 849 | loss 2.039 | nll_loss 0.491 | ppl 1.41 | wps 142079 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3391 | lr 0.000343452 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3378\n",
            "2023-12-04 21:10:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 850:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:30 | INFO | fairseq.trainer | begin training epoch 850\n",
            "2023-12-04 21:10:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 850:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:10:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:10:33 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:10:33 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A2023-12-04 21:10:35 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settemanæ de struttua fixica, a deprescion e a paura.\n",
            "2023-12-04 21:10:35 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:10:37 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:10:37 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:10:38 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:10:38 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:10:41 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in sce l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:10:41 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.90s/it]\u001b[A2023-12-04 21:10:42 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): in sce sti 75.68 km (29173 quaddræ) in sce l’Asia sud-òccidentale, e 23764 (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:10:42 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 21:10:44 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.000 vixitatoî unichi do öse d'ottobre, inserçioin personali, un network de noçieh, 24 etctlante, un mondo ciammou Ducente, Wombur do 5.\n",
            "2023-12-04 21:10:44 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 850 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:10:44 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 6.456 | nll_loss 5.275 | ppl 38.73 | bleu 13.09 | wps 4168.8 | wpb 7753.9 | bsz 142.4 | num_updates 3395 | best_bleu 13.21\n",
            "2023-12-04 21:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 3395 updates\n",
            "2023-12-04 21:10:44 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint850.pt\n",
            "2023-12-04 21:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint850.pt\n",
            "2023-12-04 21:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint850.pt (epoch 850 @ 3395 updates, score 13.09) (writing took 2.1229598679997252 seconds)\n",
            "2023-12-04 21:10:46 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)\n",
            "2023-12-04 21:10:46 | INFO | train | epoch 850 | loss 2.037 | nll_loss 0.487 | ppl 1.4 | wps 20547.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3395 | lr 0.00034325 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3395\n",
            "2023-12-04 21:10:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 851:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:46 | INFO | fairseq.trainer | begin training epoch 851\n",
            "2023-12-04 21:10:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:49 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)\n",
            "2023-12-04 21:10:49 | INFO | train | epoch 851 | loss 2.041 | nll_loss 0.494 | ppl 1.41 | wps 139232 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3399 | lr 0.000343048 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3397\n",
            "2023-12-04 21:10:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 852:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:49 | INFO | fairseq.trainer | begin training epoch 852\n",
            "2023-12-04 21:10:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:51 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)\n",
            "2023-12-04 21:10:51 | INFO | train | epoch 852 | loss 2.042 | nll_loss 0.493 | ppl 1.41 | wps 140680 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3403 | lr 0.000342846 | gnorm 0.155 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3400\n",
            "2023-12-04 21:10:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 853:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:51 | INFO | fairseq.trainer | begin training epoch 853\n",
            "2023-12-04 21:10:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:54 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)\n",
            "2023-12-04 21:10:54 | INFO | train | epoch 853 | loss 2.043 | nll_loss 0.495 | ppl 1.41 | wps 141078 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3407 | lr 0.000342645 | gnorm 0.15 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3402\n",
            "2023-12-04 21:10:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 854:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:54 | INFO | fairseq.trainer | begin training epoch 854\n",
            "2023-12-04 21:10:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:56 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)\n",
            "2023-12-04 21:10:56 | INFO | train | epoch 854 | loss 2.042 | nll_loss 0.496 | ppl 1.41 | wps 143329 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3411 | lr 0.000342444 | gnorm 0.166 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3405\n",
            "2023-12-04 21:10:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 855:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:56 | INFO | fairseq.trainer | begin training epoch 855\n",
            "2023-12-04 21:10:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:10:58 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)\n",
            "2023-12-04 21:10:58 | INFO | train | epoch 855 | loss 2.043 | nll_loss 0.495 | ppl 1.41 | wps 142142 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3415 | lr 0.000342243 | gnorm 0.158 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3407\n",
            "2023-12-04 21:10:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 856:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:10:58 | INFO | fairseq.trainer | begin training epoch 856\n",
            "2023-12-04 21:10:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:01 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)\n",
            "2023-12-04 21:11:01 | INFO | train | epoch 856 | loss 2.041 | nll_loss 0.494 | ppl 1.41 | wps 143918 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3419 | lr 0.000342043 | gnorm 0.151 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3409\n",
            "2023-12-04 21:11:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 857:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:01 | INFO | fairseq.trainer | begin training epoch 857\n",
            "2023-12-04 21:11:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:03 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)\n",
            "2023-12-04 21:11:03 | INFO | train | epoch 857 | loss 2.039 | nll_loss 0.491 | ppl 1.41 | wps 141197 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3423 | lr 0.000341843 | gnorm 0.147 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3412\n",
            "2023-12-04 21:11:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 858:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:03 | INFO | fairseq.trainer | begin training epoch 858\n",
            "2023-12-04 21:11:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:06 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)\n",
            "2023-12-04 21:11:06 | INFO | train | epoch 858 | loss 2.037 | nll_loss 0.489 | ppl 1.4 | wps 142949 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3427 | lr 0.000341643 | gnorm 0.14 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3414\n",
            "2023-12-04 21:11:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 859:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:06 | INFO | fairseq.trainer | begin training epoch 859\n",
            "2023-12-04 21:11:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:08 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)\n",
            "2023-12-04 21:11:08 | INFO | train | epoch 859 | loss 2.034 | nll_loss 0.486 | ppl 1.4 | wps 142054 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3431 | lr 0.000341444 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3417\n",
            "2023-12-04 21:11:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 860:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:08 | INFO | fairseq.trainer | begin training epoch 860\n",
            "2023-12-04 21:11:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 860:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:11:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:11:12 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:11:12 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:11:13 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:11:13 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.54s/it]\u001b[A2023-12-04 21:11:15 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erte propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:11:15 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:11:17 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à ditou unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:11:17 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:11:19 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:11:19 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.91s/it]\u001b[A2023-12-04 21:11:21 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti, 75.68 km (29173 quaddræ) se rompæ inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:11:21 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 21:11:23 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web in graddo de attirare 5.00.00 vixitatoî unichi into mese d'ottobre, inserçioin personali, un network de nozieh, 24 etlante un mondiale, ciammou Ducedy Wombur de Ombur.\n",
            "2023-12-04 21:11:23 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 860 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.77s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:11:23 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 6.418 | nll_loss 5.236 | ppl 37.69 | bleu 13.3 | wps 4142.7 | wpb 7753.9 | bsz 142.4 | num_updates 3435 | best_bleu 13.3\n",
            "2023-12-04 21:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 3435 updates\n",
            "2023-12-04 21:11:23 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint860.pt\n",
            "2023-12-04 21:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint860.pt\n",
            "2023-12-04 21:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint860.pt (epoch 860 @ 3435 updates, score 13.3) (writing took 3.7287655510003788 seconds)\n",
            "2023-12-04 21:11:26 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)\n",
            "2023-12-04 21:11:26 | INFO | train | epoch 860 | loss 2.034 | nll_loss 0.483 | ppl 1.4 | wps 18709.8 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 3435 | lr 0.000341245 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3435\n",
            "2023-12-04 21:11:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 861:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:26 | INFO | fairseq.trainer | begin training epoch 861\n",
            "2023-12-04 21:11:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:29 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)\n",
            "2023-12-04 21:11:29 | INFO | train | epoch 861 | loss 2.031 | nll_loss 0.484 | ppl 1.4 | wps 139973 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3439 | lr 0.000341047 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3438\n",
            "2023-12-04 21:11:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 862:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:29 | INFO | fairseq.trainer | begin training epoch 862\n",
            "2023-12-04 21:11:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:31 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)\n",
            "2023-12-04 21:11:31 | INFO | train | epoch 862 | loss 2.033 | nll_loss 0.485 | ppl 1.4 | wps 138965 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3443 | lr 0.000340849 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3440\n",
            "2023-12-04 21:11:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 863:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:31 | INFO | fairseq.trainer | begin training epoch 863\n",
            "2023-12-04 21:11:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:34 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)\n",
            "2023-12-04 21:11:34 | INFO | train | epoch 863 | loss 2.034 | nll_loss 0.486 | ppl 1.4 | wps 141536 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3447 | lr 0.000340651 | gnorm 0.139 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3442\n",
            "2023-12-04 21:11:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 864:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:34 | INFO | fairseq.trainer | begin training epoch 864\n",
            "2023-12-04 21:11:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:36 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)\n",
            "2023-12-04 21:11:36 | INFO | train | epoch 864 | loss 2.03 | nll_loss 0.482 | ppl 1.4 | wps 143334 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3451 | lr 0.000340453 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3445\n",
            "2023-12-04 21:11:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 865:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:36 | INFO | fairseq.trainer | begin training epoch 865\n",
            "2023-12-04 21:11:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:39 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)\n",
            "2023-12-04 21:11:39 | INFO | train | epoch 865 | loss 2.031 | nll_loss 0.482 | ppl 1.4 | wps 142375 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3455 | lr 0.000340256 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3447\n",
            "2023-12-04 21:11:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 866:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:39 | INFO | fairseq.trainer | begin training epoch 866\n",
            "2023-12-04 21:11:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:41 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)\n",
            "2023-12-04 21:11:41 | INFO | train | epoch 866 | loss 2.029 | nll_loss 0.481 | ppl 1.4 | wps 144395 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3459 | lr 0.000340059 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3450\n",
            "2023-12-04 21:11:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 867:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:41 | INFO | fairseq.trainer | begin training epoch 867\n",
            "2023-12-04 21:11:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:43 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)\n",
            "2023-12-04 21:11:43 | INFO | train | epoch 867 | loss 2.031 | nll_loss 0.483 | ppl 1.4 | wps 143379 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3463 | lr 0.000339863 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3452\n",
            "2023-12-04 21:11:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 868:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:43 | INFO | fairseq.trainer | begin training epoch 868\n",
            "2023-12-04 21:11:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:46 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)\n",
            "2023-12-04 21:11:46 | INFO | train | epoch 868 | loss 2.028 | nll_loss 0.48 | ppl 1.39 | wps 142405 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3467 | lr 0.000339667 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3454\n",
            "2023-12-04 21:11:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 869:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:46 | INFO | fairseq.trainer | begin training epoch 869\n",
            "2023-12-04 21:11:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:11:48 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)\n",
            "2023-12-04 21:11:48 | INFO | train | epoch 869 | loss 2.031 | nll_loss 0.483 | ppl 1.4 | wps 142116 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3471 | lr 0.000339471 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3457\n",
            "2023-12-04 21:11:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 870:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:11:48 | INFO | fairseq.trainer | begin training epoch 870\n",
            "2023-12-04 21:11:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 870:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:11:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:11:52 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:11:52 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:11:54 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioinæ da-e settematiche struttua de attivitæ fixica, no a deprescion e a paura.\n",
            "2023-12-04 21:11:54 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:11:55 | INFO | fairseq.tasks.translation | example hypothesis: Sence ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti forniscian à di microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:11:55 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:11:57 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à ditou unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:11:57 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:11:59 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon in sce l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:11:59 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:12:01 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) che s’attreuvan in sce l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:12:01 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.72s/it]\u001b[A2023-12-04 21:12:02 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web ch'o peu attiâ di 5.00.00 vixitatoî de vixitatoî unichi into meise d'ötovie, inserçioin personali, un network de noçieh, 24 ch'o l'é stæto lasciou into mondo de Omburto, ciammou Ducedwor à Duce.\n",
            "2023-12-04 21:12:02 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 870 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:12:02 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 6.432 | nll_loss 5.251 | ppl 38.08 | bleu 13.28 | wps 4259.2 | wpb 7753.9 | bsz 142.4 | num_updates 3475 | best_bleu 13.3\n",
            "2023-12-04 21:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 3475 updates\n",
            "2023-12-04 21:12:02 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint870.pt\n",
            "2023-12-04 21:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint870.pt\n",
            "2023-12-04 21:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint870.pt (epoch 870 @ 3475 updates, score 13.28) (writing took 2.1493286710001485 seconds)\n",
            "2023-12-04 21:12:05 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)\n",
            "2023-12-04 21:12:05 | INFO | train | epoch 870 | loss 2.029 | nll_loss 0.481 | ppl 1.4 | wps 20796.2 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3475 | lr 0.000339276 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3473\n",
            "2023-12-04 21:12:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 871:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:05 | INFO | fairseq.trainer | begin training epoch 871\n",
            "2023-12-04 21:12:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:07 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)\n",
            "2023-12-04 21:12:07 | INFO | train | epoch 871 | loss 2.028 | nll_loss 0.48 | ppl 1.4 | wps 141690 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3479 | lr 0.00033908 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3476\n",
            "2023-12-04 21:12:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 872:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:07 | INFO | fairseq.trainer | begin training epoch 872\n",
            "2023-12-04 21:12:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:10 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)\n",
            "2023-12-04 21:12:10 | INFO | train | epoch 872 | loss 2.026 | nll_loss 0.479 | ppl 1.39 | wps 140165 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3483 | lr 0.000338886 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3478\n",
            "2023-12-04 21:12:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 873:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:10 | INFO | fairseq.trainer | begin training epoch 873\n",
            "2023-12-04 21:12:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:12 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)\n",
            "2023-12-04 21:12:12 | INFO | train | epoch 873 | loss 2.027 | nll_loss 0.478 | ppl 1.39 | wps 142514 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3487 | lr 0.000338691 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3481\n",
            "2023-12-04 21:12:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 874:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:12 | INFO | fairseq.trainer | begin training epoch 874\n",
            "2023-12-04 21:12:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:14 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)\n",
            "2023-12-04 21:12:14 | INFO | train | epoch 874 | loss 2.026 | nll_loss 0.479 | ppl 1.39 | wps 141936 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3491 | lr 0.000338497 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3483\n",
            "2023-12-04 21:12:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 875:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:14 | INFO | fairseq.trainer | begin training epoch 875\n",
            "2023-12-04 21:12:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:17 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)\n",
            "2023-12-04 21:12:17 | INFO | train | epoch 875 | loss 2.027 | nll_loss 0.478 | ppl 1.39 | wps 144328 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3495 | lr 0.000338303 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3485\n",
            "2023-12-04 21:12:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 876:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:17 | INFO | fairseq.trainer | begin training epoch 876\n",
            "2023-12-04 21:12:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:19 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)\n",
            "2023-12-04 21:12:19 | INFO | train | epoch 876 | loss 2.027 | nll_loss 0.48 | ppl 1.4 | wps 143486 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3499 | lr 0.00033811 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3488\n",
            "2023-12-04 21:12:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 877:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:19 | INFO | fairseq.trainer | begin training epoch 877\n",
            "2023-12-04 21:12:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:22 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)\n",
            "2023-12-04 21:12:22 | INFO | train | epoch 877 | loss 2.027 | nll_loss 0.479 | ppl 1.39 | wps 144462 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3503 | lr 0.000337917 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3490\n",
            "2023-12-04 21:12:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 878:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:22 | INFO | fairseq.trainer | begin training epoch 878\n",
            "2023-12-04 21:12:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:24 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)\n",
            "2023-12-04 21:12:24 | INFO | train | epoch 878 | loss 2.025 | nll_loss 0.477 | ppl 1.39 | wps 141712 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3507 | lr 0.000337724 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3493\n",
            "2023-12-04 21:12:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 879:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:24 | INFO | fairseq.trainer | begin training epoch 879\n",
            "2023-12-04 21:12:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:26 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)\n",
            "2023-12-04 21:12:26 | INFO | train | epoch 879 | loss 2.025 | nll_loss 0.479 | ppl 1.39 | wps 144048 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3511 | lr 0.000337532 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3495\n",
            "2023-12-04 21:12:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 880:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:26 | INFO | fairseq.trainer | begin training epoch 880\n",
            "2023-12-04 21:12:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 880:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 21:12:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:12:30 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:12:30 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:12:32 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioinæ da-e settemañe de struttua fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:12:32 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 21:12:33 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erte propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é dito òffiti an fornio à di microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:12:33 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:12:35 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à ditou unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:12:35 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:12:37 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:12:37 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:12:39 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti, 75.68 km (29173 quaddræ) ch’a s’é collocâ inte l’Asia sud-òvest, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:12:39 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:12:41 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh 24 estlante, ch'o l'é stæto lasciou into mondo de Ducellou Ombur comme Dumbur de Omburaçion.\n",
            "2023-12-04 21:12:41 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 880 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.75s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:12:41 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 6.438 | nll_loss 5.256 | ppl 38.22 | bleu 13.08 | wps 4214.5 | wpb 7753.9 | bsz 142.4 | num_updates 3515 | best_bleu 13.3\n",
            "2023-12-04 21:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 3515 updates\n",
            "2023-12-04 21:12:41 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint880.pt\n",
            "2023-12-04 21:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint880.pt\n",
            "2023-12-04 21:12:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint880.pt (epoch 880 @ 3515 updates, score 13.08) (writing took 2.1361029939998843 seconds)\n",
            "2023-12-04 21:12:43 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)\n",
            "2023-12-04 21:12:43 | INFO | train | epoch 880 | loss 2.026 | nll_loss 0.478 | ppl 1.39 | wps 20693.1 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3515 | lr 0.00033734 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3512\n",
            "2023-12-04 21:12:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 881:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:43 | INFO | fairseq.trainer | begin training epoch 881\n",
            "2023-12-04 21:12:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:45 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)\n",
            "2023-12-04 21:12:45 | INFO | train | epoch 881 | loss 2.025 | nll_loss 0.477 | ppl 1.39 | wps 142157 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3519 | lr 0.000337148 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3514\n",
            "2023-12-04 21:12:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 882:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:45 | INFO | fairseq.trainer | begin training epoch 882\n",
            "2023-12-04 21:12:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:48 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)\n",
            "2023-12-04 21:12:48 | INFO | train | epoch 882 | loss 2.024 | nll_loss 0.477 | ppl 1.39 | wps 141146 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3523 | lr 0.000336956 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3517\n",
            "2023-12-04 21:12:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 883:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:48 | INFO | fairseq.trainer | begin training epoch 883\n",
            "2023-12-04 21:12:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:50 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)\n",
            "2023-12-04 21:12:50 | INFO | train | epoch 883 | loss 2.024 | nll_loss 0.474 | ppl 1.39 | wps 142424 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3527 | lr 0.000336765 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3519\n",
            "2023-12-04 21:12:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 884:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:50 | INFO | fairseq.trainer | begin training epoch 884\n",
            "2023-12-04 21:12:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:53 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)\n",
            "2023-12-04 21:12:53 | INFO | train | epoch 884 | loss 2.024 | nll_loss 0.478 | ppl 1.39 | wps 142833 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3531 | lr 0.000336574 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3521\n",
            "2023-12-04 21:12:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 885:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:53 | INFO | fairseq.trainer | begin training epoch 885\n",
            "2023-12-04 21:12:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:55 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)\n",
            "2023-12-04 21:12:55 | INFO | train | epoch 885 | loss 2.023 | nll_loss 0.476 | ppl 1.39 | wps 140094 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3535 | lr 0.000336384 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3524\n",
            "2023-12-04 21:12:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 886:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:55 | INFO | fairseq.trainer | begin training epoch 886\n",
            "2023-12-04 21:12:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:12:58 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)\n",
            "2023-12-04 21:12:58 | INFO | train | epoch 886 | loss 2.023 | nll_loss 0.476 | ppl 1.39 | wps 140378 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3539 | lr 0.000336194 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3526\n",
            "2023-12-04 21:12:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 887:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:12:58 | INFO | fairseq.trainer | begin training epoch 887\n",
            "2023-12-04 21:12:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:00 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)\n",
            "2023-12-04 21:13:00 | INFO | train | epoch 887 | loss 2.022 | nll_loss 0.475 | ppl 1.39 | wps 143900 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3543 | lr 0.000336004 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3529\n",
            "2023-12-04 21:13:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 888:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:00 | INFO | fairseq.trainer | begin training epoch 888\n",
            "2023-12-04 21:13:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:02 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)\n",
            "2023-12-04 21:13:02 | INFO | train | epoch 888 | loss 2.023 | nll_loss 0.476 | ppl 1.39 | wps 140664 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3547 | lr 0.000335814 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3531\n",
            "2023-12-04 21:13:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 889:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:02 | INFO | fairseq.trainer | begin training epoch 889\n",
            "2023-12-04 21:13:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:05 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)\n",
            "2023-12-04 21:13:05 | INFO | train | epoch 889 | loss 2.021 | nll_loss 0.475 | ppl 1.39 | wps 141406 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3551 | lr 0.000335625 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3534\n",
            "2023-12-04 21:13:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 890:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:05 | INFO | fairseq.trainer | begin training epoch 890\n",
            "2023-12-04 21:13:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 890:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:13:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:13:09 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:13:09 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  14% 1/7 [00:01<00:10,  1.82s/it]\u001b[A2023-12-04 21:13:11 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settematiche struttua de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:13:11 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.68s/it]\u001b[A2023-12-04 21:13:12 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erte propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti, ò an produto di additi microonde ò di atri mezi pe rescätâ o mangiâ.\n",
            "2023-12-04 21:13:12 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  43% 3/7 [00:05<00:06,  1.68s/it]\u001b[A2023-12-04 21:13:14 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à divampou un inçendio, donde l’é visciuo solo çerte requie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:13:14 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.77s/it]\u001b[A2023-12-04 21:13:16 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:13:16 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.95s/it]\u001b[A2023-12-04 21:13:18 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti, 75.68 km (291.73 quaddræ) ch’a s’é collocâ inte l’Asia sud-òvest, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:13:18 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.81s/it]\u001b[A2023-12-04 21:13:20 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in sciô graddo de attirare 5.00.00 vixitatoî de vixitoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh, 24 ch'o ponte un mondo etlante, ciammou Duce o nomme de Ombur B.\n",
            "2023-12-04 21:13:20 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 890 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:13:20 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 6.446 | nll_loss 5.272 | ppl 38.64 | bleu 13.17 | wps 4155 | wpb 7753.9 | bsz 142.4 | num_updates 3555 | best_bleu 13.3\n",
            "2023-12-04 21:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 3555 updates\n",
            "2023-12-04 21:13:20 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint890.pt\n",
            "2023-12-04 21:13:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint890.pt\n",
            "2023-12-04 21:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint890.pt (epoch 890 @ 3555 updates, score 13.17) (writing took 2.137540706999971 seconds)\n",
            "2023-12-04 21:13:22 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)\n",
            "2023-12-04 21:13:22 | INFO | train | epoch 890 | loss 2.023 | nll_loss 0.475 | ppl 1.39 | wps 20082.8 | ups 0.23 | wpb 85903.8 | bsz 1548.2 | num_updates 3555 | lr 0.000335436 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3551\n",
            "2023-12-04 21:13:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 891:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:22 | INFO | fairseq.trainer | begin training epoch 891\n",
            "2023-12-04 21:13:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:24 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)\n",
            "2023-12-04 21:13:24 | INFO | train | epoch 891 | loss 2.021 | nll_loss 0.475 | ppl 1.39 | wps 144376 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3559 | lr 0.000335248 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3553\n",
            "2023-12-04 21:13:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 892:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:24 | INFO | fairseq.trainer | begin training epoch 892\n",
            "2023-12-04 21:13:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:27 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)\n",
            "2023-12-04 21:13:27 | INFO | train | epoch 892 | loss 2.022 | nll_loss 0.475 | ppl 1.39 | wps 144024 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3563 | lr 0.00033506 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3555\n",
            "2023-12-04 21:13:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 893:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:27 | INFO | fairseq.trainer | begin training epoch 893\n",
            "2023-12-04 21:13:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:29 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)\n",
            "2023-12-04 21:13:29 | INFO | train | epoch 893 | loss 2.021 | nll_loss 0.475 | ppl 1.39 | wps 143094 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3567 | lr 0.000334872 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3558\n",
            "2023-12-04 21:13:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 894:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:29 | INFO | fairseq.trainer | begin training epoch 894\n",
            "2023-12-04 21:13:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:32 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)\n",
            "2023-12-04 21:13:32 | INFO | train | epoch 894 | loss 2.022 | nll_loss 0.474 | ppl 1.39 | wps 142425 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3571 | lr 0.000334684 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3560\n",
            "2023-12-04 21:13:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 895:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:32 | INFO | fairseq.trainer | begin training epoch 895\n",
            "2023-12-04 21:13:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:34 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)\n",
            "2023-12-04 21:13:34 | INFO | train | epoch 895 | loss 2.022 | nll_loss 0.475 | ppl 1.39 | wps 142411 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3575 | lr 0.000334497 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3563\n",
            "2023-12-04 21:13:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 896:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:34 | INFO | fairseq.trainer | begin training epoch 896\n",
            "2023-12-04 21:13:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:36 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)\n",
            "2023-12-04 21:13:36 | INFO | train | epoch 896 | loss 2.02 | nll_loss 0.475 | ppl 1.39 | wps 142982 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3579 | lr 0.00033431 | gnorm 0.132 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3565\n",
            "2023-12-04 21:13:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 897:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:36 | INFO | fairseq.trainer | begin training epoch 897\n",
            "2023-12-04 21:13:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:39 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)\n",
            "2023-12-04 21:13:39 | INFO | train | epoch 897 | loss 2.02 | nll_loss 0.472 | ppl 1.39 | wps 144577 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3583 | lr 0.000334123 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3567\n",
            "2023-12-04 21:13:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 898:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:39 | INFO | fairseq.trainer | begin training epoch 898\n",
            "2023-12-04 21:13:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:41 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)\n",
            "2023-12-04 21:13:41 | INFO | train | epoch 898 | loss 2.02 | nll_loss 0.473 | ppl 1.39 | wps 141402 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3587 | lr 0.000333937 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3570\n",
            "2023-12-04 21:13:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 899:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:41 | INFO | fairseq.trainer | begin training epoch 899\n",
            "2023-12-04 21:13:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:13:44 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)\n",
            "2023-12-04 21:13:44 | INFO | train | epoch 899 | loss 2.019 | nll_loss 0.473 | ppl 1.39 | wps 141419 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3591 | lr 0.000333751 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3572\n",
            "2023-12-04 21:13:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 900:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:13:44 | INFO | fairseq.trainer | begin training epoch 900\n",
            "2023-12-04 21:13:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 900:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 21:13:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:13:47 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelative inte quarche çircostanse.\n",
            "2023-12-04 21:13:47 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:13:49 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e seçioin settematichi struttua de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:13:49 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:13:51 | INFO | fairseq.tasks.translation | example hypothesis: Sence ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ di çibinti òffiti an fornio à di microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:13:51 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.56s/it]\u001b[A2023-12-04 21:13:52 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:13:53 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:13:55 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou pe de ciù inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:13:55 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:13:56 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) ch’a s’é collocâ inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:13:56 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 21:13:58 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.00.00 vixitatoî de vixitoî unichi into meise d'ötovie, inserçioin personali, un network de nozieh 24,4 ch'o l'é stæto lasciou do mondo errou de Ducente.\n",
            "2023-12-04 21:13:58 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 900 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:13:58 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 6.456 | nll_loss 5.281 | ppl 38.87 | bleu 13.1 | wps 4225.3 | wpb 7753.9 | bsz 142.4 | num_updates 3595 | best_bleu 13.3\n",
            "2023-12-04 21:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 3595 updates\n",
            "2023-12-04 21:13:58 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint900.pt\n",
            "2023-12-04 21:13:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint900.pt\n",
            "2023-12-04 21:14:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint900.pt (epoch 900 @ 3595 updates, score 13.1) (writing took 2.121965363000072 seconds)\n",
            "2023-12-04 21:14:00 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)\n",
            "2023-12-04 21:14:00 | INFO | train | epoch 900 | loss 2.017 | nll_loss 0.471 | ppl 1.39 | wps 20708.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3595 | lr 0.000333565 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3589\n",
            "2023-12-04 21:14:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 901:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:00 | INFO | fairseq.trainer | begin training epoch 901\n",
            "2023-12-04 21:14:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:03 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)\n",
            "2023-12-04 21:14:03 | INFO | train | epoch 901 | loss 2.018 | nll_loss 0.47 | ppl 1.38 | wps 140495 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3599 | lr 0.00033338 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3591\n",
            "2023-12-04 21:14:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 902:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:03 | INFO | fairseq.trainer | begin training epoch 902\n",
            "2023-12-04 21:14:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:05 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)\n",
            "2023-12-04 21:14:05 | INFO | train | epoch 902 | loss 2.014 | nll_loss 0.469 | ppl 1.38 | wps 141369 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3603 | lr 0.000333195 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3594\n",
            "2023-12-04 21:14:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 903:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:05 | INFO | fairseq.trainer | begin training epoch 903\n",
            "2023-12-04 21:14:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:07 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)\n",
            "2023-12-04 21:14:07 | INFO | train | epoch 903 | loss 2.017 | nll_loss 0.47 | ppl 1.39 | wps 142234 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3607 | lr 0.00033301 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3596\n",
            "2023-12-04 21:14:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 904:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:07 | INFO | fairseq.trainer | begin training epoch 904\n",
            "2023-12-04 21:14:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:10 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)\n",
            "2023-12-04 21:14:10 | INFO | train | epoch 904 | loss 2.018 | nll_loss 0.47 | ppl 1.39 | wps 139218 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3611 | lr 0.000332825 | gnorm 0.133 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3599\n",
            "2023-12-04 21:14:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 905:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:10 | INFO | fairseq.trainer | begin training epoch 905\n",
            "2023-12-04 21:14:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:13 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)\n",
            "2023-12-04 21:14:13 | INFO | train | epoch 905 | loss 2.015 | nll_loss 0.469 | ppl 1.38 | wps 130571 | ups 1.52 | wpb 85903.8 | bsz 1548.2 | num_updates 3615 | lr 0.000332641 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3601\n",
            "2023-12-04 21:14:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 906:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:13 | INFO | fairseq.trainer | begin training epoch 906\n",
            "2023-12-04 21:14:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:15 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)\n",
            "2023-12-04 21:14:15 | INFO | train | epoch 906 | loss 2.017 | nll_loss 0.471 | ppl 1.39 | wps 142128 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3619 | lr 0.000332457 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3604\n",
            "2023-12-04 21:14:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 907:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:15 | INFO | fairseq.trainer | begin training epoch 907\n",
            "2023-12-04 21:14:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:17 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)\n",
            "2023-12-04 21:14:17 | INFO | train | epoch 907 | loss 2.015 | nll_loss 0.468 | ppl 1.38 | wps 140659 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3623 | lr 0.000332274 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3606\n",
            "2023-12-04 21:14:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 908:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:17 | INFO | fairseq.trainer | begin training epoch 908\n",
            "2023-12-04 21:14:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:20 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)\n",
            "2023-12-04 21:14:20 | INFO | train | epoch 908 | loss 2.013 | nll_loss 0.467 | ppl 1.38 | wps 142599 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3627 | lr 0.00033209 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3609\n",
            "2023-12-04 21:14:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 909:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:20 | INFO | fairseq.trainer | begin training epoch 909\n",
            "2023-12-04 21:14:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:22 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)\n",
            "2023-12-04 21:14:22 | INFO | train | epoch 909 | loss 2.014 | nll_loss 0.468 | ppl 1.38 | wps 140913 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3631 | lr 0.000331907 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3611\n",
            "2023-12-04 21:14:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 910:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:22 | INFO | fairseq.trainer | begin training epoch 910\n",
            "2023-12-04 21:14:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 910:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:14:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:14:26 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:14:26 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:14:28 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e seçioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:14:28 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:14:29 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che Aldun an produto di additi microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:14:29 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:14:31 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte requie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:14:31 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:14:33 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caso sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:14:33 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:14:35 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa in sciâ scâ quaddræ): de sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest, e 23764 km (29174 km (e Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:14:35 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 21:14:37 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.0000 de vixitoî unichi into meise d'ötovie, inserçioin personali, un network de noçieh 24 ch'o l'é stæto lasciou do mondo etlante, ciammou Duceweb.\n",
            "2023-12-04 21:14:37 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 910 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:14:37 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 6.427 | nll_loss 5.253 | ppl 38.13 | bleu 13.03 | wps 4214.7 | wpb 7753.9 | bsz 142.4 | num_updates 3635 | best_bleu 13.3\n",
            "2023-12-04 21:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 3635 updates\n",
            "2023-12-04 21:14:37 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint910.pt\n",
            "2023-12-04 21:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint910.pt\n",
            "2023-12-04 21:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint910.pt (epoch 910 @ 3635 updates, score 13.03) (writing took 2.12788271799991 seconds)\n",
            "2023-12-04 21:14:39 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)\n",
            "2023-12-04 21:14:39 | INFO | train | epoch 910 | loss 2.018 | nll_loss 0.471 | ppl 1.39 | wps 20723.1 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3635 | lr 0.000331725 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3628\n",
            "2023-12-04 21:14:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 911:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:39 | INFO | fairseq.trainer | begin training epoch 911\n",
            "2023-12-04 21:14:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:41 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)\n",
            "2023-12-04 21:14:41 | INFO | train | epoch 911 | loss 2.013 | nll_loss 0.468 | ppl 1.38 | wps 141668 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3639 | lr 0.000331542 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3630\n",
            "2023-12-04 21:14:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 912:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:41 | INFO | fairseq.trainer | begin training epoch 912\n",
            "2023-12-04 21:14:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:44 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)\n",
            "2023-12-04 21:14:44 | INFO | train | epoch 912 | loss 2.015 | nll_loss 0.47 | ppl 1.38 | wps 144513 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3643 | lr 0.00033136 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3632\n",
            "2023-12-04 21:14:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 913:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:44 | INFO | fairseq.trainer | begin training epoch 913\n",
            "2023-12-04 21:14:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:46 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)\n",
            "2023-12-04 21:14:46 | INFO | train | epoch 913 | loss 2.015 | nll_loss 0.468 | ppl 1.38 | wps 142594 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3647 | lr 0.000331178 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3635\n",
            "2023-12-04 21:14:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 914:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:46 | INFO | fairseq.trainer | begin training epoch 914\n",
            "2023-12-04 21:14:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:48 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)\n",
            "2023-12-04 21:14:48 | INFO | train | epoch 914 | loss 2.013 | nll_loss 0.468 | ppl 1.38 | wps 141690 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3651 | lr 0.000330997 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3637\n",
            "2023-12-04 21:14:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 915:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:49 | INFO | fairseq.trainer | begin training epoch 915\n",
            "2023-12-04 21:14:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:51 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)\n",
            "2023-12-04 21:14:51 | INFO | train | epoch 915 | loss 2.012 | nll_loss 0.466 | ppl 1.38 | wps 141694 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3655 | lr 0.000330816 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3640\n",
            "2023-12-04 21:14:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 916:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:51 | INFO | fairseq.trainer | begin training epoch 916\n",
            "2023-12-04 21:14:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:53 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)\n",
            "2023-12-04 21:14:53 | INFO | train | epoch 916 | loss 2.011 | nll_loss 0.465 | ppl 1.38 | wps 144022 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3659 | lr 0.000330635 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3642\n",
            "2023-12-04 21:14:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 917:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:53 | INFO | fairseq.trainer | begin training epoch 917\n",
            "2023-12-04 21:14:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:56 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)\n",
            "2023-12-04 21:14:56 | INFO | train | epoch 917 | loss 2.011 | nll_loss 0.465 | ppl 1.38 | wps 144370 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3663 | lr 0.000330454 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3644\n",
            "2023-12-04 21:14:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 918:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:56 | INFO | fairseq.trainer | begin training epoch 918\n",
            "2023-12-04 21:14:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:14:58 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)\n",
            "2023-12-04 21:14:58 | INFO | train | epoch 918 | loss 2.012 | nll_loss 0.466 | ppl 1.38 | wps 142360 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3667 | lr 0.000330274 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3647\n",
            "2023-12-04 21:14:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 919:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:14:58 | INFO | fairseq.trainer | begin training epoch 919\n",
            "2023-12-04 21:14:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:01 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)\n",
            "2023-12-04 21:15:01 | INFO | train | epoch 919 | loss 2.013 | nll_loss 0.468 | ppl 1.38 | wps 141521 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3671 | lr 0.000330094 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3649\n",
            "2023-12-04 21:15:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 920:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:01 | INFO | fairseq.trainer | begin training epoch 920\n",
            "2023-12-04 21:15:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 920:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:15:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:15:04 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:15:04 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:15:06 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e sescioin semanæ de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:15:06 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:15:08 | INFO | fairseq.tasks.translation | example hypothesis: Sence ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescäda o mangiâ.\n",
            "2023-12-04 21:15:08 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:15:09 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à divampou un inçendio, donde l’é visciuo solo çerte requie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:15:09 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:15:12 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte un Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:15:12 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:15:13 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): in sce sti, 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest de Ponente, 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:15:13 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.75s/it]\u001b[A2023-12-04 21:15:15 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.000 vixitatoî unichi into meise de öse d'ötovie, inserçioin personali, un network de nozieh 24 ch'o l'é stæto lasciou à Duceante, ciammou Ombur Ombur de Duce.\n",
            "2023-12-04 21:15:15 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 920 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:15:15 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 6.435 | nll_loss 5.265 | ppl 38.45 | bleu 13.11 | wps 4186.2 | wpb 7753.9 | bsz 142.4 | num_updates 3675 | best_bleu 13.3\n",
            "2023-12-04 21:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 3675 updates\n",
            "2023-12-04 21:15:15 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint920.pt\n",
            "2023-12-04 21:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint920.pt\n",
            "2023-12-04 21:15:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint920.pt (epoch 920 @ 3675 updates, score 13.11) (writing took 2.1259648160003053 seconds)\n",
            "2023-12-04 21:15:17 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)\n",
            "2023-12-04 21:15:17 | INFO | train | epoch 920 | loss 2.009 | nll_loss 0.461 | ppl 1.38 | wps 20628.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3675 | lr 0.000329914 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3666\n",
            "2023-12-04 21:15:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 921:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:17 | INFO | fairseq.trainer | begin training epoch 921\n",
            "2023-12-04 21:15:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:20 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)\n",
            "2023-12-04 21:15:20 | INFO | train | epoch 921 | loss 2.01 | nll_loss 0.465 | ppl 1.38 | wps 142266 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3679 | lr 0.000329735 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3668\n",
            "2023-12-04 21:15:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 922:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:20 | INFO | fairseq.trainer | begin training epoch 922\n",
            "2023-12-04 21:15:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:22 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)\n",
            "2023-12-04 21:15:22 | INFO | train | epoch 922 | loss 2.008 | nll_loss 0.461 | ppl 1.38 | wps 140981 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3683 | lr 0.000329556 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3671\n",
            "2023-12-04 21:15:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 923:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:22 | INFO | fairseq.trainer | begin training epoch 923\n",
            "2023-12-04 21:15:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:24 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)\n",
            "2023-12-04 21:15:24 | INFO | train | epoch 923 | loss 2.011 | nll_loss 0.465 | ppl 1.38 | wps 143242 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3687 | lr 0.000329377 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3673\n",
            "2023-12-04 21:15:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 924:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:24 | INFO | fairseq.trainer | begin training epoch 924\n",
            "2023-12-04 21:15:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:27 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)\n",
            "2023-12-04 21:15:27 | INFO | train | epoch 924 | loss 2.009 | nll_loss 0.463 | ppl 1.38 | wps 139701 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3691 | lr 0.000329199 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3676\n",
            "2023-12-04 21:15:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 925:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:27 | INFO | fairseq.trainer | begin training epoch 925\n",
            "2023-12-04 21:15:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:29 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)\n",
            "2023-12-04 21:15:29 | INFO | train | epoch 925 | loss 2.01 | nll_loss 0.465 | ppl 1.38 | wps 143190 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3695 | lr 0.00032902 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3678\n",
            "2023-12-04 21:15:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 926:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:29 | INFO | fairseq.trainer | begin training epoch 926\n",
            "2023-12-04 21:15:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:32 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)\n",
            "2023-12-04 21:15:32 | INFO | train | epoch 926 | loss 2.01 | nll_loss 0.464 | ppl 1.38 | wps 143242 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3699 | lr 0.000328842 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3680\n",
            "2023-12-04 21:15:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 927:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:32 | INFO | fairseq.trainer | begin training epoch 927\n",
            "2023-12-04 21:15:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:34 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)\n",
            "2023-12-04 21:15:34 | INFO | train | epoch 927 | loss 2.008 | nll_loss 0.463 | ppl 1.38 | wps 144066 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3703 | lr 0.000328665 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3683\n",
            "2023-12-04 21:15:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 928:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:34 | INFO | fairseq.trainer | begin training epoch 928\n",
            "2023-12-04 21:15:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:36 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)\n",
            "2023-12-04 21:15:36 | INFO | train | epoch 928 | loss 2.008 | nll_loss 0.462 | ppl 1.38 | wps 142039 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3707 | lr 0.000328487 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3685\n",
            "2023-12-04 21:15:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 929:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:37 | INFO | fairseq.trainer | begin training epoch 929\n",
            "2023-12-04 21:15:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:39 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)\n",
            "2023-12-04 21:15:39 | INFO | train | epoch 929 | loss 2.007 | nll_loss 0.461 | ppl 1.38 | wps 140094 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3711 | lr 0.00032831 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3688\n",
            "2023-12-04 21:15:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 930:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:39 | INFO | fairseq.trainer | begin training epoch 930\n",
            "2023-12-04 21:15:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 930:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 21:15:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:15:43 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge ascì, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:15:43 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A2023-12-04 21:15:44 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e seçioin settemanæ de attivitæ fixica, a deprescion e a miagia.\n",
            "2023-12-04 21:15:44 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.73s/it]\u001b[A2023-12-04 21:15:46 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de çibboin ò an produto di additi microonde ò di atri mezi pe rescädatua do çibbo.\n",
            "2023-12-04 21:15:46 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  43% 3/7 [00:05<00:06,  1.73s/it]\u001b[A2023-12-04 21:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:15:48 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.77s/it]\u001b[A2023-12-04 21:15:50 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte un Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:15:50 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.92s/it]\u001b[A2023-12-04 21:15:52 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (300.948 miggia quaddræ): de sti, 75.68 km (2917373 quaddræ) se peu vegnî quaddræ inte l’Asia sud-òvest de Ponente, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:15:52 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.79s/it]\u001b[A2023-12-04 21:15:54 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.000 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh 24 a-o mondo etlante, ciammou Ducellou Ombur à Duce.\n",
            "2023-12-04 21:15:54 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 930 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:15:54 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 6.435 | nll_loss 5.263 | ppl 38.39 | bleu 13.23 | wps 4085.4 | wpb 7753.9 | bsz 142.4 | num_updates 3715 | best_bleu 13.3\n",
            "2023-12-04 21:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 3715 updates\n",
            "2023-12-04 21:15:54 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint930.pt\n",
            "2023-12-04 21:15:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint930.pt\n",
            "2023-12-04 21:15:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint930.pt (epoch 930 @ 3715 updates, score 13.23) (writing took 2.1317647739997483 seconds)\n",
            "2023-12-04 21:15:56 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)\n",
            "2023-12-04 21:15:56 | INFO | train | epoch 930 | loss 2.007 | nll_loss 0.463 | ppl 1.38 | wps 20265.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3715 | lr 0.000328134 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3705\n",
            "2023-12-04 21:15:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 931:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:56 | INFO | fairseq.trainer | begin training epoch 931\n",
            "2023-12-04 21:15:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:15:58 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)\n",
            "2023-12-04 21:15:58 | INFO | train | epoch 931 | loss 2.006 | nll_loss 0.459 | ppl 1.38 | wps 142259 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3719 | lr 0.000327957 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3707\n",
            "2023-12-04 21:15:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 932:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:15:58 | INFO | fairseq.trainer | begin training epoch 932\n",
            "2023-12-04 21:15:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:01 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)\n",
            "2023-12-04 21:16:01 | INFO | train | epoch 932 | loss 2.006 | nll_loss 0.461 | ppl 1.38 | wps 139081 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3723 | lr 0.000327781 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3709\n",
            "2023-12-04 21:16:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 933:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:01 | INFO | fairseq.trainer | begin training epoch 933\n",
            "2023-12-04 21:16:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:03 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)\n",
            "2023-12-04 21:16:03 | INFO | train | epoch 933 | loss 2.006 | nll_loss 0.461 | ppl 1.38 | wps 142158 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3727 | lr 0.000327605 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3712\n",
            "2023-12-04 21:16:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 934:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:03 | INFO | fairseq.trainer | begin training epoch 934\n",
            "2023-12-04 21:16:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:06 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)\n",
            "2023-12-04 21:16:06 | INFO | train | epoch 934 | loss 2.006 | nll_loss 0.46 | ppl 1.38 | wps 142384 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3731 | lr 0.000327429 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3714\n",
            "2023-12-04 21:16:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 935:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:06 | INFO | fairseq.trainer | begin training epoch 935\n",
            "2023-12-04 21:16:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:08 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)\n",
            "2023-12-04 21:16:08 | INFO | train | epoch 935 | loss 2.006 | nll_loss 0.46 | ppl 1.38 | wps 142570 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3735 | lr 0.000327254 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3717\n",
            "2023-12-04 21:16:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 936:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:08 | INFO | fairseq.trainer | begin training epoch 936\n",
            "2023-12-04 21:16:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:10 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)\n",
            "2023-12-04 21:16:10 | INFO | train | epoch 936 | loss 2.008 | nll_loss 0.464 | ppl 1.38 | wps 142979 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3739 | lr 0.000327079 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3719\n",
            "2023-12-04 21:16:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 937:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:10 | INFO | fairseq.trainer | begin training epoch 937\n",
            "2023-12-04 21:16:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:13 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)\n",
            "2023-12-04 21:16:13 | INFO | train | epoch 937 | loss 2.002 | nll_loss 0.456 | ppl 1.37 | wps 141940 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3743 | lr 0.000326904 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3722\n",
            "2023-12-04 21:16:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 938:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:13 | INFO | fairseq.trainer | begin training epoch 938\n",
            "2023-12-04 21:16:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:15 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)\n",
            "2023-12-04 21:16:15 | INFO | train | epoch 938 | loss 2.005 | nll_loss 0.46 | ppl 1.38 | wps 142295 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3747 | lr 0.000326729 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3724\n",
            "2023-12-04 21:16:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 939:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:15 | INFO | fairseq.trainer | begin training epoch 939\n",
            "2023-12-04 21:16:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:18 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)\n",
            "2023-12-04 21:16:18 | INFO | train | epoch 939 | loss 2.004 | nll_loss 0.46 | ppl 1.38 | wps 142756 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3751 | lr 0.000326555 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3726\n",
            "2023-12-04 21:16:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 940:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:18 | INFO | fairseq.trainer | begin training epoch 940\n",
            "2023-12-04 21:16:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 940:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:16:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:16:22 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:16:22 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:16:23 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e sescioin semanæ de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:16:23 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 21:16:25 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoppòsti à di microonde ò di atri mezi pe rescädamento do çibbo.\n",
            "2023-12-04 21:16:25 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:16:27 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:16:27 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.71s/it]\u001b[A2023-12-04 21:16:29 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; o l’é trovou pe de ciù inte lonquente ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:16:29 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.88s/it]\u001b[A2023-12-04 21:16:30 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggia quaddræ): de sti, 75.68 km (29173 quaddræ) che s’attreuvan in sce l’Asia sud-òvest, 23762 km (29173), ch’a l’é quaddrâ in Euröpa) inte l’Asia sud-òvest, e 23764 km (174).\n",
            "2023-12-04 21:16:30 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:16:32 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ di attirati de 5.000 de vixitatoî unichi into mese d'öto d'ottobre, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou à Duceante, Wombur de Ombur.\n",
            "2023-12-04 21:16:32 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 940 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.77s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:16:32 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 6.446 | nll_loss 5.275 | ppl 38.73 | bleu 13.31 | wps 4157 | wpb 7753.9 | bsz 142.4 | num_updates 3755 | best_bleu 13.31\n",
            "2023-12-04 21:16:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 3755 updates\n",
            "2023-12-04 21:16:32 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint940.pt\n",
            "2023-12-04 21:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint940.pt\n",
            "2023-12-04 21:16:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint940.pt (epoch 940 @ 3755 updates, score 13.31) (writing took 3.924086252000052 seconds)\n",
            "2023-12-04 21:16:36 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)\n",
            "2023-12-04 21:16:36 | INFO | train | epoch 940 | loss 2.004 | nll_loss 0.458 | ppl 1.37 | wps 18529.1 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 3755 | lr 0.000326381 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3745\n",
            "2023-12-04 21:16:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 941:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:36 | INFO | fairseq.trainer | begin training epoch 941\n",
            "2023-12-04 21:16:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:39 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)\n",
            "2023-12-04 21:16:39 | INFO | train | epoch 941 | loss 2.003 | nll_loss 0.459 | ppl 1.37 | wps 138691 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 3759 | lr 0.000326207 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3747\n",
            "2023-12-04 21:16:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 942:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:39 | INFO | fairseq.trainer | begin training epoch 942\n",
            "2023-12-04 21:16:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:41 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)\n",
            "2023-12-04 21:16:41 | INFO | train | epoch 942 | loss 2.002 | nll_loss 0.458 | ppl 1.37 | wps 141199 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3763 | lr 0.000326034 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3750\n",
            "2023-12-04 21:16:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 943:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:41 | INFO | fairseq.trainer | begin training epoch 943\n",
            "2023-12-04 21:16:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:44 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)\n",
            "2023-12-04 21:16:44 | INFO | train | epoch 943 | loss 2.002 | nll_loss 0.455 | ppl 1.37 | wps 141152 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3767 | lr 0.000325861 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3752\n",
            "2023-12-04 21:16:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 944:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:44 | INFO | fairseq.trainer | begin training epoch 944\n",
            "2023-12-04 21:16:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:46 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)\n",
            "2023-12-04 21:16:46 | INFO | train | epoch 944 | loss 2.002 | nll_loss 0.457 | ppl 1.37 | wps 143210 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3771 | lr 0.000325688 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3755\n",
            "2023-12-04 21:16:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 945:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:46 | INFO | fairseq.trainer | begin training epoch 945\n",
            "2023-12-04 21:16:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:48 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)\n",
            "2023-12-04 21:16:48 | INFO | train | epoch 945 | loss 2.002 | nll_loss 0.458 | ppl 1.37 | wps 140138 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3775 | lr 0.000325515 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3757\n",
            "2023-12-04 21:16:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 946:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:48 | INFO | fairseq.trainer | begin training epoch 946\n",
            "2023-12-04 21:16:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:51 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)\n",
            "2023-12-04 21:16:51 | INFO | train | epoch 946 | loss 2.003 | nll_loss 0.457 | ppl 1.37 | wps 139548 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3779 | lr 0.000325343 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3760\n",
            "2023-12-04 21:16:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 947:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:51 | INFO | fairseq.trainer | begin training epoch 947\n",
            "2023-12-04 21:16:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:53 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)\n",
            "2023-12-04 21:16:53 | INFO | train | epoch 947 | loss 2.001 | nll_loss 0.457 | ppl 1.37 | wps 143620 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3783 | lr 0.000325171 | gnorm 0.131 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3762\n",
            "2023-12-04 21:16:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 948:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:53 | INFO | fairseq.trainer | begin training epoch 948\n",
            "2023-12-04 21:16:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:56 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)\n",
            "2023-12-04 21:16:56 | INFO | train | epoch 948 | loss 2.003 | nll_loss 0.459 | ppl 1.37 | wps 145204 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 3787 | lr 0.000324999 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3764\n",
            "2023-12-04 21:16:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 949:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:56 | INFO | fairseq.trainer | begin training epoch 949\n",
            "2023-12-04 21:16:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:16:58 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)\n",
            "2023-12-04 21:16:58 | INFO | train | epoch 949 | loss 2 | nll_loss 0.454 | ppl 1.37 | wps 144993 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 3791 | lr 0.000324828 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3767\n",
            "2023-12-04 21:16:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 950:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:16:58 | INFO | fairseq.trainer | begin training epoch 950\n",
            "2023-12-04 21:16:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 950:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:17:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:17:02 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:17:02 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:17:03 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin settematichi struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:17:03 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:17:05 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:17:05 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:17:07 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:17:07 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:17:09 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caso sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:17:09 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:17:11 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): de sti 75.68 km (2917373 quaddræ) in sciâ scituæ inte l’Asia sud-òvest, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:17:11 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.74s/it]\u001b[A2023-12-04 21:17:12 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.000 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh 24 estlante, ch'o l'é stæto lasciou do tutto o nomme de Omburbante.\n",
            "2023-12-04 21:17:12 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 950 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:17:12 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 6.454 | nll_loss 5.286 | ppl 39.02 | bleu 13.16 | wps 4224.4 | wpb 7753.9 | bsz 142.4 | num_updates 3795 | best_bleu 13.31\n",
            "2023-12-04 21:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 3795 updates\n",
            "2023-12-04 21:17:12 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint950.pt\n",
            "2023-12-04 21:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint950.pt\n",
            "2023-12-04 21:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint950.pt (epoch 950 @ 3795 updates, score 13.16) (writing took 5.9665461039994625 seconds)\n",
            "2023-12-04 21:17:18 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)\n",
            "2023-12-04 21:17:18 | INFO | train | epoch 950 | loss 1.999 | nll_loss 0.455 | ppl 1.37 | wps 16871.5 | ups 0.2 | wpb 85903.8 | bsz 1548.2 | num_updates 3795 | lr 0.000324657 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3787\n",
            "2023-12-04 21:17:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 951:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:18 | INFO | fairseq.trainer | begin training epoch 951\n",
            "2023-12-04 21:17:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:21 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)\n",
            "2023-12-04 21:17:21 | INFO | train | epoch 951 | loss 2 | nll_loss 0.455 | ppl 1.37 | wps 140407 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3799 | lr 0.000324486 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3790\n",
            "2023-12-04 21:17:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 952:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:21 | INFO | fairseq.trainer | begin training epoch 952\n",
            "2023-12-04 21:17:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:23 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)\n",
            "2023-12-04 21:17:23 | INFO | train | epoch 952 | loss 2 | nll_loss 0.456 | ppl 1.37 | wps 142187 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3803 | lr 0.000324315 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3792\n",
            "2023-12-04 21:17:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 953:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:23 | INFO | fairseq.trainer | begin training epoch 953\n",
            "2023-12-04 21:17:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:26 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)\n",
            "2023-12-04 21:17:26 | INFO | train | epoch 953 | loss 1.998 | nll_loss 0.453 | ppl 1.37 | wps 144154 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3807 | lr 0.000324144 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3794\n",
            "2023-12-04 21:17:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 954:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:26 | INFO | fairseq.trainer | begin training epoch 954\n",
            "2023-12-04 21:17:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:28 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)\n",
            "2023-12-04 21:17:28 | INFO | train | epoch 954 | loss 1.999 | nll_loss 0.455 | ppl 1.37 | wps 142042 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3811 | lr 0.000323974 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3797\n",
            "2023-12-04 21:17:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 955:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:28 | INFO | fairseq.trainer | begin training epoch 955\n",
            "2023-12-04 21:17:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:30 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)\n",
            "2023-12-04 21:17:30 | INFO | train | epoch 955 | loss 1.998 | nll_loss 0.453 | ppl 1.37 | wps 141642 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3815 | lr 0.000323804 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3799\n",
            "2023-12-04 21:17:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 956:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:31 | INFO | fairseq.trainer | begin training epoch 956\n",
            "2023-12-04 21:17:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:33 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)\n",
            "2023-12-04 21:17:33 | INFO | train | epoch 956 | loss 1.996 | nll_loss 0.451 | ppl 1.37 | wps 143215 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3819 | lr 0.000323635 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3802\n",
            "2023-12-04 21:17:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 957:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:33 | INFO | fairseq.trainer | begin training epoch 957\n",
            "2023-12-04 21:17:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:35 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)\n",
            "2023-12-04 21:17:35 | INFO | train | epoch 957 | loss 1.997 | nll_loss 0.453 | ppl 1.37 | wps 142888 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3823 | lr 0.000323465 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3804\n",
            "2023-12-04 21:17:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 958:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:35 | INFO | fairseq.trainer | begin training epoch 958\n",
            "2023-12-04 21:17:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:38 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)\n",
            "2023-12-04 21:17:38 | INFO | train | epoch 958 | loss 1.999 | nll_loss 0.456 | ppl 1.37 | wps 143089 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3827 | lr 0.000323296 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3806\n",
            "2023-12-04 21:17:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 959:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:38 | INFO | fairseq.trainer | begin training epoch 959\n",
            "2023-12-04 21:17:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:40 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)\n",
            "2023-12-04 21:17:40 | INFO | train | epoch 959 | loss 1.997 | nll_loss 0.453 | ppl 1.37 | wps 142105 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3831 | lr 0.000323127 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3809\n",
            "2023-12-04 21:17:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 960:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:40 | INFO | fairseq.trainer | begin training epoch 960\n",
            "2023-12-04 21:17:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 960:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 21:17:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:17:44 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:17:44 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:17:45 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e seçioin semanæ de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:17:45 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 21:17:47 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:17:47 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:17:49 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:17:49 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.68s/it]\u001b[A2023-12-04 21:17:51 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ascì trovou in sce un Internet ò inte l’Internet ò un pòsto-Fi pubrico.\n",
            "2023-12-04 21:17:51 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.83s/it]\u001b[A2023-12-04 21:17:53 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa d’ato): de sti 75.68 km (2917373 quaddræ) in sce l’Asia sud-òvest, ch’o l’à 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:17:53 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.72s/it]\u001b[A2023-12-04 21:17:54 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo de impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web ch'o peu attiâ di attirati de 5.000 vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou à Duceante, Wor.\n",
            "2023-12-04 21:17:54 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 960 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.71s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:17:54 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 6.444 | nll_loss 5.274 | ppl 38.7 | bleu 13.22 | wps 4280.4 | wpb 7753.9 | bsz 142.4 | num_updates 3835 | best_bleu 13.31\n",
            "2023-12-04 21:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 3835 updates\n",
            "2023-12-04 21:17:54 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint960.pt\n",
            "2023-12-04 21:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint960.pt\n",
            "2023-12-04 21:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint960.pt (epoch 960 @ 3835 updates, score 13.22) (writing took 2.1385424890004288 seconds)\n",
            "2023-12-04 21:17:57 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)\n",
            "2023-12-04 21:17:57 | INFO | train | epoch 960 | loss 1.997 | nll_loss 0.454 | ppl 1.37 | wps 20848.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3835 | lr 0.000322959 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3825\n",
            "2023-12-04 21:17:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 961:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:57 | INFO | fairseq.trainer | begin training epoch 961\n",
            "2023-12-04 21:17:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:17:59 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)\n",
            "2023-12-04 21:17:59 | INFO | train | epoch 961 | loss 1.996 | nll_loss 0.451 | ppl 1.37 | wps 140885 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3839 | lr 0.000322791 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3828\n",
            "2023-12-04 21:17:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 962:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:17:59 | INFO | fairseq.trainer | begin training epoch 962\n",
            "2023-12-04 21:17:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:01 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)\n",
            "2023-12-04 21:18:01 | INFO | train | epoch 962 | loss 2 | nll_loss 0.457 | ppl 1.37 | wps 140573 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3843 | lr 0.000322623 | gnorm 0.135 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3830\n",
            "2023-12-04 21:18:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 963:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:01 | INFO | fairseq.trainer | begin training epoch 963\n",
            "2023-12-04 21:18:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:04 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)\n",
            "2023-12-04 21:18:04 | INFO | train | epoch 963 | loss 2.001 | nll_loss 0.458 | ppl 1.37 | wps 141688 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3847 | lr 0.000322455 | gnorm 0.145 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3833\n",
            "2023-12-04 21:18:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 964:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:04 | INFO | fairseq.trainer | begin training epoch 964\n",
            "2023-12-04 21:18:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:06 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)\n",
            "2023-12-04 21:18:06 | INFO | train | epoch 964 | loss 1.999 | nll_loss 0.456 | ppl 1.37 | wps 142567 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3851 | lr 0.000322287 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3835\n",
            "2023-12-04 21:18:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 965:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:06 | INFO | fairseq.trainer | begin training epoch 965\n",
            "2023-12-04 21:18:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:09 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)\n",
            "2023-12-04 21:18:09 | INFO | train | epoch 965 | loss 1.999 | nll_loss 0.455 | ppl 1.37 | wps 140880 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3855 | lr 0.00032212 | gnorm 0.134 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3837\n",
            "2023-12-04 21:18:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 966:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:09 | INFO | fairseq.trainer | begin training epoch 966\n",
            "2023-12-04 21:18:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:11 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)\n",
            "2023-12-04 21:18:11 | INFO | train | epoch 966 | loss 1.998 | nll_loss 0.456 | ppl 1.37 | wps 140850 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3859 | lr 0.000321953 | gnorm 0.136 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3840\n",
            "2023-12-04 21:18:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 967:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:11 | INFO | fairseq.trainer | begin training epoch 967\n",
            "2023-12-04 21:18:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:14 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)\n",
            "2023-12-04 21:18:14 | INFO | train | epoch 967 | loss 1.995 | nll_loss 0.451 | ppl 1.37 | wps 141440 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3863 | lr 0.000321786 | gnorm 0.138 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3842\n",
            "2023-12-04 21:18:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 968:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:14 | INFO | fairseq.trainer | begin training epoch 968\n",
            "2023-12-04 21:18:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:16 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)\n",
            "2023-12-04 21:18:16 | INFO | train | epoch 968 | loss 1.997 | nll_loss 0.455 | ppl 1.37 | wps 141479 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3867 | lr 0.00032162 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3845\n",
            "2023-12-04 21:18:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 969:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:16 | INFO | fairseq.trainer | begin training epoch 969\n",
            "2023-12-04 21:18:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:18 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)\n",
            "2023-12-04 21:18:18 | INFO | train | epoch 969 | loss 1.994 | nll_loss 0.45 | ppl 1.37 | wps 143856 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3871 | lr 0.000321454 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3847\n",
            "2023-12-04 21:18:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 970:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:18 | INFO | fairseq.trainer | begin training epoch 970\n",
            "2023-12-04 21:18:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 970:  75% 3/4 [00:01<00:00,  1.61it/s]2023-12-04 21:18:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:18:22 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:18:22 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  14% 1/7 [00:01<00:09,  1.50s/it]\u001b[A2023-12-04 21:18:24 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settemañe de struttua fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:18:24 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.55s/it]\u001b[A2023-12-04 21:18:26 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che Aldun an òffito à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:18:26 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.60s/it]\u001b[A2023-12-04 21:18:27 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:18:27 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:18:30 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte l’Internet ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:18:30 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.98s/it]\u001b[A2023-12-04 21:18:31 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) che s’attreuva inte l’Asia sud-òvest, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:18:31 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.82s/it]\u001b[A2023-12-04 21:18:33 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de öse d'ottobre, inserçioin personali, un network de noçieh 24 estlante, ch'o l'é stæto lasciou un mondiale, ciammou o nomme de Omburn Wor.\n",
            "2023-12-04 21:18:33 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 970 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.79s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:18:33 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 6.446 | nll_loss 5.28 | ppl 38.84 | bleu 13.24 | wps 4084.1 | wpb 7753.9 | bsz 142.4 | num_updates 3875 | best_bleu 13.31\n",
            "2023-12-04 21:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 3875 updates\n",
            "2023-12-04 21:18:33 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint970.pt\n",
            "2023-12-04 21:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint970.pt\n",
            "2023-12-04 21:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint970.pt (epoch 970 @ 3875 updates, score 13.24) (writing took 2.1230603820004035 seconds)\n",
            "2023-12-04 21:18:35 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)\n",
            "2023-12-04 21:18:35 | INFO | train | epoch 970 | loss 1.994 | nll_loss 0.449 | ppl 1.37 | wps 20215.8 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3875 | lr 0.000321288 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3864\n",
            "2023-12-04 21:18:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 971:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:35 | INFO | fairseq.trainer | begin training epoch 971\n",
            "2023-12-04 21:18:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:38 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)\n",
            "2023-12-04 21:18:38 | INFO | train | epoch 971 | loss 1.992 | nll_loss 0.448 | ppl 1.36 | wps 137476 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 3879 | lr 0.000321122 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3867\n",
            "2023-12-04 21:18:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 972:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:38 | INFO | fairseq.trainer | begin training epoch 972\n",
            "2023-12-04 21:18:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:40 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)\n",
            "2023-12-04 21:18:40 | INFO | train | epoch 972 | loss 1.993 | nll_loss 0.449 | ppl 1.36 | wps 142458 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3883 | lr 0.000320957 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3869\n",
            "2023-12-04 21:18:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 973:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:40 | INFO | fairseq.trainer | begin training epoch 973\n",
            "2023-12-04 21:18:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:43 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)\n",
            "2023-12-04 21:18:43 | INFO | train | epoch 973 | loss 1.993 | nll_loss 0.449 | ppl 1.37 | wps 142006 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3887 | lr 0.000320791 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3871\n",
            "2023-12-04 21:18:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 974:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:43 | INFO | fairseq.trainer | begin training epoch 974\n",
            "2023-12-04 21:18:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:45 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)\n",
            "2023-12-04 21:18:45 | INFO | train | epoch 974 | loss 1.994 | nll_loss 0.452 | ppl 1.37 | wps 138823 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3891 | lr 0.000320626 | gnorm 0.13 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3874\n",
            "2023-12-04 21:18:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 975:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:45 | INFO | fairseq.trainer | begin training epoch 975\n",
            "2023-12-04 21:18:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:48 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)\n",
            "2023-12-04 21:18:48 | INFO | train | epoch 975 | loss 1.993 | nll_loss 0.448 | ppl 1.36 | wps 143249 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3895 | lr 0.000320462 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3876\n",
            "2023-12-04 21:18:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 976:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:48 | INFO | fairseq.trainer | begin training epoch 976\n",
            "2023-12-04 21:18:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:50 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)\n",
            "2023-12-04 21:18:50 | INFO | train | epoch 976 | loss 1.993 | nll_loss 0.45 | ppl 1.37 | wps 142572 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3899 | lr 0.000320297 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3879\n",
            "2023-12-04 21:18:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 977:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:50 | INFO | fairseq.trainer | begin training epoch 977\n",
            "2023-12-04 21:18:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:52 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)\n",
            "2023-12-04 21:18:52 | INFO | train | epoch 977 | loss 1.992 | nll_loss 0.448 | ppl 1.36 | wps 142100 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3903 | lr 0.000320133 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3881\n",
            "2023-12-04 21:18:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 978:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:52 | INFO | fairseq.trainer | begin training epoch 978\n",
            "2023-12-04 21:18:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:55 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)\n",
            "2023-12-04 21:18:55 | INFO | train | epoch 978 | loss 1.991 | nll_loss 0.448 | ppl 1.36 | wps 142631 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3907 | lr 0.000319969 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3884\n",
            "2023-12-04 21:18:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 979:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:55 | INFO | fairseq.trainer | begin training epoch 979\n",
            "2023-12-04 21:18:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:18:57 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)\n",
            "2023-12-04 21:18:57 | INFO | train | epoch 979 | loss 1.99 | nll_loss 0.447 | ppl 1.36 | wps 144951 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 3911 | lr 0.000319806 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3886\n",
            "2023-12-04 21:18:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 980:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:18:57 | INFO | fairseq.trainer | begin training epoch 980\n",
            "2023-12-04 21:18:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 980:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:19:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:19:01 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, ascì che peuan revelâse inte quarcheduña de çircostanse.\n",
            "2023-12-04 21:19:01 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:19:03 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settemañe de struttua fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:19:03 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:19:04 | INFO | fairseq.tasks.translation | example hypothesis: Sence ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:19:04 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.56s/it]\u001b[A2023-12-04 21:19:06 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:19:06 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:19:08 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo soggettiniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:19:08 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:19:10 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest de Ponente, 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:19:10 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:19:12 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.0000 de vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou à Duceante, Woldur de Ombur.\n",
            "2023-12-04 21:19:12 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 980 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:19:12 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 6.448 | nll_loss 5.281 | ppl 38.88 | bleu 13.23 | wps 4224.8 | wpb 7753.9 | bsz 142.4 | num_updates 3915 | best_bleu 13.31\n",
            "2023-12-04 21:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 3915 updates\n",
            "2023-12-04 21:19:12 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint980.pt\n",
            "2023-12-04 21:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint980.pt\n",
            "2023-12-04 21:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint980.pt (epoch 980 @ 3915 updates, score 13.23) (writing took 2.1321787400001995 seconds)\n",
            "2023-12-04 21:19:14 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)\n",
            "2023-12-04 21:19:14 | INFO | train | epoch 980 | loss 1.992 | nll_loss 0.45 | ppl 1.37 | wps 20768.2 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3915 | lr 0.000319642 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3902\n",
            "2023-12-04 21:19:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 981:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:14 | INFO | fairseq.trainer | begin training epoch 981\n",
            "2023-12-04 21:19:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:16 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)\n",
            "2023-12-04 21:19:16 | INFO | train | epoch 981 | loss 1.991 | nll_loss 0.447 | ppl 1.36 | wps 141609 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3919 | lr 0.000319479 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3905\n",
            "2023-12-04 21:19:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 982:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:16 | INFO | fairseq.trainer | begin training epoch 982\n",
            "2023-12-04 21:19:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:19 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)\n",
            "2023-12-04 21:19:19 | INFO | train | epoch 982 | loss 1.989 | nll_loss 0.445 | ppl 1.36 | wps 140839 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3923 | lr 0.000319316 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3907\n",
            "2023-12-04 21:19:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 983:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:19 | INFO | fairseq.trainer | begin training epoch 983\n",
            "2023-12-04 21:19:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:21 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)\n",
            "2023-12-04 21:19:21 | INFO | train | epoch 983 | loss 1.987 | nll_loss 0.445 | ppl 1.36 | wps 141702 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3927 | lr 0.000319153 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3910\n",
            "2023-12-04 21:19:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 984:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:21 | INFO | fairseq.trainer | begin training epoch 984\n",
            "2023-12-04 21:19:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:23 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)\n",
            "2023-12-04 21:19:23 | INFO | train | epoch 984 | loss 1.992 | nll_loss 0.449 | ppl 1.37 | wps 142785 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3931 | lr 0.000318991 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3912\n",
            "2023-12-04 21:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 985:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:24 | INFO | fairseq.trainer | begin training epoch 985\n",
            "2023-12-04 21:19:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:26 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)\n",
            "2023-12-04 21:19:26 | INFO | train | epoch 985 | loss 1.99 | nll_loss 0.446 | ppl 1.36 | wps 142817 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3935 | lr 0.000318829 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3915\n",
            "2023-12-04 21:19:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 986:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:26 | INFO | fairseq.trainer | begin training epoch 986\n",
            "2023-12-04 21:19:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:28 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)\n",
            "2023-12-04 21:19:28 | INFO | train | epoch 986 | loss 1.989 | nll_loss 0.447 | ppl 1.36 | wps 143171 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3939 | lr 0.000318667 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3917\n",
            "2023-12-04 21:19:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 987:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:28 | INFO | fairseq.trainer | begin training epoch 987\n",
            "2023-12-04 21:19:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:31 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)\n",
            "2023-12-04 21:19:31 | INFO | train | epoch 987 | loss 1.989 | nll_loss 0.446 | ppl 1.36 | wps 141678 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3943 | lr 0.000318505 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3919\n",
            "2023-12-04 21:19:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 988:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:31 | INFO | fairseq.trainer | begin training epoch 988\n",
            "2023-12-04 21:19:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:33 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)\n",
            "2023-12-04 21:19:33 | INFO | train | epoch 988 | loss 1.988 | nll_loss 0.447 | ppl 1.36 | wps 140627 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3947 | lr 0.000318344 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3922\n",
            "2023-12-04 21:19:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 989:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:33 | INFO | fairseq.trainer | begin training epoch 989\n",
            "2023-12-04 21:19:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:36 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)\n",
            "2023-12-04 21:19:36 | INFO | train | epoch 989 | loss 1.989 | nll_loss 0.448 | ppl 1.36 | wps 142214 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3951 | lr 0.000318183 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3924\n",
            "2023-12-04 21:19:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 990:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:36 | INFO | fairseq.trainer | begin training epoch 990\n",
            "2023-12-04 21:19:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 990:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:19:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:19:39 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge ascì, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:19:39 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 21:19:41 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin settematichi de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:19:41 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.49s/it]\u001b[A2023-12-04 21:19:43 | INFO | fairseq.tasks.translation | example hypothesis: Sence ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio de microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:19:43 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:19:44 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:19:44 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:19:47 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (isòspite sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ascì trovou in sce l’Internet ò inte un pòsto con Wi-Fi pubrico.\n",
            "2023-12-04 21:19:47 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:19:48 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): in sce sti, 75.68 km (29173 quaddræ) se peu vegnî quaddræ inte l’Asia sud-òvest de Ponente, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:19:48 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.72s/it]\u001b[A2023-12-04 21:19:50 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo de impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web o peu attâ di attirati de 5.000 vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh 24 estlante, ch'o l'é stæto lasciou à Duceante, Wor.\n",
            "2023-12-04 21:19:50 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 990 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.71s/it]\u001b[A\n",
            "                                                                      \u001b[A2023-12-04 21:19:50 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 6.45 | nll_loss 5.284 | ppl 38.97 | bleu 13.1 | wps 4264.1 | wpb 7753.9 | bsz 142.4 | num_updates 3955 | best_bleu 13.31\n",
            "2023-12-04 21:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 3955 updates\n",
            "2023-12-04 21:19:50 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint990.pt\n",
            "2023-12-04 21:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint990.pt\n",
            "2023-12-04 21:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint990.pt (epoch 990 @ 3955 updates, score 13.1) (writing took 2.136991375999969 seconds)\n",
            "2023-12-04 21:19:52 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)\n",
            "2023-12-04 21:19:52 | INFO | train | epoch 990 | loss 1.988 | nll_loss 0.444 | ppl 1.36 | wps 20908.2 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3955 | lr 0.000318022 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3941\n",
            "2023-12-04 21:19:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 991:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:52 | INFO | fairseq.trainer | begin training epoch 991\n",
            "2023-12-04 21:19:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:54 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)\n",
            "2023-12-04 21:19:54 | INFO | train | epoch 991 | loss 1.987 | nll_loss 0.444 | ppl 1.36 | wps 139253 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 3959 | lr 0.000317861 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3943\n",
            "2023-12-04 21:19:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 992:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:55 | INFO | fairseq.trainer | begin training epoch 992\n",
            "2023-12-04 21:19:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:57 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)\n",
            "2023-12-04 21:19:57 | INFO | train | epoch 992 | loss 1.987 | nll_loss 0.445 | ppl 1.36 | wps 140850 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3963 | lr 0.000317701 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3946\n",
            "2023-12-04 21:19:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 993:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:57 | INFO | fairseq.trainer | begin training epoch 993\n",
            "2023-12-04 21:19:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:19:59 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)\n",
            "2023-12-04 21:19:59 | INFO | train | epoch 993 | loss 1.987 | nll_loss 0.444 | ppl 1.36 | wps 139665 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3967 | lr 0.00031754 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3948\n",
            "2023-12-04 21:19:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 994:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:19:59 | INFO | fairseq.trainer | begin training epoch 994\n",
            "2023-12-04 21:19:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:02 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)\n",
            "2023-12-04 21:20:02 | INFO | train | epoch 994 | loss 1.987 | nll_loss 0.445 | ppl 1.36 | wps 144600 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 3971 | lr 0.00031738 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3950\n",
            "2023-12-04 21:20:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 995:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:02 | INFO | fairseq.trainer | begin training epoch 995\n",
            "2023-12-04 21:20:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:04 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)\n",
            "2023-12-04 21:20:04 | INFO | train | epoch 995 | loss 1.986 | nll_loss 0.444 | ppl 1.36 | wps 142977 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3975 | lr 0.000317221 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3953\n",
            "2023-12-04 21:20:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 996:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:04 | INFO | fairseq.trainer | begin training epoch 996\n",
            "2023-12-04 21:20:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:07 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)\n",
            "2023-12-04 21:20:07 | INFO | train | epoch 996 | loss 1.986 | nll_loss 0.443 | ppl 1.36 | wps 143599 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 3979 | lr 0.000317061 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3955\n",
            "2023-12-04 21:20:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 997:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:07 | INFO | fairseq.trainer | begin training epoch 997\n",
            "2023-12-04 21:20:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:09 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)\n",
            "2023-12-04 21:20:09 | INFO | train | epoch 997 | loss 1.985 | nll_loss 0.442 | ppl 1.36 | wps 142024 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 3983 | lr 0.000316902 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3958\n",
            "2023-12-04 21:20:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 998:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:09 | INFO | fairseq.trainer | begin training epoch 998\n",
            "2023-12-04 21:20:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:11 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)\n",
            "2023-12-04 21:20:11 | INFO | train | epoch 998 | loss 1.986 | nll_loss 0.444 | ppl 1.36 | wps 141004 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 3987 | lr 0.000316743 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3960\n",
            "2023-12-04 21:20:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 999:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:11 | INFO | fairseq.trainer | begin training epoch 999\n",
            "2023-12-04 21:20:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:14 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)\n",
            "2023-12-04 21:20:14 | INFO | train | epoch 999 | loss 1.984 | nll_loss 0.442 | ppl 1.36 | wps 142962 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 3991 | lr 0.000316584 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3963\n",
            "2023-12-04 21:20:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1000:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:14 | INFO | fairseq.trainer | begin training epoch 1000\n",
            "2023-12-04 21:20:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1000:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:20:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:20:18 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no en deuviæ da-e famigge ascì, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:20:18 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 21:20:19 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e seçioin settemanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:20:19 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.51s/it]\u001b[A2023-12-04 21:20:21 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erte propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:20:21 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:20:23 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:20:23 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:20:25 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’à trovou ascì unna collocâ inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:20:25 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.86s/it]\u001b[A2023-12-04 21:20:26 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (29173 quaddræ) se rompæ inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:20:26 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.72s/it]\u001b[A2023-12-04 21:20:28 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attâ di attirati de 5.000 vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh 24, e o ponte un mondo de pontellou, ciammou Duceoldur de Ombur.\n",
            "2023-12-04 21:20:28 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1000 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.71s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:20:28 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 6.458 | nll_loss 5.295 | ppl 39.27 | bleu 13.15 | wps 4265.1 | wpb 7753.9 | bsz 142.4 | num_updates 3995 | best_bleu 13.31\n",
            "2023-12-04 21:20:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 3995 updates\n",
            "2023-12-04 21:20:28 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1000.pt\n",
            "2023-12-04 21:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1000.pt\n",
            "2023-12-04 21:20:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1000.pt (epoch 1000 @ 3995 updates, score 13.15) (writing took 2.1306757660004223 seconds)\n",
            "2023-12-04 21:20:30 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)\n",
            "2023-12-04 21:20:30 | INFO | train | epoch 1000 | loss 1.987 | nll_loss 0.444 | ppl 1.36 | wps 20916.2 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 3995 | lr 0.000316426 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 3979\n",
            "2023-12-04 21:20:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1001:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:30 | INFO | fairseq.trainer | begin training epoch 1001\n",
            "2023-12-04 21:20:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:33 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)\n",
            "2023-12-04 21:20:33 | INFO | train | epoch 1001 | loss 1.985 | nll_loss 0.443 | ppl 1.36 | wps 140413 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 3999 | lr 0.000316267 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 3981\n",
            "2023-12-04 21:20:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1002:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:33 | INFO | fairseq.trainer | begin training epoch 1002\n",
            "2023-12-04 21:20:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:35 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)\n",
            "2023-12-04 21:20:35 | INFO | train | epoch 1002 | loss 1.983 | nll_loss 0.44 | ppl 1.36 | wps 138689 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 4003 | lr 0.000316109 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3984\n",
            "2023-12-04 21:20:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1003:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:35 | INFO | fairseq.trainer | begin training epoch 1003\n",
            "2023-12-04 21:20:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:38 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)\n",
            "2023-12-04 21:20:38 | INFO | train | epoch 1003 | loss 1.985 | nll_loss 0.444 | ppl 1.36 | wps 140953 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4007 | lr 0.000315951 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 3986\n",
            "2023-12-04 21:20:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1004:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:38 | INFO | fairseq.trainer | begin training epoch 1004\n",
            "2023-12-04 21:20:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:40 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)\n",
            "2023-12-04 21:20:40 | INFO | train | epoch 1004 | loss 1.982 | nll_loss 0.44 | ppl 1.36 | wps 143208 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4011 | lr 0.000315794 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 3989\n",
            "2023-12-04 21:20:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1005:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:40 | INFO | fairseq.trainer | begin training epoch 1005\n",
            "2023-12-04 21:20:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:42 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)\n",
            "2023-12-04 21:20:42 | INFO | train | epoch 1005 | loss 1.985 | nll_loss 0.441 | ppl 1.36 | wps 141487 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4015 | lr 0.000315637 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3991\n",
            "2023-12-04 21:20:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1006:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:42 | INFO | fairseq.trainer | begin training epoch 1006\n",
            "2023-12-04 21:20:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:45 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)\n",
            "2023-12-04 21:20:45 | INFO | train | epoch 1006 | loss 1.982 | nll_loss 0.442 | ppl 1.36 | wps 142122 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4019 | lr 0.000315479 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 3994\n",
            "2023-12-04 21:20:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1007:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:45 | INFO | fairseq.trainer | begin training epoch 1007\n",
            "2023-12-04 21:20:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:47 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)\n",
            "2023-12-04 21:20:47 | INFO | train | epoch 1007 | loss 1.983 | nll_loss 0.441 | ppl 1.36 | wps 141185 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4023 | lr 0.000315323 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 3996\n",
            "2023-12-04 21:20:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1008:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:47 | INFO | fairseq.trainer | begin training epoch 1008\n",
            "2023-12-04 21:20:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:50 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)\n",
            "2023-12-04 21:20:50 | INFO | train | epoch 1008 | loss 1.983 | nll_loss 0.44 | ppl 1.36 | wps 137862 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 4027 | lr 0.000315166 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 3998\n",
            "2023-12-04 21:20:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1009:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:50 | INFO | fairseq.trainer | begin training epoch 1009\n",
            "2023-12-04 21:20:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:20:52 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)\n",
            "2023-12-04 21:20:52 | INFO | train | epoch 1009 | loss 1.983 | nll_loss 0.443 | ppl 1.36 | wps 143903 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 4031 | lr 0.000315009 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4001\n",
            "2023-12-04 21:20:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1010:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:20:52 | INFO | fairseq.trainer | begin training epoch 1010\n",
            "2023-12-04 21:20:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1010:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:20:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:20:56 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çirconstanse.\n",
            "2023-12-04 21:20:56 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 21:20:58 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçioin da-e sescioin settematichi de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:20:58 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:20:59 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù erte propoñan un reparto con unna ciù grande çernia de mangiâ che Aldun an produto di additi microonde ò di atri mezi pe rescädatua do çibbo.\n",
            "2023-12-04 21:20:59 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.56s/it]\u001b[A2023-12-04 21:21:01 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dæto unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:21:01 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:21:03 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é trovou pe de ciù inteisovie inte l’Internet caft ò un pòsto-Fi pubrico.\n",
            "2023-12-04 21:21:03 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:21:05 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (29173 quaddræ) se peu vegnî quaddræ inte l’Asia sud-òvest, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:21:05 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.74s/it]\u001b[A2023-12-04 21:21:06 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ de 5.000 vixitatoî de vixitoî unichi into mese d'ottobre, inserçioin personali, un network de nòçieh24, ch'o l'é vegnuo ponte un mondo etlante, ciammou Ducea o Wor.\n",
            "2023-12-04 21:21:06 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1010 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:21:06 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 6.452 | nll_loss 5.284 | ppl 38.96 | bleu 12.93 | wps 4232.9 | wpb 7753.9 | bsz 142.4 | num_updates 4035 | best_bleu 13.31\n",
            "2023-12-04 21:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 4035 updates\n",
            "2023-12-04 21:21:06 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1010.pt\n",
            "2023-12-04 21:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1010.pt\n",
            "2023-12-04 21:21:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1010.pt (epoch 1010 @ 4035 updates, score 12.93) (writing took 2.1312289130000863 seconds)\n",
            "2023-12-04 21:21:09 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)\n",
            "2023-12-04 21:21:09 | INFO | train | epoch 1010 | loss 1.984 | nll_loss 0.443 | ppl 1.36 | wps 20782.5 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4035 | lr 0.000314853 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4017\n",
            "2023-12-04 21:21:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1011:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:09 | INFO | fairseq.trainer | begin training epoch 1011\n",
            "2023-12-04 21:21:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:11 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)\n",
            "2023-12-04 21:21:11 | INFO | train | epoch 1011 | loss 1.981 | nll_loss 0.437 | ppl 1.35 | wps 136888 | ups 1.59 | wpb 85903.8 | bsz 1548.2 | num_updates 4039 | lr 0.000314697 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4020\n",
            "2023-12-04 21:21:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1012:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:11 | INFO | fairseq.trainer | begin training epoch 1012\n",
            "2023-12-04 21:21:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:14 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)\n",
            "2023-12-04 21:21:14 | INFO | train | epoch 1012 | loss 1.983 | nll_loss 0.443 | ppl 1.36 | wps 141472 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4043 | lr 0.000314542 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4022\n",
            "2023-12-04 21:21:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1013:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:14 | INFO | fairseq.trainer | begin training epoch 1013\n",
            "2023-12-04 21:21:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:16 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)\n",
            "2023-12-04 21:21:16 | INFO | train | epoch 1013 | loss 1.98 | nll_loss 0.439 | ppl 1.36 | wps 141658 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4047 | lr 0.000314386 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 4025\n",
            "2023-12-04 21:21:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1014:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:16 | INFO | fairseq.trainer | begin training epoch 1014\n",
            "2023-12-04 21:21:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:18 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)\n",
            "2023-12-04 21:21:18 | INFO | train | epoch 1014 | loss 1.982 | nll_loss 0.44 | ppl 1.36 | wps 143550 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4051 | lr 0.000314231 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4027\n",
            "2023-12-04 21:21:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1015:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:18 | INFO | fairseq.trainer | begin training epoch 1015\n",
            "2023-12-04 21:21:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:21 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)\n",
            "2023-12-04 21:21:21 | INFO | train | epoch 1015 | loss 1.981 | nll_loss 0.44 | ppl 1.36 | wps 143106 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4055 | lr 0.000314076 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4030\n",
            "2023-12-04 21:21:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1016:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:21 | INFO | fairseq.trainer | begin training epoch 1016\n",
            "2023-12-04 21:21:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:23 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)\n",
            "2023-12-04 21:21:23 | INFO | train | epoch 1016 | loss 1.979 | nll_loss 0.437 | ppl 1.35 | wps 142204 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4059 | lr 0.000313921 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4032\n",
            "2023-12-04 21:21:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1017:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:23 | INFO | fairseq.trainer | begin training epoch 1017\n",
            "2023-12-04 21:21:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:26 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)\n",
            "2023-12-04 21:21:26 | INFO | train | epoch 1017 | loss 1.98 | nll_loss 0.44 | ppl 1.36 | wps 139165 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4063 | lr 0.000313767 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 4034\n",
            "2023-12-04 21:21:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1018:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:26 | INFO | fairseq.trainer | begin training epoch 1018\n",
            "2023-12-04 21:21:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:28 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)\n",
            "2023-12-04 21:21:28 | INFO | train | epoch 1018 | loss 1.98 | nll_loss 0.438 | ppl 1.35 | wps 144831 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 4067 | lr 0.000313612 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4037\n",
            "2023-12-04 21:21:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1019:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:28 | INFO | fairseq.trainer | begin training epoch 1019\n",
            "2023-12-04 21:21:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:31 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)\n",
            "2023-12-04 21:21:31 | INFO | train | epoch 1019 | loss 1.979 | nll_loss 0.437 | ppl 1.35 | wps 141799 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4071 | lr 0.000313458 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4039\n",
            "2023-12-04 21:21:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1020:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:31 | INFO | fairseq.trainer | begin training epoch 1020\n",
            "2023-12-04 21:21:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1020:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:21:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:21:35 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:21:35 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  14% 1/7 [00:01<00:10,  1.80s/it]\u001b[A2023-12-04 21:21:36 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e settemañe de struttua de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:21:36 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.67s/it]\u001b[A2023-12-04 21:21:38 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che an produto di òffiti inte di microonde ò di atri mezi pe rescädatua do çibbo.\n",
            "2023-12-04 21:21:38 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  43% 3/7 [00:05<00:06,  1.67s/it]\u001b[A2023-12-04 21:21:40 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:21:40 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.77s/it]\u001b[A2023-12-04 21:21:42 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ascì trovou in sce l’Internet ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:21:42 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.90s/it]\u001b[A2023-12-04 21:21:44 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti, 75.68 km (2917373 quaddræ) che s’attreuva inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:21:44 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:21:45 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ di attirare 5.000 vixitatoî de vixitoî unichi into mese d'ottobre, inserçioin personali, un network de nòçieh24, ch'o l'é stæto lasciou un mondo etlante, ciammou Ducedweb.\n",
            "2023-12-04 21:21:45 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1020 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.78s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:21:45 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 6.45 | nll_loss 5.285 | ppl 38.99 | bleu 13.2 | wps 4163.6 | wpb 7753.9 | bsz 142.4 | num_updates 4075 | best_bleu 13.31\n",
            "2023-12-04 21:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 4075 updates\n",
            "2023-12-04 21:21:45 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1020.pt\n",
            "2023-12-04 21:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1020.pt\n",
            "2023-12-04 21:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1020.pt (epoch 1020 @ 4075 updates, score 13.2) (writing took 2.143662709000637 seconds)\n",
            "2023-12-04 21:21:48 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)\n",
            "2023-12-04 21:21:48 | INFO | train | epoch 1020 | loss 1.979 | nll_loss 0.438 | ppl 1.36 | wps 20126.6 | ups 0.23 | wpb 85903.8 | bsz 1548.2 | num_updates 4075 | lr 0.000313304 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4056\n",
            "2023-12-04 21:21:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1021:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:48 | INFO | fairseq.trainer | begin training epoch 1021\n",
            "2023-12-04 21:21:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:50 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)\n",
            "2023-12-04 21:21:50 | INFO | train | epoch 1021 | loss 1.98 | nll_loss 0.438 | ppl 1.35 | wps 139287 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4079 | lr 0.000313151 | gnorm 0.129 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4059\n",
            "2023-12-04 21:21:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1022:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:50 | INFO | fairseq.trainer | begin training epoch 1022\n",
            "2023-12-04 21:21:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:52 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)\n",
            "2023-12-04 21:21:52 | INFO | train | epoch 1022 | loss 1.98 | nll_loss 0.438 | ppl 1.35 | wps 143647 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4083 | lr 0.000312997 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4061\n",
            "2023-12-04 21:21:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1023:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:53 | INFO | fairseq.trainer | begin training epoch 1023\n",
            "2023-12-04 21:21:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:55 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)\n",
            "2023-12-04 21:21:55 | INFO | train | epoch 1023 | loss 1.979 | nll_loss 0.439 | ppl 1.36 | wps 143272 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4087 | lr 0.000312844 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4064\n",
            "2023-12-04 21:21:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1024:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:55 | INFO | fairseq.trainer | begin training epoch 1024\n",
            "2023-12-04 21:21:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:21:57 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)\n",
            "2023-12-04 21:21:57 | INFO | train | epoch 1024 | loss 1.976 | nll_loss 0.434 | ppl 1.35 | wps 143100 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4091 | lr 0.000312691 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4066\n",
            "2023-12-04 21:21:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1025:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:21:57 | INFO | fairseq.trainer | begin training epoch 1025\n",
            "2023-12-04 21:21:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:00 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)\n",
            "2023-12-04 21:22:00 | INFO | train | epoch 1025 | loss 1.978 | nll_loss 0.438 | ppl 1.35 | wps 142395 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4095 | lr 0.000312538 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4068\n",
            "2023-12-04 21:22:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1026:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:00 | INFO | fairseq.trainer | begin training epoch 1026\n",
            "2023-12-04 21:22:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:02 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)\n",
            "2023-12-04 21:22:02 | INFO | train | epoch 1026 | loss 1.979 | nll_loss 0.438 | ppl 1.35 | wps 139123 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4099 | lr 0.000312386 | gnorm 0.127 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4071\n",
            "2023-12-04 21:22:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1027:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:02 | INFO | fairseq.trainer | begin training epoch 1027\n",
            "2023-12-04 21:22:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:05 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)\n",
            "2023-12-04 21:22:05 | INFO | train | epoch 1027 | loss 1.976 | nll_loss 0.434 | ppl 1.35 | wps 142801 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4103 | lr 0.000312233 | gnorm 0.126 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4073\n",
            "2023-12-04 21:22:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1028:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:05 | INFO | fairseq.trainer | begin training epoch 1028\n",
            "2023-12-04 21:22:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:07 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)\n",
            "2023-12-04 21:22:07 | INFO | train | epoch 1028 | loss 1.977 | nll_loss 0.44 | ppl 1.36 | wps 141844 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4107 | lr 0.000312081 | gnorm 0.128 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4076\n",
            "2023-12-04 21:22:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1029:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:07 | INFO | fairseq.trainer | begin training epoch 1029\n",
            "2023-12-04 21:22:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:09 | INFO | fairseq_cli.train | end of epoch 1029 (average epoch stats below)\n",
            "2023-12-04 21:22:09 | INFO | train | epoch 1029 | loss 1.978 | nll_loss 0.434 | ppl 1.35 | wps 143129 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4111 | lr 0.000311929 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4078\n",
            "2023-12-04 21:22:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1030:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:09 | INFO | fairseq.trainer | begin training epoch 1030\n",
            "2023-12-04 21:22:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1030:  75% 3/4 [00:01<00:00,  1.65it/s]2023-12-04 21:22:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:22:13 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:22:13 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:22:15 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse vegnî condiçioin da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:22:15 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.51s/it]\u001b[A2023-12-04 21:22:16 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é dito òffiti an fornio à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:22:16 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:22:18 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:22:18 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.69s/it]\u001b[A2023-12-04 21:22:20 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ancon in azzonta ò inte un Internet caft ò con Wi-Fi pubrico.\n",
            "2023-12-04 21:22:20 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:22:22 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) che s’attreuva inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:22:22 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:22:24 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da poula de l'informaçion, con unn'ediçion cartacea, un scito web o peu attâ di attirati de 5.00.00 vixitatoî unichi into mese d'ottobre, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou un mondo etlante, ciammou Ducedweb.\n",
            "2023-12-04 21:22:24 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1030 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:22:24 | INFO | valid | epoch 1030 | valid on 'valid' subset | loss 6.451 | nll_loss 5.291 | ppl 39.14 | bleu 13.18 | wps 4242.3 | wpb 7753.9 | bsz 142.4 | num_updates 4115 | best_bleu 13.31\n",
            "2023-12-04 21:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1030 @ 4115 updates\n",
            "2023-12-04 21:22:24 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1030.pt\n",
            "2023-12-04 21:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1030.pt\n",
            "2023-12-04 21:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1030.pt (epoch 1030 @ 4115 updates, score 13.18) (writing took 2.151820019999832 seconds)\n",
            "2023-12-04 21:22:26 | INFO | fairseq_cli.train | end of epoch 1030 (average epoch stats below)\n",
            "2023-12-04 21:22:26 | INFO | train | epoch 1030 | loss 1.977 | nll_loss 0.436 | ppl 1.35 | wps 20724.3 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4115 | lr 0.000311778 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4095\n",
            "2023-12-04 21:22:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1031:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:26 | INFO | fairseq.trainer | begin training epoch 1031\n",
            "2023-12-04 21:22:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:28 | INFO | fairseq_cli.train | end of epoch 1031 (average epoch stats below)\n",
            "2023-12-04 21:22:28 | INFO | train | epoch 1031 | loss 1.975 | nll_loss 0.434 | ppl 1.35 | wps 136134 | ups 1.58 | wpb 85903.8 | bsz 1548.2 | num_updates 4119 | lr 0.000311626 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4097\n",
            "2023-12-04 21:22:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1032:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:29 | INFO | fairseq.trainer | begin training epoch 1032\n",
            "2023-12-04 21:22:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:31 | INFO | fairseq_cli.train | end of epoch 1032 (average epoch stats below)\n",
            "2023-12-04 21:22:31 | INFO | train | epoch 1032 | loss 1.975 | nll_loss 0.433 | ppl 1.35 | wps 140676 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4123 | lr 0.000311475 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4100\n",
            "2023-12-04 21:22:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1033:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:31 | INFO | fairseq.trainer | begin training epoch 1033\n",
            "2023-12-04 21:22:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:33 | INFO | fairseq_cli.train | end of epoch 1033 (average epoch stats below)\n",
            "2023-12-04 21:22:33 | INFO | train | epoch 1033 | loss 1.974 | nll_loss 0.434 | ppl 1.35 | wps 145749 | ups 1.7 | wpb 85903.8 | bsz 1548.2 | num_updates 4127 | lr 0.000311324 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4102\n",
            "2023-12-04 21:22:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1034:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:33 | INFO | fairseq.trainer | begin training epoch 1034\n",
            "2023-12-04 21:22:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:36 | INFO | fairseq_cli.train | end of epoch 1034 (average epoch stats below)\n",
            "2023-12-04 21:22:36 | INFO | train | epoch 1034 | loss 1.974 | nll_loss 0.433 | ppl 1.35 | wps 141515 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4131 | lr 0.000311173 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4104\n",
            "2023-12-04 21:22:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1035:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:36 | INFO | fairseq.trainer | begin training epoch 1035\n",
            "2023-12-04 21:22:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:38 | INFO | fairseq_cli.train | end of epoch 1035 (average epoch stats below)\n",
            "2023-12-04 21:22:38 | INFO | train | epoch 1035 | loss 1.975 | nll_loss 0.434 | ppl 1.35 | wps 141675 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4135 | lr 0.000311023 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4107\n",
            "2023-12-04 21:22:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1036:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:38 | INFO | fairseq.trainer | begin training epoch 1036\n",
            "2023-12-04 21:22:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:41 | INFO | fairseq_cli.train | end of epoch 1036 (average epoch stats below)\n",
            "2023-12-04 21:22:41 | INFO | train | epoch 1036 | loss 1.974 | nll_loss 0.433 | ppl 1.35 | wps 137613 | ups 1.6 | wpb 85903.8 | bsz 1548.2 | num_updates 4139 | lr 0.000310872 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4109\n",
            "2023-12-04 21:22:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1037:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:41 | INFO | fairseq.trainer | begin training epoch 1037\n",
            "2023-12-04 21:22:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:43 | INFO | fairseq_cli.train | end of epoch 1037 (average epoch stats below)\n",
            "2023-12-04 21:22:43 | INFO | train | epoch 1037 | loss 1.974 | nll_loss 0.433 | ppl 1.35 | wps 142363 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4143 | lr 0.000310722 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4112\n",
            "2023-12-04 21:22:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1038:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:43 | INFO | fairseq.trainer | begin training epoch 1038\n",
            "2023-12-04 21:22:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:45 | INFO | fairseq_cli.train | end of epoch 1038 (average epoch stats below)\n",
            "2023-12-04 21:22:45 | INFO | train | epoch 1038 | loss 1.974 | nll_loss 0.435 | ppl 1.35 | wps 143484 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4147 | lr 0.000310572 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4114\n",
            "2023-12-04 21:22:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1039:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:45 | INFO | fairseq.trainer | begin training epoch 1039\n",
            "2023-12-04 21:22:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:22:48 | INFO | fairseq_cli.train | end of epoch 1039 (average epoch stats below)\n",
            "2023-12-04 21:22:48 | INFO | train | epoch 1039 | loss 1.974 | nll_loss 0.432 | ppl 1.35 | wps 143521 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4151 | lr 0.000310423 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.7 | wall 4117\n",
            "2023-12-04 21:22:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1040:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:22:48 | INFO | fairseq.trainer | begin training epoch 1040\n",
            "2023-12-04 21:22:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1040:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:22:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:22:52 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çircostanse.\n",
            "2023-12-04 21:22:52 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.47s/it]\u001b[A2023-12-04 21:22:53 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:22:53 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:22:55 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de mangiâ ch’an produto di òffiti à di microonde ò di atri mezi pe rescätâ o çibbo.\n",
            "2023-12-04 21:22:55 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:22:57 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à divampou un inçendio, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Nwang Namgyal.\n",
            "2023-12-04 21:22:57 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.68s/it]\u001b[A2023-12-04 21:22:59 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; o l’é trovou pe de ciù inte lonquente ò inte un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:22:59 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:23:00 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): de costi, 75.68 km (29173 quaddræ) che s’attreuvan in sce l’Asia sud-òvest, e 23764 (29173 quaddræ) in Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:23:00 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.74s/it]\u001b[A2023-12-04 21:23:02 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ di attirati de 5.000 vixitatoî de vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou un mondo etnou de Ombur B.\n",
            "2023-12-04 21:23:02 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1040 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.75s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:23:02 | INFO | valid | epoch 1040 | valid on 'valid' subset | loss 6.451 | nll_loss 5.289 | ppl 39.09 | bleu 13.17 | wps 4219.7 | wpb 7753.9 | bsz 142.4 | num_updates 4155 | best_bleu 13.31\n",
            "2023-12-04 21:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1040 @ 4155 updates\n",
            "2023-12-04 21:23:02 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1040.pt\n",
            "2023-12-04 21:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1040.pt\n",
            "2023-12-04 21:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1040.pt (epoch 1040 @ 4155 updates, score 13.17) (writing took 2.148414756999955 seconds)\n",
            "2023-12-04 21:23:04 | INFO | fairseq_cli.train | end of epoch 1040 (average epoch stats below)\n",
            "2023-12-04 21:23:04 | INFO | train | epoch 1040 | loss 1.974 | nll_loss 0.434 | ppl 1.35 | wps 20655.1 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4155 | lr 0.000310273 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4133\n",
            "2023-12-04 21:23:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1041:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:05 | INFO | fairseq.trainer | begin training epoch 1041\n",
            "2023-12-04 21:23:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:07 | INFO | fairseq_cli.train | end of epoch 1041 (average epoch stats below)\n",
            "2023-12-04 21:23:07 | INFO | train | epoch 1041 | loss 1.974 | nll_loss 0.433 | ppl 1.35 | wps 138594 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 4159 | lr 0.000310124 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4136\n",
            "2023-12-04 21:23:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1042:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:07 | INFO | fairseq.trainer | begin training epoch 1042\n",
            "2023-12-04 21:23:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:09 | INFO | fairseq_cli.train | end of epoch 1042 (average epoch stats below)\n",
            "2023-12-04 21:23:09 | INFO | train | epoch 1042 | loss 1.974 | nll_loss 0.433 | ppl 1.35 | wps 143021 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4163 | lr 0.000309975 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4138\n",
            "2023-12-04 21:23:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1043:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:09 | INFO | fairseq.trainer | begin training epoch 1043\n",
            "2023-12-04 21:23:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:12 | INFO | fairseq_cli.train | end of epoch 1043 (average epoch stats below)\n",
            "2023-12-04 21:23:12 | INFO | train | epoch 1043 | loss 1.975 | nll_loss 0.435 | ppl 1.35 | wps 142148 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4167 | lr 0.000309826 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4140\n",
            "2023-12-04 21:23:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1044:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:12 | INFO | fairseq.trainer | begin training epoch 1044\n",
            "2023-12-04 21:23:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:14 | INFO | fairseq_cli.train | end of epoch 1044 (average epoch stats below)\n",
            "2023-12-04 21:23:14 | INFO | train | epoch 1044 | loss 1.972 | nll_loss 0.431 | ppl 1.35 | wps 142698 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4171 | lr 0.000309678 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.2 | wall 4143\n",
            "2023-12-04 21:23:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1045:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:14 | INFO | fairseq.trainer | begin training epoch 1045\n",
            "2023-12-04 21:23:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:17 | INFO | fairseq_cli.train | end of epoch 1045 (average epoch stats below)\n",
            "2023-12-04 21:23:17 | INFO | train | epoch 1045 | loss 1.974 | nll_loss 0.434 | ppl 1.35 | wps 141921 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4175 | lr 0.000309529 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4145\n",
            "2023-12-04 21:23:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1046:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:17 | INFO | fairseq.trainer | begin training epoch 1046\n",
            "2023-12-04 21:23:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:19 | INFO | fairseq_cli.train | end of epoch 1046 (average epoch stats below)\n",
            "2023-12-04 21:23:19 | INFO | train | epoch 1046 | loss 1.971 | nll_loss 0.431 | ppl 1.35 | wps 141764 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4179 | lr 0.000309381 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4148\n",
            "2023-12-04 21:23:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1047:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:19 | INFO | fairseq.trainer | begin training epoch 1047\n",
            "2023-12-04 21:23:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:21 | INFO | fairseq_cli.train | end of epoch 1047 (average epoch stats below)\n",
            "2023-12-04 21:23:21 | INFO | train | epoch 1047 | loss 1.972 | nll_loss 0.432 | ppl 1.35 | wps 143325 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4183 | lr 0.000309233 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4150\n",
            "2023-12-04 21:23:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1048:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:21 | INFO | fairseq.trainer | begin training epoch 1048\n",
            "2023-12-04 21:23:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:24 | INFO | fairseq_cli.train | end of epoch 1048 (average epoch stats below)\n",
            "2023-12-04 21:23:24 | INFO | train | epoch 1048 | loss 1.972 | nll_loss 0.432 | ppl 1.35 | wps 144970 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 4187 | lr 0.000309085 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4152\n",
            "2023-12-04 21:23:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1049:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:24 | INFO | fairseq.trainer | begin training epoch 1049\n",
            "2023-12-04 21:23:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:26 | INFO | fairseq_cli.train | end of epoch 1049 (average epoch stats below)\n",
            "2023-12-04 21:23:26 | INFO | train | epoch 1049 | loss 1.971 | nll_loss 0.431 | ppl 1.35 | wps 145081 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 4191 | lr 0.000308938 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4155\n",
            "2023-12-04 21:23:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1050:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:26 | INFO | fairseq.trainer | begin training epoch 1050\n",
            "2023-12-04 21:23:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1050:  75% 3/4 [00:01<00:00,  1.69it/s]2023-12-04 21:23:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:23:30 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çircostanse.\n",
            "2023-12-04 21:23:30 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A2023-12-04 21:23:32 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:23:32 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:23:33 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de gibinti.\n",
            "2023-12-04 21:23:33 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.57s/it]\u001b[A2023-12-04 21:23:35 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:23:35 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.68s/it]\u001b[A2023-12-04 21:23:37 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; o l’à trovou ancon inte un Internet ò «Internet» con Wi-Fi pubrico.\n",
            "2023-12-04 21:23:37 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.84s/it]\u001b[A2023-12-04 21:23:39 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) che s’attreuva inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:23:39 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.73s/it]\u001b[A2023-12-04 21:23:40 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo de impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.000 vixitatoî de vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh24 ch'o ponte un mondo etlante, ciammou Ducea o nomme de Ombur B.\n",
            "2023-12-04 21:23:40 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1050 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.71s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:23:40 | INFO | valid | epoch 1050 | valid on 'valid' subset | loss 6.453 | nll_loss 5.293 | ppl 39.22 | bleu 13.14 | wps 4276.1 | wpb 7753.9 | bsz 142.4 | num_updates 4195 | best_bleu 13.31\n",
            "2023-12-04 21:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1050 @ 4195 updates\n",
            "2023-12-04 21:23:40 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1050.pt\n",
            "2023-12-04 21:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1050.pt\n",
            "2023-12-04 21:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1050.pt (epoch 1050 @ 4195 updates, score 13.14) (writing took 2.152171761000318 seconds)\n",
            "2023-12-04 21:23:43 | INFO | fairseq_cli.train | end of epoch 1050 (average epoch stats below)\n",
            "2023-12-04 21:23:43 | INFO | train | epoch 1050 | loss 1.971 | nll_loss 0.43 | ppl 1.35 | wps 20849.6 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4195 | lr 0.000308791 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4171\n",
            "2023-12-04 21:23:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1051:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:43 | INFO | fairseq.trainer | begin training epoch 1051\n",
            "2023-12-04 21:23:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:45 | INFO | fairseq_cli.train | end of epoch 1051 (average epoch stats below)\n",
            "2023-12-04 21:23:45 | INFO | train | epoch 1051 | loss 1.969 | nll_loss 0.43 | ppl 1.35 | wps 139666 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4199 | lr 0.000308643 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4174\n",
            "2023-12-04 21:23:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1052:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:45 | INFO | fairseq.trainer | begin training epoch 1052\n",
            "2023-12-04 21:23:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:48 | INFO | fairseq_cli.train | end of epoch 1052 (average epoch stats below)\n",
            "2023-12-04 21:23:48 | INFO | train | epoch 1052 | loss 1.971 | nll_loss 0.43 | ppl 1.35 | wps 139873 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4203 | lr 0.000308497 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4176\n",
            "2023-12-04 21:23:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1053:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:48 | INFO | fairseq.trainer | begin training epoch 1053\n",
            "2023-12-04 21:23:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:50 | INFO | fairseq_cli.train | end of epoch 1053 (average epoch stats below)\n",
            "2023-12-04 21:23:50 | INFO | train | epoch 1053 | loss 1.97 | nll_loss 0.43 | ppl 1.35 | wps 142967 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4207 | lr 0.00030835 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4179\n",
            "2023-12-04 21:23:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1054:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:50 | INFO | fairseq.trainer | begin training epoch 1054\n",
            "2023-12-04 21:23:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:52 | INFO | fairseq_cli.train | end of epoch 1054 (average epoch stats below)\n",
            "2023-12-04 21:23:52 | INFO | train | epoch 1054 | loss 1.97 | nll_loss 0.43 | ppl 1.35 | wps 143000 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4211 | lr 0.000308203 | gnorm 0.118 | loss_scale 8 | train_wall 2 | gb_free 33.6 | wall 4181\n",
            "2023-12-04 21:23:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1055:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:52 | INFO | fairseq.trainer | begin training epoch 1055\n",
            "2023-12-04 21:23:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:55 | INFO | fairseq_cli.train | end of epoch 1055 (average epoch stats below)\n",
            "2023-12-04 21:23:55 | INFO | train | epoch 1055 | loss 1.969 | nll_loss 0.426 | ppl 1.34 | wps 140564 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4215 | lr 0.000308057 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4184\n",
            "2023-12-04 21:23:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1056:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:55 | INFO | fairseq.trainer | begin training epoch 1056\n",
            "2023-12-04 21:23:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:23:57 | INFO | fairseq_cli.train | end of epoch 1056 (average epoch stats below)\n",
            "2023-12-04 21:23:57 | INFO | train | epoch 1056 | loss 1.969 | nll_loss 0.43 | ppl 1.35 | wps 141386 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4219 | lr 0.000307911 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.4 | wall 4186\n",
            "2023-12-04 21:23:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1057:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:23:57 | INFO | fairseq.trainer | begin training epoch 1057\n",
            "2023-12-04 21:23:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:00 | INFO | fairseq_cli.train | end of epoch 1057 (average epoch stats below)\n",
            "2023-12-04 21:24:00 | INFO | train | epoch 1057 | loss 1.968 | nll_loss 0.427 | ppl 1.34 | wps 140573 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4223 | lr 0.000307765 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4188\n",
            "2023-12-04 21:24:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1058:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:00 | INFO | fairseq.trainer | begin training epoch 1058\n",
            "2023-12-04 21:24:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:02 | INFO | fairseq_cli.train | end of epoch 1058 (average epoch stats below)\n",
            "2023-12-04 21:24:02 | INFO | train | epoch 1058 | loss 1.969 | nll_loss 0.429 | ppl 1.35 | wps 143260 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4227 | lr 0.00030762 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4191\n",
            "2023-12-04 21:24:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1059:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:02 | INFO | fairseq.trainer | begin training epoch 1059\n",
            "2023-12-04 21:24:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:04 | INFO | fairseq_cli.train | end of epoch 1059 (average epoch stats below)\n",
            "2023-12-04 21:24:04 | INFO | train | epoch 1059 | loss 1.967 | nll_loss 0.425 | ppl 1.34 | wps 143993 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 4231 | lr 0.000307474 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4193\n",
            "2023-12-04 21:24:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1060:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:05 | INFO | fairseq.trainer | begin training epoch 1060\n",
            "2023-12-04 21:24:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1060:  75% 3/4 [00:01<00:00,  1.67it/s]2023-12-04 21:24:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:24:08 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:24:08 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:24:10 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settemañe de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:24:10 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  29% 2/7 [00:03<00:08,  1.70s/it]\u001b[A2023-12-04 21:24:12 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de gibinti. Çerti figgi an fornio à di microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:24:12 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.68s/it]\u001b[A2023-12-04 21:24:14 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l’à dito unna perçendia, donde l’é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l’imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:24:14 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.75s/it]\u001b[A2023-12-04 21:24:16 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caxo sozzorniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’à trovou ancon inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:24:16 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.90s/it]\u001b[A2023-12-04 21:24:17 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (300.948 miggia quaddræ): in sce sti 75.68 km (2917373 quaddræ) ch’a s’é collocâ inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:24:17 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.77s/it]\u001b[A2023-12-04 21:24:19 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ di attirati de 5.000 vixitatoî de vixitatoî unichi into mese d'ötovie, inserçioin personali, un network de noçieh24, ch'o ponte un mondo etlante, ciammou Ducedweb.\n",
            "2023-12-04 21:24:19 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1060 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.79s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:24:19 | INFO | valid | epoch 1060 | valid on 'valid' subset | loss 6.448 | nll_loss 5.287 | ppl 39.05 | bleu 13.28 | wps 4059.8 | wpb 7753.9 | bsz 142.4 | num_updates 4235 | best_bleu 13.31\n",
            "2023-12-04 21:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1060 @ 4235 updates\n",
            "2023-12-04 21:24:19 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1060.pt\n",
            "2023-12-04 21:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1060.pt\n",
            "2023-12-04 21:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1060.pt (epoch 1060 @ 4235 updates, score 13.28) (writing took 2.136273132000497 seconds)\n",
            "2023-12-04 21:24:21 | INFO | fairseq_cli.train | end of epoch 1060 (average epoch stats below)\n",
            "2023-12-04 21:24:21 | INFO | train | epoch 1060 | loss 1.969 | nll_loss 0.43 | ppl 1.35 | wps 20214.9 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4235 | lr 0.000307329 | gnorm 0.124 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4210\n",
            "2023-12-04 21:24:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1061:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:22 | INFO | fairseq.trainer | begin training epoch 1061\n",
            "2023-12-04 21:24:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:24 | INFO | fairseq_cli.train | end of epoch 1061 (average epoch stats below)\n",
            "2023-12-04 21:24:24 | INFO | train | epoch 1061 | loss 1.967 | nll_loss 0.426 | ppl 1.34 | wps 141855 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4239 | lr 0.000307184 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4213\n",
            "2023-12-04 21:24:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1062:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:24 | INFO | fairseq.trainer | begin training epoch 1062\n",
            "2023-12-04 21:24:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:26 | INFO | fairseq_cli.train | end of epoch 1062 (average epoch stats below)\n",
            "2023-12-04 21:24:26 | INFO | train | epoch 1062 | loss 1.967 | nll_loss 0.428 | ppl 1.35 | wps 141005 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4243 | lr 0.000307039 | gnorm 0.121 | loss_scale 8 | train_wall 2 | gb_free 33.5 | wall 4215\n",
            "2023-12-04 21:24:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1063:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:26 | INFO | fairseq.trainer | begin training epoch 1063\n",
            "2023-12-04 21:24:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:29 | INFO | fairseq_cli.train | end of epoch 1063 (average epoch stats below)\n",
            "2023-12-04 21:24:29 | INFO | train | epoch 1063 | loss 1.967 | nll_loss 0.428 | ppl 1.35 | wps 142202 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4247 | lr 0.000306894 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4217\n",
            "2023-12-04 21:24:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1064:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:29 | INFO | fairseq.trainer | begin training epoch 1064\n",
            "2023-12-04 21:24:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:31 | INFO | fairseq_cli.train | end of epoch 1064 (average epoch stats below)\n",
            "2023-12-04 21:24:31 | INFO | train | epoch 1064 | loss 1.967 | nll_loss 0.427 | ppl 1.34 | wps 140177 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4251 | lr 0.00030675 | gnorm 0.119 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4220\n",
            "2023-12-04 21:24:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1065:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:31 | INFO | fairseq.trainer | begin training epoch 1065\n",
            "2023-12-04 21:24:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:34 | INFO | fairseq_cli.train | end of epoch 1065 (average epoch stats below)\n",
            "2023-12-04 21:24:34 | INFO | train | epoch 1065 | loss 1.967 | nll_loss 0.427 | ppl 1.34 | wps 140702 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4255 | lr 0.000306606 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4222\n",
            "2023-12-04 21:24:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1066:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:34 | INFO | fairseq.trainer | begin training epoch 1066\n",
            "2023-12-04 21:24:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:36 | INFO | fairseq_cli.train | end of epoch 1066 (average epoch stats below)\n",
            "2023-12-04 21:24:36 | INFO | train | epoch 1066 | loss 1.967 | nll_loss 0.428 | ppl 1.35 | wps 143281 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4259 | lr 0.000306462 | gnorm 0.125 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4225\n",
            "2023-12-04 21:24:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1067:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:36 | INFO | fairseq.trainer | begin training epoch 1067\n",
            "2023-12-04 21:24:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:38 | INFO | fairseq_cli.train | end of epoch 1067 (average epoch stats below)\n",
            "2023-12-04 21:24:38 | INFO | train | epoch 1067 | loss 1.968 | nll_loss 0.428 | ppl 1.35 | wps 143648 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4263 | lr 0.000306318 | gnorm 0.123 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4227\n",
            "2023-12-04 21:24:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1068:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:38 | INFO | fairseq.trainer | begin training epoch 1068\n",
            "2023-12-04 21:24:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:41 | INFO | fairseq_cli.train | end of epoch 1068 (average epoch stats below)\n",
            "2023-12-04 21:24:41 | INFO | train | epoch 1068 | loss 1.968 | nll_loss 0.43 | ppl 1.35 | wps 142341 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4267 | lr 0.000306174 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4230\n",
            "2023-12-04 21:24:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1069:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:41 | INFO | fairseq.trainer | begin training epoch 1069\n",
            "2023-12-04 21:24:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:24:43 | INFO | fairseq_cli.train | end of epoch 1069 (average epoch stats below)\n",
            "2023-12-04 21:24:43 | INFO | train | epoch 1069 | loss 1.967 | nll_loss 0.427 | ppl 1.34 | wps 142371 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4271 | lr 0.000306031 | gnorm 0.12 | loss_scale 8 | train_wall 2 | gb_free 33.3 | wall 4232\n",
            "2023-12-04 21:24:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1070:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:24:43 | INFO | fairseq.trainer | begin training epoch 1070\n",
            "2023-12-04 21:24:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1070:  75% 3/4 [00:01<00:00,  1.66it/s]2023-12-04 21:24:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:24:47 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:24:47 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.46s/it]\u001b[A2023-12-04 21:24:49 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settemañe de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:24:49 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:24:50 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de mangiâ che gh’é ditoin òffiti an fornio à di microonde ò di atri mezi pe rescâ o mangiâ.\n",
            "2023-12-04 21:24:50 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:24:52 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:24:52 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:24:54 | INFO | fairseq.tasks.translation | example hypothesis: L'é bon che o vòstro hotel o vòstro òspite (in caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l'agge o Wi-Fi ò un PC connesso à l'Internet; o rescideiva inte un Internet ò «Internet» con Wi-Fi pubrico.\n",
            "2023-12-04 21:24:54 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.87s/it]\u001b[A2023-12-04 21:24:56 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:24:56 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.77s/it]\u001b[A2023-12-04 21:24:58 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.000 vixitatoî unichi into meise de l'ottobre, inserçioin personali, un network de noçieh24 ch'o l'é stæto lasciou un mondo etlante, ciammou Ducedweb.\n",
            "2023-12-04 21:24:58 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1070 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.73s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:24:58 | INFO | valid | epoch 1070 | valid on 'valid' subset | loss 6.447 | nll_loss 5.287 | ppl 39.03 | bleu 13.24 | wps 4209.1 | wpb 7753.9 | bsz 142.4 | num_updates 4275 | best_bleu 13.31\n",
            "2023-12-04 21:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1070 @ 4275 updates\n",
            "2023-12-04 21:24:58 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1070.pt\n",
            "2023-12-04 21:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1070.pt\n",
            "2023-12-04 21:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1070.pt (epoch 1070 @ 4275 updates, score 13.24) (writing took 2.141920417999245 seconds)\n",
            "2023-12-04 21:25:00 | INFO | fairseq_cli.train | end of epoch 1070 (average epoch stats below)\n",
            "2023-12-04 21:25:00 | INFO | train | epoch 1070 | loss 1.966 | nll_loss 0.426 | ppl 1.34 | wps 20646.8 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4275 | lr 0.000305888 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4249\n",
            "2023-12-04 21:25:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1071:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:00 | INFO | fairseq.trainer | begin training epoch 1071\n",
            "2023-12-04 21:25:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:02 | INFO | fairseq_cli.train | end of epoch 1071 (average epoch stats below)\n",
            "2023-12-04 21:25:02 | INFO | train | epoch 1071 | loss 1.965 | nll_loss 0.427 | ppl 1.34 | wps 141298 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4279 | lr 0.000305745 | gnorm 0.122 | loss_scale 8 | train_wall 2 | gb_free 33.1 | wall 4251\n",
            "2023-12-04 21:25:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1072:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:02 | INFO | fairseq.trainer | begin training epoch 1072\n",
            "2023-12-04 21:25:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:05 | INFO | fairseq_cli.train | end of epoch 1072 (average epoch stats below)\n",
            "2023-12-04 21:25:05 | INFO | train | epoch 1072 | loss 1.965 | nll_loss 0.425 | ppl 1.34 | wps 139851 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4283 | lr 0.000305602 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4253\n",
            "2023-12-04 21:25:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1073:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:05 | INFO | fairseq.trainer | begin training epoch 1073\n",
            "2023-12-04 21:25:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:07 | INFO | fairseq_cli.train | end of epoch 1073 (average epoch stats below)\n",
            "2023-12-04 21:25:07 | INFO | train | epoch 1073 | loss 1.965 | nll_loss 0.426 | ppl 1.34 | wps 142061 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4287 | lr 0.000305459 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.2 | wall 4256\n",
            "2023-12-04 21:25:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1074:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:07 | INFO | fairseq.trainer | begin training epoch 1074\n",
            "2023-12-04 21:25:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:10 | INFO | fairseq_cli.train | end of epoch 1074 (average epoch stats below)\n",
            "2023-12-04 21:25:10 | INFO | train | epoch 1074 | loss 1.966 | nll_loss 0.428 | ppl 1.35 | wps 143037 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4291 | lr 0.000305317 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.6 | wall 4258\n",
            "2023-12-04 21:25:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1075:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:10 | INFO | fairseq.trainer | begin training epoch 1075\n",
            "2023-12-04 21:25:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:12 | INFO | fairseq_cli.train | end of epoch 1075 (average epoch stats below)\n",
            "2023-12-04 21:25:12 | INFO | train | epoch 1075 | loss 1.963 | nll_loss 0.423 | ppl 1.34 | wps 140676 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4295 | lr 0.000305175 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4261\n",
            "2023-12-04 21:25:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1076:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:12 | INFO | fairseq.trainer | begin training epoch 1076\n",
            "2023-12-04 21:25:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:14 | INFO | fairseq_cli.train | end of epoch 1076 (average epoch stats below)\n",
            "2023-12-04 21:25:14 | INFO | train | epoch 1076 | loss 1.964 | nll_loss 0.425 | ppl 1.34 | wps 141109 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4299 | lr 0.000305033 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4263\n",
            "2023-12-04 21:25:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1077:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:15 | INFO | fairseq.trainer | begin training epoch 1077\n",
            "2023-12-04 21:25:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:17 | INFO | fairseq_cli.train | end of epoch 1077 (average epoch stats below)\n",
            "2023-12-04 21:25:17 | INFO | train | epoch 1077 | loss 1.963 | nll_loss 0.424 | ppl 1.34 | wps 139408 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4303 | lr 0.000304891 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4266\n",
            "2023-12-04 21:25:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1078:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:17 | INFO | fairseq.trainer | begin training epoch 1078\n",
            "2023-12-04 21:25:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:19 | INFO | fairseq_cli.train | end of epoch 1078 (average epoch stats below)\n",
            "2023-12-04 21:25:19 | INFO | train | epoch 1078 | loss 1.965 | nll_loss 0.428 | ppl 1.35 | wps 143354 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4307 | lr 0.000304749 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.8 | wall 4268\n",
            "2023-12-04 21:25:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1079:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:19 | INFO | fairseq.trainer | begin training epoch 1079\n",
            "2023-12-04 21:25:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:22 | INFO | fairseq_cli.train | end of epoch 1079 (average epoch stats below)\n",
            "2023-12-04 21:25:22 | INFO | train | epoch 1079 | loss 1.965 | nll_loss 0.425 | ppl 1.34 | wps 142334 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4311 | lr 0.000304608 | gnorm 0.124 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4270\n",
            "2023-12-04 21:25:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1080:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:22 | INFO | fairseq.trainer | begin training epoch 1080\n",
            "2023-12-04 21:25:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1080:  75% 3/4 [00:01<00:00,  1.62it/s]2023-12-04 21:25:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:25:26 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çircostanse.\n",
            "2023-12-04 21:25:26 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:25:27 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:25:27 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:25:29 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de gibinti.\n",
            "2023-12-04 21:25:29 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:25:31 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte reliquie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:25:31 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:25:33 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; pe de ciù intenet ò inte l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:25:33 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.91s/it]\u001b[A2023-12-04 21:25:35 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): de costi, 75.68 km (2917373 quaddræ) ch’a s’é unna collocâ inte l’Asia sud-occidentale, e 23764 km (174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:25:35 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.77s/it]\u001b[A2023-12-04 21:25:36 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de l'öto d'ottobre, inserçioin personali, un network de noçieh 24,4 ch'o l'é stæto lasciou un mondo etlante, ciammou Ducedwor B.\n",
            "2023-12-04 21:25:36 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1080 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.75s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:25:36 | INFO | valid | epoch 1080 | valid on 'valid' subset | loss 6.453 | nll_loss 5.292 | ppl 39.19 | bleu 13.21 | wps 4179.6 | wpb 7753.9 | bsz 142.4 | num_updates 4315 | best_bleu 13.31\n",
            "2023-12-04 21:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1080 @ 4315 updates\n",
            "2023-12-04 21:25:36 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1080.pt\n",
            "2023-12-04 21:25:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1080.pt\n",
            "2023-12-04 21:25:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1080.pt (epoch 1080 @ 4315 updates, score 13.21) (writing took 2.128218959000151 seconds)\n",
            "2023-12-04 21:25:38 | INFO | fairseq_cli.train | end of epoch 1080 (average epoch stats below)\n",
            "2023-12-04 21:25:38 | INFO | train | epoch 1080 | loss 1.966 | nll_loss 0.426 | ppl 1.34 | wps 20563.4 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4315 | lr 0.000304467 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4287\n",
            "2023-12-04 21:25:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1081:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:39 | INFO | fairseq.trainer | begin training epoch 1081\n",
            "2023-12-04 21:25:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:41 | INFO | fairseq_cli.train | end of epoch 1081 (average epoch stats below)\n",
            "2023-12-04 21:25:41 | INFO | train | epoch 1081 | loss 1.963 | nll_loss 0.426 | ppl 1.34 | wps 139920 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4319 | lr 0.000304326 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4290\n",
            "2023-12-04 21:25:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1082:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:41 | INFO | fairseq.trainer | begin training epoch 1082\n",
            "2023-12-04 21:25:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:43 | INFO | fairseq_cli.train | end of epoch 1082 (average epoch stats below)\n",
            "2023-12-04 21:25:43 | INFO | train | epoch 1082 | loss 1.963 | nll_loss 0.424 | ppl 1.34 | wps 142680 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4323 | lr 0.000304185 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.6 | wall 4292\n",
            "2023-12-04 21:25:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1083:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:43 | INFO | fairseq.trainer | begin training epoch 1083\n",
            "2023-12-04 21:25:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:46 | INFO | fairseq_cli.train | end of epoch 1083 (average epoch stats below)\n",
            "2023-12-04 21:25:46 | INFO | train | epoch 1083 | loss 1.962 | nll_loss 0.423 | ppl 1.34 | wps 142163 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4327 | lr 0.000304044 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4294\n",
            "2023-12-04 21:25:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1084:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:46 | INFO | fairseq.trainer | begin training epoch 1084\n",
            "2023-12-04 21:25:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:48 | INFO | fairseq_cli.train | end of epoch 1084 (average epoch stats below)\n",
            "2023-12-04 21:25:48 | INFO | train | epoch 1084 | loss 1.963 | nll_loss 0.425 | ppl 1.34 | wps 141396 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4331 | lr 0.000303904 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4297\n",
            "2023-12-04 21:25:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1085:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:48 | INFO | fairseq.trainer | begin training epoch 1085\n",
            "2023-12-04 21:25:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:51 | INFO | fairseq_cli.train | end of epoch 1085 (average epoch stats below)\n",
            "2023-12-04 21:25:51 | INFO | train | epoch 1085 | loss 1.962 | nll_loss 0.423 | ppl 1.34 | wps 140887 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4335 | lr 0.000303763 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4299\n",
            "2023-12-04 21:25:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1086:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:51 | INFO | fairseq.trainer | begin training epoch 1086\n",
            "2023-12-04 21:25:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:53 | INFO | fairseq_cli.train | end of epoch 1086 (average epoch stats below)\n",
            "2023-12-04 21:25:53 | INFO | train | epoch 1086 | loss 1.96 | nll_loss 0.421 | ppl 1.34 | wps 141782 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4339 | lr 0.000303623 | gnorm 0.117 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4302\n",
            "2023-12-04 21:25:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1087:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:53 | INFO | fairseq.trainer | begin training epoch 1087\n",
            "2023-12-04 21:25:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:56 | INFO | fairseq_cli.train | end of epoch 1087 (average epoch stats below)\n",
            "2023-12-04 21:25:56 | INFO | train | epoch 1087 | loss 1.962 | nll_loss 0.421 | ppl 1.34 | wps 136918 | ups 1.59 | wpb 85903.8 | bsz 1548.2 | num_updates 4343 | lr 0.000303483 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4304\n",
            "2023-12-04 21:25:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1088:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:56 | INFO | fairseq.trainer | begin training epoch 1088\n",
            "2023-12-04 21:25:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:25:58 | INFO | fairseq_cli.train | end of epoch 1088 (average epoch stats below)\n",
            "2023-12-04 21:25:58 | INFO | train | epoch 1088 | loss 1.961 | nll_loss 0.424 | ppl 1.34 | wps 140079 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4347 | lr 0.000303344 | gnorm 0.118 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4307\n",
            "2023-12-04 21:25:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1089:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:25:58 | INFO | fairseq.trainer | begin training epoch 1089\n",
            "2023-12-04 21:25:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:00 | INFO | fairseq_cli.train | end of epoch 1089 (average epoch stats below)\n",
            "2023-12-04 21:26:00 | INFO | train | epoch 1089 | loss 1.961 | nll_loss 0.422 | ppl 1.34 | wps 142401 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4351 | lr 0.000303204 | gnorm 0.118 | loss_scale 16 | train_wall 2 | gb_free 33.6 | wall 4309\n",
            "2023-12-04 21:26:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1090:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:00 | INFO | fairseq.trainer | begin training epoch 1090\n",
            "2023-12-04 21:26:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1090:  75% 3/4 [00:01<00:00,  1.62it/s]2023-12-04 21:26:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:26:04 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de circostanse.\n",
            "2023-12-04 21:26:04 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.48s/it]\u001b[A2023-12-04 21:26:06 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin semanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:26:06 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.52s/it]\u001b[A2023-12-04 21:26:08 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de mangiâ ch’an produto di figgi an fornio à di microonde ò di atri mezi pe rescädamento do çibbo.\n",
            "2023-12-04 21:26:08 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.61s/it]\u001b[A2023-12-04 21:26:09 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:26:09 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.72s/it]\u001b[A2023-12-04 21:26:12 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (inte caxo soviniate inte unna guærasthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à l’Internet; o l’é ancon in azzonta ò inte un Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:26:12 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.89s/it]\u001b[A2023-12-04 21:26:13 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) s’attreuva inte l’Asia sud-òvest, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:26:13 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:26:15 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da parodia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.00.00 vixitatoî unichi into meise de l'öto d'ottobre, inserçioin personali, un network de noçieh 24 ch'o l'é stæto lasciou à Duvante, Woldur de Ombur.\n",
            "2023-12-04 21:26:15 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1090 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.75s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:26:15 | INFO | valid | epoch 1090 | valid on 'valid' subset | loss 6.444 | nll_loss 5.284 | ppl 38.97 | bleu 13.19 | wps 4159.9 | wpb 7753.9 | bsz 142.4 | num_updates 4355 | best_bleu 13.31\n",
            "2023-12-04 21:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1090 @ 4355 updates\n",
            "2023-12-04 21:26:15 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1090.pt\n",
            "2023-12-04 21:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1090.pt\n",
            "2023-12-04 21:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1090.pt (epoch 1090 @ 4355 updates, score 13.19) (writing took 2.1272167669994815 seconds)\n",
            "2023-12-04 21:26:17 | INFO | fairseq_cli.train | end of epoch 1090 (average epoch stats below)\n",
            "2023-12-04 21:26:17 | INFO | train | epoch 1090 | loss 1.96 | nll_loss 0.421 | ppl 1.34 | wps 20472.1 | ups 0.24 | wpb 85903.8 | bsz 1548.2 | num_updates 4355 | lr 0.000303065 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4326\n",
            "2023-12-04 21:26:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1091:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:17 | INFO | fairseq.trainer | begin training epoch 1091\n",
            "2023-12-04 21:26:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:20 | INFO | fairseq_cli.train | end of epoch 1091 (average epoch stats below)\n",
            "2023-12-04 21:26:20 | INFO | train | epoch 1091 | loss 1.959 | nll_loss 0.421 | ppl 1.34 | wps 138056 | ups 1.61 | wpb 85903.8 | bsz 1548.2 | num_updates 4359 | lr 0.000302926 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4328\n",
            "2023-12-04 21:26:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1092:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:20 | INFO | fairseq.trainer | begin training epoch 1092\n",
            "2023-12-04 21:26:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:22 | INFO | fairseq_cli.train | end of epoch 1092 (average epoch stats below)\n",
            "2023-12-04 21:26:22 | INFO | train | epoch 1092 | loss 1.959 | nll_loss 0.419 | ppl 1.34 | wps 142417 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4363 | lr 0.000302787 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4331\n",
            "2023-12-04 21:26:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1093:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:22 | INFO | fairseq.trainer | begin training epoch 1093\n",
            "2023-12-04 21:26:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:25 | INFO | fairseq_cli.train | end of epoch 1093 (average epoch stats below)\n",
            "2023-12-04 21:26:25 | INFO | train | epoch 1093 | loss 1.961 | nll_loss 0.423 | ppl 1.34 | wps 139165 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4367 | lr 0.000302648 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4333\n",
            "2023-12-04 21:26:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1094:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:25 | INFO | fairseq.trainer | begin training epoch 1094\n",
            "2023-12-04 21:26:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:27 | INFO | fairseq_cli.train | end of epoch 1094 (average epoch stats below)\n",
            "2023-12-04 21:26:27 | INFO | train | epoch 1094 | loss 1.958 | nll_loss 0.42 | ppl 1.34 | wps 142754 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4371 | lr 0.00030251 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.7 | wall 4336\n",
            "2023-12-04 21:26:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1095:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:27 | INFO | fairseq.trainer | begin training epoch 1095\n",
            "2023-12-04 21:26:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:29 | INFO | fairseq_cli.train | end of epoch 1095 (average epoch stats below)\n",
            "2023-12-04 21:26:29 | INFO | train | epoch 1095 | loss 1.959 | nll_loss 0.42 | ppl 1.34 | wps 143247 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4375 | lr 0.000302372 | gnorm 0.124 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4338\n",
            "2023-12-04 21:26:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1096:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:29 | INFO | fairseq.trainer | begin training epoch 1096\n",
            "2023-12-04 21:26:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:32 | INFO | fairseq_cli.train | end of epoch 1096 (average epoch stats below)\n",
            "2023-12-04 21:26:32 | INFO | train | epoch 1096 | loss 1.959 | nll_loss 0.422 | ppl 1.34 | wps 140428 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4379 | lr 0.000302233 | gnorm 0.124 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4341\n",
            "2023-12-04 21:26:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1097:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:32 | INFO | fairseq.trainer | begin training epoch 1097\n",
            "2023-12-04 21:26:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:34 | INFO | fairseq_cli.train | end of epoch 1097 (average epoch stats below)\n",
            "2023-12-04 21:26:34 | INFO | train | epoch 1097 | loss 1.96 | nll_loss 0.421 | ppl 1.34 | wps 145024 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 4383 | lr 0.000302096 | gnorm 0.126 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4343\n",
            "2023-12-04 21:26:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1098:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:34 | INFO | fairseq.trainer | begin training epoch 1098\n",
            "2023-12-04 21:26:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:37 | INFO | fairseq_cli.train | end of epoch 1098 (average epoch stats below)\n",
            "2023-12-04 21:26:37 | INFO | train | epoch 1098 | loss 1.961 | nll_loss 0.424 | ppl 1.34 | wps 139434 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4387 | lr 0.000301958 | gnorm 0.124 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4345\n",
            "2023-12-04 21:26:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1099:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:37 | INFO | fairseq.trainer | begin training epoch 1099\n",
            "2023-12-04 21:26:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:39 | INFO | fairseq_cli.train | end of epoch 1099 (average epoch stats below)\n",
            "2023-12-04 21:26:39 | INFO | train | epoch 1099 | loss 1.96 | nll_loss 0.421 | ppl 1.34 | wps 140798 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4391 | lr 0.00030182 | gnorm 0.124 | loss_scale 16 | train_wall 2 | gb_free 33.6 | wall 4348\n",
            "2023-12-04 21:26:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1100:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:39 | INFO | fairseq.trainer | begin training epoch 1100\n",
            "2023-12-04 21:26:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1100:  75% 3/4 [00:01<00:00,  1.63it/s]2023-12-04 21:26:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:26:43 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarche çircostanse.\n",
            "2023-12-04 21:26:43 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.45s/it]\u001b[A2023-12-04 21:26:45 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e settemañe de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:26:45 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  29% 2/7 [00:03<00:07,  1.55s/it]\u001b[A2023-12-04 21:26:46 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ertati propoñan un reparto con unna çernia de mangiâ ch’an produto di òffiti à di microonde ò di atri mezi pe rescädamento do çibbo.\n",
            "2023-12-04 21:26:46 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.59s/it]\u001b[A2023-12-04 21:26:48 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:26:48 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.84s/it]\u001b[A2023-12-04 21:26:51 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sovitessarniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’à trovou ascì inte un Internet ò inte l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:26:51 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  71% 5/7 [00:09<00:03,  1.96s/it]\u001b[A2023-12-04 21:26:52 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): de sti, 75.68 km (291.73 quaddræ) ch’a s’é collocâ inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:26:52 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.83s/it]\u001b[A2023-12-04 21:26:54 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web o peu attiâ di attirati de 5.000 vixitatoî unichi into mese d'öto d'ottobre, inserçioin personali, un network de noçieh, 24 ch'o ponte un mondo etlante, ciammou Ducedweb.\n",
            "2023-12-04 21:26:54 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1100 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.77s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:26:54 | INFO | valid | epoch 1100 | valid on 'valid' subset | loss 6.453 | nll_loss 5.295 | ppl 39.25 | bleu 13.17 | wps 4065 | wpb 7753.9 | bsz 142.4 | num_updates 4395 | best_bleu 13.31\n",
            "2023-12-04 21:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1100 @ 4395 updates\n",
            "2023-12-04 21:26:54 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1100.pt\n",
            "2023-12-04 21:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1100.pt\n",
            "2023-12-04 21:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1100.pt (epoch 1100 @ 4395 updates, score 13.17) (writing took 2.1586933959997623 seconds)\n",
            "2023-12-04 21:26:56 | INFO | fairseq_cli.train | end of epoch 1100 (average epoch stats below)\n",
            "2023-12-04 21:26:56 | INFO | train | epoch 1100 | loss 1.96 | nll_loss 0.422 | ppl 1.34 | wps 20186.7 | ups 0.23 | wpb 85903.8 | bsz 1548.2 | num_updates 4395 | lr 0.000301683 | gnorm 0.13 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4365\n",
            "2023-12-04 21:26:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1101:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:56 | INFO | fairseq.trainer | begin training epoch 1101\n",
            "2023-12-04 21:26:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:26:59 | INFO | fairseq_cli.train | end of epoch 1101 (average epoch stats below)\n",
            "2023-12-04 21:26:59 | INFO | train | epoch 1101 | loss 1.957 | nll_loss 0.42 | ppl 1.34 | wps 139245 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4399 | lr 0.000301546 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4367\n",
            "2023-12-04 21:26:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1102:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:26:59 | INFO | fairseq.trainer | begin training epoch 1102\n",
            "2023-12-04 21:26:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:01 | INFO | fairseq_cli.train | end of epoch 1102 (average epoch stats below)\n",
            "2023-12-04 21:27:01 | INFO | train | epoch 1102 | loss 1.959 | nll_loss 0.42 | ppl 1.34 | wps 142596 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4403 | lr 0.000301409 | gnorm 0.118 | loss_scale 16 | train_wall 2 | gb_free 33.6 | wall 4370\n",
            "2023-12-04 21:27:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1103:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:01 | INFO | fairseq.trainer | begin training epoch 1103\n",
            "2023-12-04 21:27:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:03 | INFO | fairseq_cli.train | end of epoch 1103 (average epoch stats below)\n",
            "2023-12-04 21:27:03 | INFO | train | epoch 1103 | loss 1.957 | nll_loss 0.419 | ppl 1.34 | wps 144022 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 4407 | lr 0.000301272 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4372\n",
            "2023-12-04 21:27:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1104:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:03 | INFO | fairseq.trainer | begin training epoch 1104\n",
            "2023-12-04 21:27:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:06 | INFO | fairseq_cli.train | end of epoch 1104 (average epoch stats below)\n",
            "2023-12-04 21:27:06 | INFO | train | epoch 1104 | loss 1.957 | nll_loss 0.417 | ppl 1.34 | wps 145002 | ups 1.69 | wpb 85903.8 | bsz 1548.2 | num_updates 4411 | lr 0.000301135 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4374\n",
            "2023-12-04 21:27:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1105:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:06 | INFO | fairseq.trainer | begin training epoch 1105\n",
            "2023-12-04 21:27:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:08 | INFO | fairseq_cli.train | end of epoch 1105 (average epoch stats below)\n",
            "2023-12-04 21:27:08 | INFO | train | epoch 1105 | loss 1.958 | nll_loss 0.421 | ppl 1.34 | wps 141846 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4415 | lr 0.000300999 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4377\n",
            "2023-12-04 21:27:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1106:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:08 | INFO | fairseq.trainer | begin training epoch 1106\n",
            "2023-12-04 21:27:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:11 | INFO | fairseq_cli.train | end of epoch 1106 (average epoch stats below)\n",
            "2023-12-04 21:27:11 | INFO | train | epoch 1106 | loss 1.955 | nll_loss 0.417 | ppl 1.33 | wps 143409 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4419 | lr 0.000300862 | gnorm 0.117 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4379\n",
            "2023-12-04 21:27:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1107:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:11 | INFO | fairseq.trainer | begin training epoch 1107\n",
            "2023-12-04 21:27:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:13 | INFO | fairseq_cli.train | end of epoch 1107 (average epoch stats below)\n",
            "2023-12-04 21:27:13 | INFO | train | epoch 1107 | loss 1.956 | nll_loss 0.419 | ppl 1.34 | wps 142385 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4423 | lr 0.000300726 | gnorm 0.118 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4382\n",
            "2023-12-04 21:27:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1108:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:13 | INFO | fairseq.trainer | begin training epoch 1108\n",
            "2023-12-04 21:27:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:15 | INFO | fairseq_cli.train | end of epoch 1108 (average epoch stats below)\n",
            "2023-12-04 21:27:15 | INFO | train | epoch 1108 | loss 1.956 | nll_loss 0.417 | ppl 1.34 | wps 139986 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4427 | lr 0.00030059 | gnorm 0.118 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4384\n",
            "2023-12-04 21:27:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1109:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:16 | INFO | fairseq.trainer | begin training epoch 1109\n",
            "2023-12-04 21:27:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:18 | INFO | fairseq_cli.train | end of epoch 1109 (average epoch stats below)\n",
            "2023-12-04 21:27:18 | INFO | train | epoch 1109 | loss 1.958 | nll_loss 0.42 | ppl 1.34 | wps 139446 | ups 1.62 | wpb 85903.8 | bsz 1548.2 | num_updates 4431 | lr 0.000300455 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4387\n",
            "2023-12-04 21:27:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1110:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:18 | INFO | fairseq.trainer | begin training epoch 1110\n",
            "2023-12-04 21:27:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1110:  75% 3/4 [00:01<00:00,  1.64it/s]2023-12-04 21:27:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:27:22 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çirconstanse.\n",
            "2023-12-04 21:27:22 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.43s/it]\u001b[A2023-12-04 21:27:23 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin settemanæ de attivitæ fixica, no a deprescion e a miagia.\n",
            "2023-12-04 21:27:23 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:27:25 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ercæ propoñan un reparto con unna ciù grande çernia de mangiâ che gh’é ditoin òffiti an fornio à microonde ò di atri mezi pe rescâ o çibbo.\n",
            "2023-12-04 21:27:25 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:27:27 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Ngawang Namgyal.\n",
            "2023-12-04 21:27:27 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.73s/it]\u001b[A2023-12-04 21:27:29 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vostro òspite (isòspite soviniate inte unnaguesthouse ò inte unna casa privata) o l’agge o Wi-Fi ò un PC connesso à Internet; o l’é ascì trovou in sce l’Internet caft ò un pòsto in sce Wi-Fi pubrico.\n",
            "2023-12-04 21:27:29 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.90s/it]\u001b[A2023-12-04 21:27:31 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggiæa quaddræ): in sce sti 75.68 km (2917373 quaddræ) se rompliæ inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:27:31 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.78s/it]\u001b[A2023-12-04 21:27:32 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web pe attiâ attia de 5.000 de vixitatoî unichi into mesegno de l'ottobre, inserçioin personali, un network de noçieh24 ch'o ponte un mondo etlante, ciammou Ducellou Oldur de Ombur.\n",
            "2023-12-04 21:27:32 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1110 | valid on 'valid' subset: 100% 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:27:32 | INFO | valid | epoch 1110 | valid on 'valid' subset | loss 6.45 | nll_loss 5.293 | ppl 39.21 | bleu 13.42 | wps 4143 | wpb 7753.9 | bsz 142.4 | num_updates 4435 | best_bleu 13.42\n",
            "2023-12-04 21:27:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1110 @ 4435 updates\n",
            "2023-12-04 21:27:32 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1110.pt\n",
            "2023-12-04 21:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1110.pt\n",
            "2023-12-04 21:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1110.pt (epoch 1110 @ 4435 updates, score 13.42) (writing took 3.9621545439995316 seconds)\n",
            "2023-12-04 21:27:37 | INFO | fairseq_cli.train | end of epoch 1110 (average epoch stats below)\n",
            "2023-12-04 21:27:37 | INFO | train | epoch 1110 | loss 1.957 | nll_loss 0.421 | ppl 1.34 | wps 18482.9 | ups 0.22 | wpb 85903.8 | bsz 1548.2 | num_updates 4435 | lr 0.000300319 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4405\n",
            "2023-12-04 21:27:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1111:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:37 | INFO | fairseq.trainer | begin training epoch 1111\n",
            "2023-12-04 21:27:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:39 | INFO | fairseq_cli.train | end of epoch 1111 (average epoch stats below)\n",
            "2023-12-04 21:27:39 | INFO | train | epoch 1111 | loss 1.955 | nll_loss 0.418 | ppl 1.34 | wps 141504 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4439 | lr 0.000300184 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4408\n",
            "2023-12-04 21:27:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1112:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:39 | INFO | fairseq.trainer | begin training epoch 1112\n",
            "2023-12-04 21:27:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:41 | INFO | fairseq_cli.train | end of epoch 1112 (average epoch stats below)\n",
            "2023-12-04 21:27:41 | INFO | train | epoch 1112 | loss 1.955 | nll_loss 0.418 | ppl 1.34 | wps 142533 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4443 | lr 0.000300049 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4410\n",
            "2023-12-04 21:27:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1113:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:41 | INFO | fairseq.trainer | begin training epoch 1113\n",
            "2023-12-04 21:27:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:44 | INFO | fairseq_cli.train | end of epoch 1113 (average epoch stats below)\n",
            "2023-12-04 21:27:44 | INFO | train | epoch 1113 | loss 1.956 | nll_loss 0.418 | ppl 1.34 | wps 142782 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4447 | lr 0.000299914 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.8 | wall 4412\n",
            "2023-12-04 21:27:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1114:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:44 | INFO | fairseq.trainer | begin training epoch 1114\n",
            "2023-12-04 21:27:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:46 | INFO | fairseq_cli.train | end of epoch 1114 (average epoch stats below)\n",
            "2023-12-04 21:27:46 | INFO | train | epoch 1114 | loss 1.955 | nll_loss 0.419 | ppl 1.34 | wps 143212 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4451 | lr 0.000299779 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4415\n",
            "2023-12-04 21:27:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1115:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:46 | INFO | fairseq.trainer | begin training epoch 1115\n",
            "2023-12-04 21:27:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:49 | INFO | fairseq_cli.train | end of epoch 1115 (average epoch stats below)\n",
            "2023-12-04 21:27:49 | INFO | train | epoch 1115 | loss 1.954 | nll_loss 0.417 | ppl 1.33 | wps 141994 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4455 | lr 0.000299644 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4417\n",
            "2023-12-04 21:27:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1116:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:49 | INFO | fairseq.trainer | begin training epoch 1116\n",
            "2023-12-04 21:27:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:51 | INFO | fairseq_cli.train | end of epoch 1116 (average epoch stats below)\n",
            "2023-12-04 21:27:51 | INFO | train | epoch 1116 | loss 1.953 | nll_loss 0.414 | ppl 1.33 | wps 143148 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4459 | lr 0.00029951 | gnorm 0.125 | loss_scale 16 | train_wall 2 | gb_free 33.2 | wall 4420\n",
            "2023-12-04 21:27:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1117:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:51 | INFO | fairseq.trainer | begin training epoch 1117\n",
            "2023-12-04 21:27:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:53 | INFO | fairseq_cli.train | end of epoch 1117 (average epoch stats below)\n",
            "2023-12-04 21:27:53 | INFO | train | epoch 1117 | loss 1.955 | nll_loss 0.42 | ppl 1.34 | wps 141666 | ups 1.65 | wpb 85903.8 | bsz 1548.2 | num_updates 4463 | lr 0.000299376 | gnorm 0.127 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4422\n",
            "2023-12-04 21:27:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1118:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:53 | INFO | fairseq.trainer | begin training epoch 1118\n",
            "2023-12-04 21:27:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:56 | INFO | fairseq_cli.train | end of epoch 1118 (average epoch stats below)\n",
            "2023-12-04 21:27:56 | INFO | train | epoch 1118 | loss 1.955 | nll_loss 0.415 | ppl 1.33 | wps 140631 | ups 1.64 | wpb 85903.8 | bsz 1548.2 | num_updates 4467 | lr 0.000299242 | gnorm 0.125 | loss_scale 16 | train_wall 2 | gb_free 33.2 | wall 4425\n",
            "2023-12-04 21:27:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1119:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:56 | INFO | fairseq.trainer | begin training epoch 1119\n",
            "2023-12-04 21:27:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:27:58 | INFO | fairseq_cli.train | end of epoch 1119 (average epoch stats below)\n",
            "2023-12-04 21:27:58 | INFO | train | epoch 1119 | loss 1.955 | nll_loss 0.418 | ppl 1.34 | wps 140349 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4471 | lr 0.000299108 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4427\n",
            "2023-12-04 21:27:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1120:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:27:58 | INFO | fairseq.trainer | begin training epoch 1120\n",
            "2023-12-04 21:27:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 1120:  75% 3/4 [00:01<00:00,  1.68it/s]2023-12-04 21:28:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:   0% 0/7 [00:00<?, ?it/s]\u001b[A2023-12-04 21:28:02 | INFO | fairseq.tasks.translation | example hypothesis: Pe commun, à Chalotte, i taxi no vëgnan deuviæ da-e famigge, sciben che peuan revelâse inte quarcheduña de çircostanse.\n",
            "2023-12-04 21:28:02 | INFO | fairseq.tasks.translation | example reference: Pe commun i tascì no en guæi deuviæ da-e famigge à Charlotte, sciben che inte çerti caxi peuan vegnî ben.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  14% 1/7 [00:01<00:08,  1.44s/it]\u001b[A2023-12-04 21:28:04 | INFO | fairseq.tasks.translation | example hypothesis: I effetti da catastrofizzaçion en i unichi à ëse condiçionæ da-e sescioin semanæ de attivitæ fixica, a no deprescion e a miagia.\n",
            "2023-12-04 21:28:04 | INFO | fairseq.tasks.translation | example reference: Solo i effetti da castrofizzaçion, no a deprescion ò a poia, ean condiçionæ da de regolari sescioin strutturæ e settimanali de PA.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  29% 2/7 [00:02<00:07,  1.50s/it]\u001b[A2023-12-04 21:28:05 | INFO | fairseq.tasks.translation | example hypothesis: Sempre ciù ercæ propoñan un reparto con unna ciù grande çernia de gibinti.\n",
            "2023-12-04 21:28:05 | INFO | fairseq.tasks.translation | example reference: Sempre ciù de spesso i supermercoei son apreuvo à inandiâ unna seçion ciù varia de mangiæ za pronti. Çerti forniscian fiña un forno à microonde ò atri mezzi pe ascädâ o mangiâ.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  43% 3/7 [00:04<00:06,  1.58s/it]\u001b[A2023-12-04 21:28:07 | INFO | fairseq.tasks.translation | example hypothesis: Do 1951 a l'à dito unna perçendia, donde l'é visciuo solo çerte requie do Drugkyal Dzong, compreiso l'imagine de Zhabdrung Nwang Namgyal.\n",
            "2023-12-04 21:28:07 | INFO | fairseq.tasks.translation | example reference: Do 1951 un incendio o l’à fæto scì che restesse solo quarche relichia do Drukgyal Dzong, comme l’imagine de Zhabdrung Ngawang.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  57% 4/7 [00:06<00:05,  1.70s/it]\u001b[A2023-12-04 21:28:09 | INFO | fairseq.tasks.translation | example hypothesis: L’é bon che o vòstro hotel o vòstro òspite (in caxo sozzorniate inte unna guærasthouse o l’à ò inte unna casa privata) o Wi-Fi ò un PC connesso à Internet; o l’é trovou ancon inte un Internet ò inte l’Internet caft ò un pòsto in Wi-Fi pubrico.\n",
            "2023-12-04 21:28:09 | INFO | fairseq.tasks.translation | example reference: O teu hotel ò i teu host (se ti stæ int’unna penscion ò int’unna casa privæ) avian probabilmente o wifi ò un PC connesso à internet e tutti i insediamenti avian un internet caffè ò un leugo pubrico con wifi pubrico.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  71% 5/7 [00:08<00:03,  1.85s/it]\u001b[A2023-12-04 21:28:11 | INFO | fairseq.tasks.translation | example hypothesis: A Turchia, compreiso i laghi, a l’à unna superfiçie de 783.562 km (30.948 miggia quaddræ): in sce sti, 75.68 km (2917373 quaddræ) a s’é collocâ inte l’Asia sud-occidentale, e 23764 km (29174 d’Euröpa quaddræ) in Euröpa.\n",
            "2023-12-04 21:28:11 | INFO | fairseq.tasks.translation | example reference: A superficce da Turchia, compreiso i laghi, a l’òccupa 783.562 chilòmetri quaddræ (300.948 miggia quaddræ), di quæ 755.688 chilòmetri quaddræ (291.773 miggia quaddræ) se treuvan into sud-òvest de l’Asia e 23.764 (9.174 miggi quaddræ) in Euröpa.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset:  86% 6/7 [00:10<00:01,  1.76s/it]\u001b[A2023-12-04 21:28:13 | INFO | fairseq.tasks.translation | example hypothesis: À partî da-o seu debutto, The Onion o l'é vegnuo un veo impëio da paròdia de l'informaçion, con unn'ediçion cartacea, un scito web in graddo attia de 5.00.00 vixitatoî unichi into meseggio de l'ottobre, inserçioin personali, un network de noçieh 24 estlante, ch'o l'é stæto lasciou à Ducellou o Wombur de Duce.\n",
            "2023-12-04 21:28:13 | INFO | fairseq.tasks.translation | example reference: Fin da-o seu comenso, The Onion a l'é vegnua à ëse un vertadeo impëio da parodia do giornaliximo, con unn'ediçion à stampa, un scito web ch'o l'à attiou 5.000.000 vixitatoî sôo che into meise d'ötovie, personali ads, un network de notiçie à 24 oe, podcasts, e un atlante do mondo, stæto allansou che no l'é guæi, stæto ciammou Our Dumb World.\n",
            "\n",
            "epoch 1120 | valid on 'valid' subset: 100% 7/7 [00:11<00:00,  1.75s/it]\u001b[A\n",
            "                                                                       \u001b[A2023-12-04 21:28:13 | INFO | valid | epoch 1120 | valid on 'valid' subset | loss 6.453 | nll_loss 5.292 | ppl 39.18 | bleu 13.25 | wps 4198.4 | wpb 7753.9 | bsz 142.4 | num_updates 4475 | best_bleu 13.42\n",
            "2023-12-04 21:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1120 @ 4475 updates\n",
            "2023-12-04 21:28:13 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoint/checkpoint1120.pt\n",
            "2023-12-04 21:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoint/checkpoint1120.pt\n",
            "2023-12-04 21:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint/checkpoint1120.pt (epoch 1120 @ 4475 updates, score 13.25) (writing took 2.840643466000074 seconds)\n",
            "2023-12-04 21:28:16 | INFO | fairseq_cli.train | end of epoch 1120 (average epoch stats below)\n",
            "2023-12-04 21:28:16 | INFO | train | epoch 1120 | loss 1.955 | nll_loss 0.419 | ppl 1.34 | wps 19839.7 | ups 0.23 | wpb 85903.8 | bsz 1548.2 | num_updates 4475 | lr 0.000298974 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4444\n",
            "2023-12-04 21:28:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1121:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:16 | INFO | fairseq.trainer | begin training epoch 1121\n",
            "2023-12-04 21:28:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:18 | INFO | fairseq_cli.train | end of epoch 1121 (average epoch stats below)\n",
            "2023-12-04 21:28:18 | INFO | train | epoch 1121 | loss 1.951 | nll_loss 0.41 | ppl 1.33 | wps 140113 | ups 1.63 | wpb 85903.8 | bsz 1548.2 | num_updates 4479 | lr 0.000298841 | gnorm 0.119 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4447\n",
            "2023-12-04 21:28:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1122:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:18 | INFO | fairseq.trainer | begin training epoch 1122\n",
            "2023-12-04 21:28:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:20 | INFO | fairseq_cli.train | end of epoch 1122 (average epoch stats below)\n",
            "2023-12-04 21:28:20 | INFO | train | epoch 1122 | loss 1.954 | nll_loss 0.418 | ppl 1.34 | wps 144409 | ups 1.68 | wpb 85903.8 | bsz 1548.2 | num_updates 4483 | lr 0.000298707 | gnorm 0.123 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4449\n",
            "2023-12-04 21:28:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1123:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:20 | INFO | fairseq.trainer | begin training epoch 1123\n",
            "2023-12-04 21:28:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:23 | INFO | fairseq_cli.train | end of epoch 1123 (average epoch stats below)\n",
            "2023-12-04 21:28:23 | INFO | train | epoch 1123 | loss 1.953 | nll_loss 0.415 | ppl 1.33 | wps 142931 | ups 1.66 | wpb 85903.8 | bsz 1548.2 | num_updates 4487 | lr 0.000298574 | gnorm 0.12 | loss_scale 16 | train_wall 2 | gb_free 33.1 | wall 4452\n",
            "2023-12-04 21:28:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1124:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:23 | INFO | fairseq.trainer | begin training epoch 1124\n",
            "2023-12-04 21:28:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:25 | INFO | fairseq_cli.train | end of epoch 1124 (average epoch stats below)\n",
            "2023-12-04 21:28:25 | INFO | train | epoch 1124 | loss 1.954 | nll_loss 0.415 | ppl 1.33 | wps 143667 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4491 | lr 0.000298441 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4454\n",
            "2023-12-04 21:28:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1125:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:25 | INFO | fairseq.trainer | begin training epoch 1125\n",
            "2023-12-04 21:28:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:28 | INFO | fairseq_cli.train | end of epoch 1125 (average epoch stats below)\n",
            "2023-12-04 21:28:28 | INFO | train | epoch 1125 | loss 1.954 | nll_loss 0.419 | ppl 1.34 | wps 143095 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4495 | lr 0.000298308 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.5 | wall 4456\n",
            "2023-12-04 21:28:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1126:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:28 | INFO | fairseq.trainer | begin training epoch 1126\n",
            "2023-12-04 21:28:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:30 | INFO | fairseq_cli.train | end of epoch 1126 (average epoch stats below)\n",
            "2023-12-04 21:28:30 | INFO | train | epoch 1126 | loss 1.953 | nll_loss 0.415 | ppl 1.33 | wps 143142 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4499 | lr 0.000298176 | gnorm 0.122 | loss_scale 16 | train_wall 2 | gb_free 33.4 | wall 4459\n",
            "2023-12-04 21:28:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1127:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:30 | INFO | fairseq.trainer | begin training epoch 1127\n",
            "2023-12-04 21:28:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-12-04 21:28:32 | INFO | fairseq_cli.train | end of epoch 1127 (average epoch stats below)\n",
            "2023-12-04 21:28:32 | INFO | train | epoch 1127 | loss 1.954 | nll_loss 0.417 | ppl 1.34 | wps 143473 | ups 1.67 | wpb 85903.8 | bsz 1548.2 | num_updates 4503 | lr 0.000298043 | gnorm 0.121 | loss_scale 16 | train_wall 2 | gb_free 33.3 | wall 4461\n",
            "2023-12-04 21:28:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 4\n",
            "epoch 1128:   0% 0/4 [00:00<?, ?it/s]2023-12-04 21:28:32 | INFO | fairseq.trainer | begin training epoch 1128\n",
            "2023-12-04 21:28:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq_cli/train.py\", line 557, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq_cli/train.py\", line 190, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq_cli/train.py\", line 316, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/trainer.py\", line 824, in train_step\n",
            "    loss, sample_size_i, logging_output = self.task.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/tasks/fairseq_task.py\", line 519, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/optim/fp16_optimizer.py\", line 106, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 492, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate"
      ],
      "metadata": {
        "id": "AA4KnpkXLVuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! fairseq-generate \"sidetranslation/data_bin\" \\\n",
        "  --task translation -s ita -t lij \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model \"sidetranslation/spm/multi.unigram.2k.model\" \\\n",
        "  --sacrebleu --scoring sacrebleu --remove-bpe \\\n",
        "  --beam 5 --lenpen 1.0 \\\n",
        "  --gen-subset test \\\n",
        "  --path \"checkpoint/checkpoint_best.pt\" | grep \"^D-\" | LC_ALL=C sort -V | cut -f3 > gen.lij"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0jB11J0JY5a",
        "outputId": "ac8007cd-712b-4ea8-f360-540a6c5275b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-04 21:29:27.260101: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-12-04 21:29:27.308486: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-04 21:29:27.308557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-04 21:29:27.308597: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-04 21:29:27.317226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-04 21:29:28.323733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-04 21:29:30 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-12-04 21:29:32 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoint/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'sidetranslation/data_bin', 'source_lang': 'ita', 'target_lang': 'lij', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'sacrebleu', 'sacrebleu_tokenizer': '13a', 'sacrebleu_lowercase': False, 'sacrebleu_char_level': False}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'sidetranslation/spm/multi.unigram.2k.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-12-04 21:29:32 | INFO | fairseq.tasks.translation | [ita] dictionary: 2088 types\n",
            "2023-12-04 21:29:32 | INFO | fairseq.tasks.translation | [lij] dictionary: 2088 types\n",
            "2023-12-04 21:29:32 | INFO | fairseq_cli.generate | loading model(s) from checkpoint/checkpoint_best.pt\n",
            "2023-12-04 21:29:33 | INFO | fairseq.data.data_utils | loaded 1,012 examples from: sidetranslation/data_bin/test.ita-lij.ita\n",
            "2023-12-04 21:29:33 | INFO | fairseq.data.data_utils | loaded 1,012 examples from: sidetranslation/data_bin/test.ita-lij.lij\n",
            "2023-12-04 21:29:33 | INFO | fairseq.tasks.translation | sidetranslation/data_bin test ita-lij 1012 examples\n",
            "2023-12-04 21:29:59 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-12-04 21:29:59 | INFO | fairseq_cli.generate | Translated 1,012 sentences (57,339 tokens) in 12.8s (78.77 sentences/s, 4463.18 tokens/s)\n",
            "2023-12-04 21:29:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2023-12-04 21:29:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2023-12-04 21:29:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head gen.lij"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u19cjbCQMNDj",
        "outputId": "23c5e776-d096-40e1-9649-4bf75c662b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "«Abbia topi de quattro meixi che primma a l'ea de diabetichi e a ô son ciù».\n",
            "O studio o l'é ancon in fase comensa, comme dito che o l'é deciarou da-o dòtto Ehud Ur, o profescionâ de mediçiña a-a Dalhousie University de Halifax, Nuova Scoçia e diretto do dipartimento clinico e scientifico da Canadian Diabetes Association.\n",
            "Comme di atri esperti, a l'é scettico che l'é za a poscibilitæ de cuâ o diabete, e l'aggibbo che sti exiti no gh'an za affeto da-o diabete de tipo 1.\n",
            "A segretaria permanente do Comitato pe-o Nobel pe-a lettiatua de l’Academia svedeise, Sara Danius, into corso de un programma radiofònico e o l’à annonu in sciâ reixe svedeise Sveriges Radios Radio, a l’à annonçiou pubricamente o Comitaçion a l’à annonçiou co-a lettiatua do Bobylan, e pe mezo da communitæ arazzonze do 2016.\n",
            "O Danius o l'à dischiou: «Ora comme o no l'é scciuppâ de niente. Hofonato e pe-a televixon e inviou a-o seu ciù streito conlaboratô, ch'o l'à respòsto à un mòddo gentile. Pe-o momento, basou e avansou».\n",
            "In passou, o Jamie Siminoff, amministratô de Ringto di Ring, o l'à sottolicou che a soçietæ a no poeiva ëse ancon sentivâ o campanello da-o seu negoçio inssegna.\n",
            "O l'à dito ch'o l'aiva tiou sciù un campanello Wi-Fi.\n",
            "Seminoff o l'à dito che e vendie son cresciue dòppo a seu comparsa do 2013 inte un episòdio de Shark Tank, pe-a quæ a giuria do programma a l'é refuâ de finançiâ a statup.\n",
            "Gh'é comparso in sce l'emittente televisiva commerciale QVC a-a fin do 2017.\n",
            "O Ring ascì o l'à razzonto un accòrdio transattivo co-a soçietæ concorrente de serviçi de seguessa, a ADT Corporation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head sidetranslation/devtest.lij"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0oFNWIgvQVM",
        "outputId": "feb64043-314c-4740-895d-1854d1f7723d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Oua gh'emmo di ratti de 4 meixi che no son diabetichi e che in avanti ean diabetichi” o l'à azzonto. \n",
            "O dr. Ehud Ur, professô de meixiña a-a Dalhousie University de Halifax, Nova Scotia e prescidente da divixon clinica e scientifica da Canadian Diabetes Association o l'à avvertio che a reçerca a l'é ancon a-i seu primmi pasci.\n",
            "Pægio de quarche atro esperto, o l'é scettico che o diabete o pòsse ëse cuou, e o l'osserva che ste descoerte chì no gh'an de importansa pe-e gente che gh'an de za o diabete de meña 1.\n",
            "A-o lunesdì, a Sara Danius, segretäia permanente da Commiscion Nobel pe-a Lettiatua de l'Academia de Sveçia, a l'à annonçiou pubricamente int'un programma radio de l'aradio svedeise in Sveçia che a commiscion, comme a no poeiva arrivâ direttamente a-o Bob Dylan in ponto vittöia do Premmio Nobel pe-a lettiatua 2016, a l'aiva abbandonou i seu sfòrsci pe seghittâlo.\n",
            "A Danius a l'à dito, “Inte sto momento no femmo ninte. Ò ciammou e ò mandou de email a-i seu ciù streiti conlaboratoî e ò reçevuo de respòste ben ben da amixi. Pe-o momento, l'é basta de seguo.”\n",
            "In avanti, o CEO de Ring, o Jamie Siminoff, o l'aiva osservou che l'açienda a l'à comensou quande o sunaggin da pòrta o no se poeiva sentî da-o seu negòçio into garaxe..\n",
            "O l'à construto un sunaggin da pòrta WiFi, o l'à dito.\n",
            "O Siminoff o l'à dito che e vendie, stæte cresciue dòppo a seu appariçion do 2013 int'un episòdio de Shark Tank, donde o pannello do spettacolo o vegniva zu, an dæto i fondi pe comensâ.\n",
            "Verso a fin do 2017, o Siminoff o l'é apparso in sciô cannâ televixivo commersâ QVC.\n",
            "Ring a l'à fiña resciòrto unna causa con unna dita de seguessa concorrente, a ADT corporation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! sacrebleu sidetranslation/devtest.lij -m chrf --chrf-word-order 2 -i gen.lij"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGDdlLc6MmU3",
        "outputId": "f9a2471c-02d6-4bac-bf64-781ac3cb63dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            " \"name\": \"chrF2++\",\n",
            " \"score\": 41.5,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:2|space:no|version:2.3.3\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"2\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.3.3\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "Dxz-8wp25jR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c42900-68f2-4df7-f8a7-2b0554d404ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "7M5CsaxhD3Tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5980d80-7639-4e80-ce1c-5c419f235986"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "UKC75TIeKY6g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8FfvCKPeKx1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}